{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%reset -sf","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:00:00.278699Z","iopub.execute_input":"2022-01-10T20:00:00.279257Z","iopub.status.idle":"2022-01-10T20:00:00.414934Z","shell.execute_reply.started":"2022-01-10T20:00:00.279151Z","shell.execute_reply":"2022-01-10T20:00:00.413986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:00:00.41655Z","iopub.execute_input":"2022-01-10T20:00:00.416866Z","iopub.status.idle":"2022-01-10T20:00:00.420977Z","shell.execute_reply.started":"2022-01-10T20:00:00.416833Z","shell.execute_reply":"2022-01-10T20:00:00.42017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U scikit-learn","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:00:00.422345Z","iopub.execute_input":"2022-01-10T20:00:00.422764Z","iopub.status.idle":"2022-01-10T20:00:18.497306Z","shell.execute_reply.started":"2022-01-10T20:00:00.422715Z","shell.execute_reply":"2022-01-10T20:00:18.496243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Patch Xeon Intel OneAPI Scikit accelerator\n!pip install scikit-learn-intelex\nfrom sklearnex import patch_sklearn\npatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:00:18.499758Z","iopub.execute_input":"2022-01-10T20:00:18.500002Z","iopub.status.idle":"2022-01-10T20:00:57.386703Z","shell.execute_reply.started":"2022-01-10T20:00:18.499974Z","shell.execute_reply":"2022-01-10T20:00:57.385834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import array, linspace, mean, column_stack\nfrom pandas import read_parquet, DataFrame, Series, to_datetime, concat\nfrom pathlib import Path\nfrom itertools import cycle\nfrom random import randint\nfrom gc import collect\nfrom joblib import dump, load\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, classification_report\nfrom sklearn.model_selection import train_test_split, ShuffleSplit\nfrom sklearn.linear_model import Lasso, LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom deap import creator as ga_cr, base as ga_b, algorithms as ga_algo, tools as ga_t","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:00:57.388243Z","iopub.execute_input":"2022-01-10T20:00:57.388584Z","iopub.status.idle":"2022-01-10T20:00:57.425331Z","shell.execute_reply.started":"2022-01-10T20:00:57.38854Z","shell.execute_reply":"2022-01-10T20:00:57.424653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = Path().cwd()\np = p.parent\np = p / 'input' / 'kaggle-pog-series-s01e01'\n\ntrain = read_parquet(p / 'train.parquet')\ntest = read_parquet(p / 'test.parquet')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:00:57.42671Z","iopub.execute_input":"2022-01-10T20:00:57.426909Z","iopub.status.idle":"2022-01-10T20:01:00.662554Z","shell.execute_reply.started":"2022-01-10T20:00:57.426884Z","shell.execute_reply":"2022-01-10T20:01:00.661644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_train(df):\n    df['publishedAt'] = to_datetime(df['publishedAt'], errors='coerce').dt.tz_localize(None)\n    df['trending_date'] = to_datetime(df['trending_date'], errors='coerce').dt.tz_localize(None) \n    return df\n    \ntrain = clean_train(train)\ntest = clean_train(test)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:01:00.66563Z","iopub.execute_input":"2022-01-10T20:01:00.66598Z","iopub.status.idle":"2022-01-10T20:01:00.768771Z","shell.execute_reply.started":"2022-01-10T20:01:00.665944Z","shell.execute_reply":"2022-01-10T20:01:00.767808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feat_eng(df):\n    df['t_delta'] = (df['trending_date'] - df['publishedAt']).dt.seconds\n    return df\n\ntrain = feat_eng(train)\ntest = feat_eng(test)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:01:00.770275Z","iopub.execute_input":"2022-01-10T20:01:00.770557Z","iopub.status.idle":"2022-01-10T20:01:04.396056Z","shell.execute_reply.started":"2022-01-10T20:01:00.770511Z","shell.execute_reply":"2022-01-10T20:01:04.395089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GA_Scikit():\n    def __init__(self, \n                 estimator, \n                 #\n                 params, \n                 eval_func, \n                 eval_weights, \n                 #\n                 train_df, \n                 #valid_df, \n                 score, \n                 #\n                 sel_tournsize=2, \n                 cx_uniform_prob=0.5, \n                 mut_shuffle_idx_prob=0.1, \n                 n_pop=10, \n                 n_gen=10, \n                 n_hof=1, \n                 cx_prob=0.5, \n                 mut_prob=0.1, \n                 n_jobs=4  # not good with HistGradBoosReg...\n                ):\n        \n        self.est = estimator\n        self.params = params\n        self.eval_func = eval_func\n        self.eval_weights = eval_weights\n        #\n        self.train_df = train_df\n        #self.valid_df = valid_df\n        self.score = score\n        #\n        self.sel_tournsize = sel_tournsize\n        self.cx_uniform_prob = cx_uniform_prob\n        self.mut_shuffle_idx_prob = mut_shuffle_idx_prob\n        self.n_pop = n_pop\n        self.n_gen = n_gen\n        self.n_hof = n_hof\n        self.cx_prob = cx_prob\n        self.mut_prob = mut_prob\n        self.n_jobs = n_jobs\n        \n        self._pad_params()\n        self._create_fitness_and_indiv()\n        self._register_indiv_and_pop_generators()\n        self._register_eval_func()\n        self._register_selection_crossover_mutation_methods()\n        \n    def _pad_params(self):\n        \"\"\"Pad params for crossover shuffle idx method\"\"\"\n        assert isinstance(self.params, dict), 'Params must be a dict, i.e. estimator.get_params()'\n        params_count = {k: len(v) for k,v in self.params.items()}\n        max_length, max_key = -99, ''\n        for k, v in params_count.items():\n            if v <= max_length:\n                continue\n            else:\n                max_key = k\n                max_length = v\n        assert isinstance(max_length, int), 'The max length between all params must be an int'\n        # cycle through params for max length param, otherwise infinite cycle\n        values_padded = (cycle(v) if k!=max_key else v for k,v in self.params.items())\n        values_padded = zip(*values_padded)  # ('a', 1, 14), ('b', 2, 16), ('c', 3, 16) ...\n        values_padded = zip(*values_padded)  # ('a', 'b', 'c'), (1, 2, 3), (14, 15, 16)...\n        padded_params = {}\n        for k, v in zip(self.params, values_padded):\n            padded_params[k] = v\n        self.padded_params = padded_params\n        \n    def _create_fitness_and_indiv(self):\n        \"\"\"Create GA individual and fitness entities (classes)\"\"\"\n        ga_cr.create('Fitness', ga_b.Fitness, weights=self.eval_weights)\n        ga_cr.create('Individual', list, fitness=ga_cr.Fitness)\n\n    def _gen_params_to_ga(self):\n        \"\"\"Generate index for each param for individual\"\"\"\n        max_dict = len(self.padded_params)\n        max_length = len(list(self.padded_params.values())[0])\n        idxs = [randint(0, max_length-1) for _ in range(max_dict)]\n        return idxs\n            \n    def _register_indiv_and_pop_generators(self):\n        \"\"\"Register GA individual and population generators\"\"\"\n        self.tb = ga_b.Toolbox()\n\n        if self.n_jobs > 1:\n            from multiprocessing import Pool\n            pool = Pool()\n            self.tb.register(\"map\", pool.map)\n\n        self.tb.register(\"individual\", ga_t.initIterate, ga_cr.Individual, self._gen_params_to_ga)\n        #print('indiv', self.tb.individual())\n        self.tb.register(\"population\", ga_t.initRepeat, list, self.tb.individual)\n        #print('population', self.tb.population(n=2))\n    \n    def _register_eval_func(self):\n        \"\"\"Set GA evaluate individual function\"\"\"\n        self.tb.register(\"evaluate\",\n                        self.eval_func,\n                        padded_params=self.padded_params,\n                        est=self.est,\n                        train_df=self.train_df,\n                        score=self.score\n                        )\n        #print(list(self.tb.evaluate(indiv) for indiv in self.tb.population(3)))\n        \n    def _register_selection_crossover_mutation_methods(self):\n        \"\"\"Register GA select/mate/mutate methods\"\"\"\n        self.tb.register(\"select\", ga_t.selTournament, tournsize=self.sel_tournsize)\n        self.tb.register(\"mate\", ga_t.cxUniform, indpb=self.cx_uniform_prob)\n        self.tb.register(\"mutate\", ga_t.mutShuffleIndexes, indpb=self.mut_shuffle_idx_prob)\n        \n    def run_ga_search(self):\n        \"\"\"Run search\"\"\"\n        pop = self.tb.population(n=self.n_pop)\n        hof = ga_t.HallOfFame(self.n_hof)\n\n        # Stats stdout\n        #stats = ga_t.Statistics(lambda ind: ind.fitness.values )\n        stats1 = ga_t.Statistics(lambda ind: ind.fitness.values[0] )\n        stats2 = ga_t.Statistics(lambda ind: ind.fitness.values[1] )\n        stats3 = ga_t.Statistics(lambda ind: ind.fitness.values[2] )\n        stats = ga_t.MultiStatistics(v_loss=stats1, max_depth=stats2, n_est=stats3)\n        stats.register(\"avg\", mean)\n        #stats.register(\"std\", np.std)\n        \n        # GA Run\n        pop, log = ga_algo.eaSimple(pop, self.tb, cxpb=self.cx_prob, \n                                    mutpb=self.mut_prob, ngen=self.n_gen, \n                                    stats=stats, halloffame=hof, verbose=True)\n        \n        # Convert back params\n        hof_ = {}\n        for i in range(self.n_hof):\n            hof_['hof_' + str(i)] = self._ga_to_params(hof[i])\n\n        return pop, log, hof_\n    \n    def _ga_to_params(self, idx_params):\n        \"\"\"Helper to convert to readable params\"\"\"\n        res = {}\n        for (k,v), idx in zip(self.padded_params.items(), idx_params):\n            res[k] = v[idx]\n        return res","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:01:04.397931Z","iopub.execute_input":"2022-01-10T20:01:04.398272Z","iopub.status.idle":"2022-01-10T20:01:04.429789Z","shell.execute_reply.started":"2022-01-10T20:01:04.398225Z","shell.execute_reply":"2022-01-10T20:01:04.428975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prep_data(params, train_df, train_data=True):\n    train_X = train_df[['title', 'duration_seconds', 't_delta']].copy()\n\n    cv_params = {k:v for k,v in params.items() if k != 'q'}\n    cv_params = {**cv_params, **{'strip_accents': 'ascii',\n                                 'lowercase': True,\n                                 'stop_words': 'english',\n                                 'analyzer': 'word',\n                                 #'token_pattern': '(?u)\\b\\w\\w\\w+\\b',  # 3 or more letters\n                                 }}\n    #cv = CountVectorizer(**)\n    tdf = TfidfVectorizer(**cv_params)\n    \n    q_param = {k:v for k,v in params.items() if k == 'q'}\n    q = train_X['duration_seconds'].quantile(**q_param)\n    mask = train_X['duration_seconds'].isna()\n    train_X.loc[mask, 'duration_seconds'] = q\n    \n    mms = MinMaxScaler()\n    \n    train_X = column_stack((\n        tdf.fit_transform(train_X['title']).toarray(),\n        mms.fit_transform(train_X[['duration_seconds']]),\n        mms.fit_transform(train_X[['t_delta']]),\n    ))\n    \n    if train_data:\n        train_y = train_df[['likes', 'view_count']]\n        train_y = train_y['likes'] / train_y['view_count']\n        return train_X, train_y\n    else:\n        return train_X","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:01:04.432851Z","iopub.execute_input":"2022-01-10T20:01:04.433579Z","iopub.status.idle":"2022-01-10T20:01:04.449394Z","shell.execute_reply.started":"2022-01-10T20:01:04.433539Z","shell.execute_reply":"2022-01-10T20:01:04.448195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(train_X, train_y, est, score, give_model=False, folds=False):\n    if not give_model:\n        if not folds:\n            train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, train_size=0.8)\n            est.fit(train_X, train_y)\n            pred_v = est.predict(valid_X)\n            obj = score(valid_y, pred_v)\n            return obj\n        else:\n            ss = ShuffleSplit(n_splits=5, test_size=0.2)\n            #ss = TimeSeriesSplit(n_splits=2)\n            objs = []\n            for train_idx, valid_idx in ss.split(train_X):\n                est.fit(train_X[train_idx, :], train_y.iloc[train_idx])\n                pred_v = est.predict(train_X[valid_idx, :])\n                obj = score(train_y.iloc[valid_idx], pred_v)\n                objs.append(obj)\n            obj = mean(objs)\n            return obj\n    else:\n        est.fit(train_X, train_y)\n        return est","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:01:04.451544Z","iopub.execute_input":"2022-01-10T20:01:04.452696Z","iopub.status.idle":"2022-01-10T20:01:04.46627Z","shell.execute_reply.started":"2022-01-10T20:01:04.452649Z","shell.execute_reply":"2022-01-10T20:01:04.465579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Estimator, params and requirements\n\nest = RandomForestRegressor(random_state=16)\n\ncv_params = {\n             'n_estimators': linspace(1,100,100).astype(int),\n             'max_depth': linspace(1,100,100).astype(int),\n             #\n             'q': linspace(0.01,0.99,100),\n             #\n             #'ngram_range_': linspace(1,10,10).astype(int),\n             'min_df': linspace(1,5,10).astype(int),\n             'max_df': linspace(5,10,10).astype(int),\n             'max_features': linspace(10,300,100).astype(int),\n             'binary': [True, False],\n            }\n\ndef cv_eval_indiv(individual, padded_params, est, train_df, score):\n    \"\"\"Evaluate individual's genes (estimator's params)\"\"\"\n    est_params = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual) if k in ['n_estimators', 'max_depth']}\n    _ = est.set_params(**est_params)\n    \n    cv_params = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual) if k not in ['n_estimators', 'max_depth']}\n    train_X, train_y = prep_data(cv_params, train_df, train_data=True)\n\n    #model_params = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual) if k != '#_lags'}\n    #est.set_params(**model_params)  # seems can't parallelize this simultaneous with GA  # **{**model_params, **{'n_jobs': 1} }\n\n    obj = train_model(train_X, train_y, est, score, folds=False)\n    \n    collect()\n    \n    return obj, est_params['n_estimators'], est_params['max_depth'],\n        \ncv_weights = -0.5, -1, -1,","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:01:04.467528Z","iopub.execute_input":"2022-01-10T20:01:04.468288Z","iopub.status.idle":"2022-01-10T20:01:04.485283Z","shell.execute_reply.started":"2022-01-10T20:01:04.468237Z","shell.execute_reply":"2022-01-10T20:01:04.48456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ga_params = GA_Scikit(est,\n                      cv_params,\n                      cv_eval_indiv,\n                      cv_weights,\n                      #\n                      train[['title', 'duration_seconds', 't_delta', 'likes', 'view_count']],\n                      mean_absolute_error,\n                      )\npop, log, hof = ga_params.run_ga_search()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:01:04.486338Z","iopub.execute_input":"2022-01-10T20:01:04.486959Z","iopub.status.idle":"2022-01-10T20:01:23.686523Z","shell.execute_reply.started":"2022-01-10T20:01:04.48691Z","shell.execute_reply":"2022-01-10T20:01:23.685464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save HOF params\nhof\ndump(hof['hof_0'], 'best_params.json')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:01:23.688239Z","iopub.execute_input":"2022-01-10T20:01:23.688529Z","iopub.status.idle":"2022-01-10T20:01:23.702926Z","shell.execute_reply.started":"2022-01-10T20:01:23.688494Z","shell.execute_reply":"2022-01-10T20:01:23.701748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Full train\nparams = load('best_params.json')\n\nest_params = {k:v for k,v in params.items() if k in ['n_estimators', 'max_depth']}\nest_params\nest = RandomForestRegressor(random_state=16)\nest.set_params(**est_params)\n\ncv_params = {k:v for k,v in params.items() if k not in ['n_estimators', 'max_depth']}\ncv_params\ntrain_X, train_y = prep_data(cv_params, train)\nest = train_model(train_X, train_y, est, mean_absolute_error, give_model=True)\n\n# Submission\ntest_X = prep_data(cv_params, test, train_data=False)\npred = est.predict(test_X)\nsubm = concat([test['id'], Series(pred)], axis=1)\nsubm.columns = ['id', 'target']\nsubm.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:02:36.174561Z","iopub.execute_input":"2022-01-10T20:02:36.175469Z","iopub.status.idle":"2022-01-10T20:02:41.063131Z","shell.execute_reply.started":"2022-01-10T20:02:36.175433Z","shell.execute_reply":"2022-01-10T20:02:41.062499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm","metadata":{"execution":{"iopub.status.busy":"2022-01-10T20:01:23.862801Z","iopub.status.idle":"2022-01-10T20:01:23.863474Z","shell.execute_reply.started":"2022-01-10T20:01:23.863186Z","shell.execute_reply":"2022-01-10T20:01:23.863214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}