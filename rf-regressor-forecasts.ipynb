{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-03T01:27:35.323009Z","iopub.execute_input":"2022-01-03T01:27:35.323324Z","iopub.status.idle":"2022-01-03T01:27:35.357530Z","shell.execute_reply.started":"2022-01-03T01:27:35.323245Z","shell.execute_reply":"2022-01-03T01:27:35.356976Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-jan-2022/sample_submission.csv\n/kaggle/input/tabular-playground-series-jan-2022/train.csv\n/kaggle/input/tabular-playground-series-jan-2022/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from pathlib import Path\nfrom pprint import pprint\nfrom itertools import cycle\nfrom random import randint\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nfrom random import randint\nfrom itertools import cycle\nfrom time import monotonic\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom deap import creator as ga_cr, base as ga_b, algorithms as ga_algo, tools as ga_t","metadata":{"execution":{"iopub.status.busy":"2022-01-03T01:31:24.139842Z","iopub.execute_input":"2022-01-03T01:31:24.140150Z","iopub.status.idle":"2022-01-03T01:31:24.147941Z","shell.execute_reply.started":"2022-01-03T01:31:24.140117Z","shell.execute_reply":"2022-01-03T01:31:24.147135Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'","metadata":{"execution":{"iopub.status.busy":"2022-01-03T01:27:37.630215Z","iopub.execute_input":"2022-01-03T01:27:37.630400Z","iopub.status.idle":"2022-01-03T01:27:37.634718Z","shell.execute_reply.started":"2022-01-03T01:27:37.630378Z","shell.execute_reply":"2022-01-03T01:27:37.633636Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"path = Path().cwd().parent / 'input'\nfiles = list(path.rglob('*'))\nfiles","metadata":{"execution":{"iopub.status.busy":"2022-01-03T01:27:39.034245Z","iopub.execute_input":"2022-01-03T01:27:39.035341Z","iopub.status.idle":"2022-01-03T01:27:39.046738Z","shell.execute_reply.started":"2022-01-03T01:27:39.035309Z","shell.execute_reply":"2022-01-03T01:27:39.046054Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[PosixPath('/kaggle/input/tabular-playground-series-jan-2022'),\n PosixPath('/kaggle/input/tabular-playground-series-jan-2022/sample_submission.csv'),\n PosixPath('/kaggle/input/tabular-playground-series-jan-2022/train.csv'),\n PosixPath('/kaggle/input/tabular-playground-series-jan-2022/test.csv')]"},"metadata":{}}]},{"cell_type":"code","source":"train = pd.read_csv(files[2])\ntrain['date'] = pd.to_datetime(train['date'], errors='coerce')\ntrain = train.set_index('date')\n\ntest = pd.read_csv(files[3])\ntest['date'] = pd.to_datetime(test['date'], errors='coerce')\ntest = test.set_index('date')\n\ntrain\ntest","metadata":{"execution":{"iopub.status.busy":"2022-01-03T01:27:39.783856Z","iopub.execute_input":"2022-01-03T01:27:39.784119Z","iopub.status.idle":"2022-01-03T01:27:39.914191Z","shell.execute_reply.started":"2022-01-03T01:27:39.784087Z","shell.execute_reply":"2022-01-03T01:27:39.913501Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"            row_id  country       store         product  num_sold\ndate                                                             \n2015-01-01       0  Finland  KaggleMart      Kaggle Mug       329\n2015-01-01       1  Finland  KaggleMart      Kaggle Hat       520\n2015-01-01       2  Finland  KaggleMart  Kaggle Sticker       146\n2015-01-01       3  Finland  KaggleRama      Kaggle Mug       572\n2015-01-01       4  Finland  KaggleRama      Kaggle Hat       911\n...            ...      ...         ...             ...       ...\n2018-12-31   26293   Sweden  KaggleMart      Kaggle Hat       823\n2018-12-31   26294   Sweden  KaggleMart  Kaggle Sticker       250\n2018-12-31   26295   Sweden  KaggleRama      Kaggle Mug      1004\n2018-12-31   26296   Sweden  KaggleRama      Kaggle Hat      1441\n2018-12-31   26297   Sweden  KaggleRama  Kaggle Sticker       388\n\n[26298 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>country</th>\n      <th>store</th>\n      <th>product</th>\n      <th>num_sold</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-01</th>\n      <td>0</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Mug</td>\n      <td>329</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>1</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Hat</td>\n      <td>520</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>2</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Sticker</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>3</td>\n      <td>Finland</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Mug</td>\n      <td>572</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>4</td>\n      <td>Finland</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Hat</td>\n      <td>911</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>26293</td>\n      <td>Sweden</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Hat</td>\n      <td>823</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>26294</td>\n      <td>Sweden</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Sticker</td>\n      <td>250</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>26295</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Mug</td>\n      <td>1004</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>26296</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Hat</td>\n      <td>1441</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>26297</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Sticker</td>\n      <td>388</td>\n    </tr>\n  </tbody>\n</table>\n<p>26298 rows × 5 columns</p>\n</div>"},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"            row_id  country       store         product\ndate                                                   \n2019-01-01   26298  Finland  KaggleMart      Kaggle Mug\n2019-01-01   26299  Finland  KaggleMart      Kaggle Hat\n2019-01-01   26300  Finland  KaggleMart  Kaggle Sticker\n2019-01-01   26301  Finland  KaggleRama      Kaggle Mug\n2019-01-01   26302  Finland  KaggleRama      Kaggle Hat\n...            ...      ...         ...             ...\n2019-12-31   32863   Sweden  KaggleMart      Kaggle Hat\n2019-12-31   32864   Sweden  KaggleMart  Kaggle Sticker\n2019-12-31   32865   Sweden  KaggleRama      Kaggle Mug\n2019-12-31   32866   Sweden  KaggleRama      Kaggle Hat\n2019-12-31   32867   Sweden  KaggleRama  Kaggle Sticker\n\n[6570 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>country</th>\n      <th>store</th>\n      <th>product</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-01-01</th>\n      <td>26298</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Mug</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>26299</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Hat</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>26300</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Sticker</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>26301</td>\n      <td>Finland</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Mug</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>26302</td>\n      <td>Finland</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Hat</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2019-12-31</th>\n      <td>32863</td>\n      <td>Sweden</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Hat</td>\n    </tr>\n    <tr>\n      <th>2019-12-31</th>\n      <td>32864</td>\n      <td>Sweden</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Sticker</td>\n    </tr>\n    <tr>\n      <th>2019-12-31</th>\n      <td>32865</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Mug</td>\n    </tr>\n    <tr>\n      <th>2019-12-31</th>\n      <td>32866</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Hat</td>\n    </tr>\n    <tr>\n      <th>2019-12-31</th>\n      <td>32867</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Sticker</td>\n    </tr>\n  </tbody>\n</table>\n<p>6570 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Checking\n\ndef train_valid(df_wide):\n    train_dfs, train_ids = {}, {}\n    valid_dfs, valid_ids = {}, {}\n    for cat in df_wide['country'].unique():\n        for cat_ in df_wide['store'].unique():\n            for cat__ in df_wide['product'].unique():\n                mask = (df_wide['country']==cat) & (df_wide['store']==cat_) & (df_wide['product']==cat__)\n                df = df_wide[mask]\n                #train_ids[cat+cat_+cat__] = df['row_id']\n                df = df.groupby(['country', 'store', 'product']).resample('D').sum()['num_sold']\n                df = df.reset_index(level=[0,1,2], drop=True).squeeze()\n                df.name = cat+cat_+cat__\n                thresh = int(len(df)*0.8)\n                df_train = df.iloc[:thresh]\n                df_valid = df.iloc[thresh:]\n                train_dfs[cat+cat_+cat__] = df_train\n                valid_dfs[cat+cat_+cat__] = df_valid\n                print(df_wide[mask].shape[0] == (df_train.shape[0] + df_valid.shape[0])) \n    return train_dfs, valid_dfs\n\ntrain_dfs, valid_dfs = train_valid(train)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T01:27:40.527470Z","iopub.execute_input":"2022-01-03T01:27:40.527918Z","iopub.status.idle":"2022-01-03T01:27:40.791216Z","shell.execute_reply.started":"2022-01-03T01:27:40.527881Z","shell.execute_reply":"2022-01-03T01:27:40.790412Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"True\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n","output_type":"stream"}]},{"cell_type":"code","source":"class GA_Scikit():\n    def __init__(self, \n                 estimator, \n                 #\n                 params, \n                 eval_func, \n                 eval_weights, \n                 #\n                 train_df, \n                 valid_df, \n                 score, \n                 #\n                 sel_tournsize=2, \n                 cx_uniform_prob=0.5, \n                 mut_shuffle_idx_prob=0.1, \n                 n_pop=20, \n                 n_gen=10, \n                 n_hof=1, \n                 cx_prob=0.5, \n                 mut_prob=0.1, \n                 n_jobs=4\n                ):\n        \n        self.est = estimator\n        self.params = params\n        self.eval_func = eval_func\n        self.eval_weights = eval_weights\n        #\n        self.train_df = train_df\n        self.valid_df = valid_df\n        self.score = score\n        #\n        self.sel_tournsize = sel_tournsize\n        self.cx_uniform_prob = cx_uniform_prob\n        self.mut_shuffle_idx_prob = mut_shuffle_idx_prob\n        self.n_pop = n_pop\n        self.n_gen = n_gen\n        self.n_hof = n_hof\n        self.cx_prob = cx_prob\n        self.mut_prob = mut_prob\n        self.n_jobs = n_jobs\n        \n        self._pad_params()\n        self._create_fitness_and_indiv()\n        self._register_indiv_and_pop_generators()\n        self._register_eval_func()\n        self._register_selection_crossover_mutation_methods()\n        \n    def _pad_params(self):\n        \"\"\"Pad params for crossover shuffle idx method\"\"\"\n        assert isinstance(self.params, dict), 'Params must be a dict, i.e. estimator.get_params()'\n        params_count = {k: len(v) for k,v in self.params.items()}\n        max_length, max_key = -99, ''\n        for k, v in params_count.items():\n            if v <= max_length:\n                continue\n            else:\n                max_key = k\n                max_length = v\n        assert isinstance(max_length, int), 'The max length between all params must be an int'\n        # cycle through params for max length param, otherwise infinite cycle\n        values_padded = (cycle(v) if k!=max_key else v for k,v in self.params.items())\n        values_padded = zip(*values_padded)  # ('a', 1, 14), ('b', 2, 16), ('c', 3, 16) ...\n        values_padded = zip(*values_padded)  # ('a', 'b', 'c'), (1, 2, 3), (14, 15, 16)...\n        padded_params = {}\n        for k, v in zip(self.params, values_padded):\n            padded_params[k] = v\n        self.padded_params = padded_params\n        \n    def _create_fitness_and_indiv(self):\n        \"\"\"Create GA individual and fitness entities (classes)\"\"\"\n        ga_cr.create('Fitness', ga_b.Fitness, weights=self.eval_weights)\n        ga_cr.create('Individual', list, fitness=ga_cr.Fitness)\n\n    def _gen_params_to_ga(self):\n        \"\"\"Generate index for each param for individual\"\"\"\n        max_dict = len(self.padded_params)\n        max_length = len(list(self.padded_params.values())[0])\n        idxs = [randint(0, max_length-1) for _ in range(max_dict)]\n        return idxs\n            \n    def _register_indiv_and_pop_generators(self):\n        \"\"\"Register GA individual and population generators\"\"\"\n        self.tb = ga_b.Toolbox()\n\n        if self.n_jobs > 1:\n            from multiprocessing import Pool\n            pool = Pool()\n            self.tb.register(\"map\", pool.map)\n\n        self.tb.register(\"individual\", ga_t.initIterate, ga_cr.Individual, self._gen_params_to_ga)\n        #print('indiv', self.tb.individual())\n        self.tb.register(\"population\", ga_t.initRepeat, list, self.tb.individual)\n        #print('population', self.tb.population(n=2))\n    \n    def _register_eval_func(self):\n        \"\"\"Set GA evaluate individual function\"\"\"\n        self.tb.register(\"evaluate\",\n                        self.eval_func,\n                        padded_params=self.padded_params,\n                        est=self.est,\n                        train_df=self.train_df,\n                        valid_df=self.valid_df, \n                        score=self.score\n                        )\n        #print(list(self.tb.evaluate(indiv) for indiv in self.tb.population(3)))\n        \n    def _register_selection_crossover_mutation_methods(self):\n        self.tb.register(\"select\", ga_t.selTournament, tournsize=self.sel_tournsize)\n        self.tb.register(\"mate\", ga_t.cxUniform, indpb=self.cx_uniform_prob)\n        self.tb.register(\"mutate\", ga_t.mutShuffleIndexes, indpb=self.mut_shuffle_idx_prob)\n        \n    def run_ga_search(self):\n        pop = self.tb.population(n=self.n_pop)\n        hof = ga_t.HallOfFame(self.n_hof)\n\n        # Stats stdout\n        stats = ga_t.Statistics(lambda ind: ind.fitness.values )\n        #stats1 = ga_t.Statistics(lambda ind: ind.fitness.values[0] )\n        #stats2 = ga_t.Statistics(lambda ind: ind.fitness.values[1] )\n        #stats3 = ga_t.Statistics(lambda ind: ind.fitness.values[2] )\n        stats = ga_t.MultiStatistics(score=stats)\n        stats.register(\"avg\", np.mean)\n        #stats.register(\"std\", np.std)\n        #stats.register(\"min\", np.min)\n        #stats.register(\"max\", np.max)\n\n        # History\n        #hist = tools.History()\n        #toolbox.decorate(\"select\", hist.decorator)\n        #tb.decorate(\"mate\", hist.decorator)\n        #tb.decorate(\"mutate\", hist.decorator)\n        #hist.update(pop)\n\n        # GA Run\n        pop, log = ga_algo.eaSimple(pop, self.tb, cxpb=self.cx_prob, \n                                    mutpb=self.mut_prob, ngen=self.n_gen, \n                                    stats=stats, halloffame=hof, verbose=True)\n        \n        # Convert back params\n        hof_ = {}\n        for i in range(self.n_hof):\n            hof_['hof_' + str(i)] = self._ga_to_params(hof[i])\n\n        return pop, log, hof_\n    \n    def _ga_to_params(self, idx_params):\n        res = {}\n        for (k,v), idx in zip(self.padded_params.items(), idx_params):\n            res[k] = v[idx]\n        return res","metadata":{"execution":{"iopub.status.busy":"2022-01-03T01:44:41.100127Z","iopub.execute_input":"2022-01-03T01:44:41.100837Z","iopub.status.idle":"2022-01-03T01:44:41.135866Z","shell.execute_reply.started":"2022-01-03T01:44:41.100791Z","shell.execute_reply":"2022-01-03T01:44:41.135022Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Estimator, params and requirements\n\nts_est = RandomForestClassifier()\n\nts_params = {\n            '#_lags': np.linspace(1, 10, 100).astype(int),\n            #\n            'class_weight': ['balanced', 'balanced_subsample'],\n            'bootstrap': [False, True],\n            'n_estimators': np.linspace(1, 100, 100).astype(int),\n            'max_depth': np.linspace(1, 100, 100).astype(int),\n            'criterion': ['gini', 'entropy'],\n            'max_features': np.linspace(.01, .99, 100),\n            'max_samples': np.linspace(.01, .99, 100),\n            }\n\ndef ts_eval_indiv(individual, padded_params, est, train_df, valid_df, score):\n    \"\"\"Evaluate individual's genes (estimator's params)\"\"\"\n    ### => Result tuple must match weights in GA\n    model_params = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual) if k != '#_lags'}\n    \n    data_params = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual) if k == '#_lags'}\n    \n    # def it\n    ###\n    train_df = train_df.to_frame()\n    valid_df = valid_df.to_frame()\n    for i in range(data_params['#_lags']):\n        lagged = train_df.iloc[:, 0].shift(i+1)\n        train_df = pd.concat([train_df, lagged], axis=1)\n        \n        lagged = valid_df.iloc[:, 0].shift(i+1)\n        valid_df = pd.concat([valid_df, lagged], axis=1)\n        \n    train_df = train_df.dropna()\n    train_y = train_df.iloc[:, 0]\n    train_X = train_df.iloc[:, 1:]\n        \n    valid_df = valid_df.dropna()\n    valid_y = valid_df.iloc[:, 0]\n    valid_X = valid_df.iloc[:, 1:]\n    ###\n    \n    est.set_params(**{**model_params, **{'n_jobs': 1} })  # seems can't parallelize this simultaneous with GA\n    est.fit(train_X, train_y)\n    pred = est.predict(valid_X)\n    obj = score(valid_y, pred)\n    return obj,\n        \nts_weights = (-1,)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T01:45:25.650633Z","iopub.execute_input":"2022-01-03T01:45:25.651145Z","iopub.status.idle":"2022-01-03T01:45:25.667981Z","shell.execute_reply.started":"2022-01-03T01:45:25.651111Z","shell.execute_reply":"2022-01-03T01:45:25.667369Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# testing\nnames = list(train_dfs.keys())\ntemp = train_dfs[names[0]]\n\nnames = list(valid_dfs.keys())\ntemp_ = valid_dfs[names[0]]\n# TODO loop each train dataset \n\nrf = RandomForestClassifier()\n\nga_params = GA_Scikit(rf,                          \n                      ts_params, \n                      ts_eval_indiv, \n                      ts_weights,\n                      #\n                      temp,\n                      temp_,\n                      mean_squared_error,\n                      )\npop, log, hof = ga_params.run_ga_search()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T01:45:26.059303Z","iopub.execute_input":"2022-01-03T01:45:26.059925Z","iopub.status.idle":"2022-01-03T01:46:48.536399Z","shell.execute_reply.started":"2022-01-03T01:45:26.059890Z","shell.execute_reply":"2022-01-03T01:46:48.535464Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"   \t      \t        score         \n   \t      \t----------------------\ngen\tnevals\tavg    \tgen\tnevals\n0  \t20    \t2175.85\t0  \t20    \n1  \t14    \t1899.07\t1  \t14    \n2  \t14    \t1527.43\t2  \t14    \n3  \t12    \t1257.32\t3  \t12    \n4  \t10    \t1125.26\t4  \t10    \n5  \t11    \t1078.11\t5  \t11    \n6  \t14    \t1040.65\t6  \t14    \n7  \t9     \t1021.71\t7  \t9     \n8  \t13    \t1087.26\t8  \t13    \n9  \t12    \t1076.02\t9  \t12    \n10 \t15    \t1029.72\t10 \t15    \n","output_type":"stream"}]},{"cell_type":"code","source":"hof","metadata":{"execution":{"iopub.status.busy":"2022-01-03T01:46:48.538210Z","iopub.execute_input":"2022-01-03T01:46:48.538537Z","iopub.status.idle":"2022-01-03T01:46:48.544323Z","shell.execute_reply.started":"2022-01-03T01:46:48.538504Z","shell.execute_reply":"2022-01-03T01:46:48.543131Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"{'hof_0': {'#_lags': 9,\n  'class_weight': 'balanced_subsample',\n  'bootstrap': True,\n  'n_estimators': 48,\n  'max_depth': 43,\n  'criterion': 'gini',\n  'max_features': 0.8712121212121212,\n  'max_samples': 0.8613131313131313}}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}