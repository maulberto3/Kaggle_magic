{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-03T00:50:45.090342Z","iopub.execute_input":"2022-01-03T00:50:45.090797Z","iopub.status.idle":"2022-01-03T00:50:45.099090Z","shell.execute_reply.started":"2022-01-03T00:50:45.090764Z","shell.execute_reply":"2022-01-03T00:50:45.098055Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-jan-2022/sample_submission.csv\n/kaggle/input/tabular-playground-series-jan-2022/train.csv\n/kaggle/input/tabular-playground-series-jan-2022/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!conda list statsmodels","metadata":{"execution":{"iopub.status.busy":"2022-01-03T00:39:44.70308Z","iopub.execute_input":"2022-01-03T00:39:44.703327Z","iopub.status.idle":"2022-01-03T00:40:01.657161Z","shell.execute_reply.started":"2022-01-03T00:39:44.7033Z","shell.execute_reply":"2022-01-03T00:40:01.656438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall statsmodels -y\n!pip install -U statsmodels","metadata":{"execution":{"iopub.status.busy":"2022-01-03T00:40:01.659377Z","iopub.execute_input":"2022-01-03T00:40:01.659619Z","iopub.status.idle":"2022-01-03T00:40:19.487165Z","shell.execute_reply.started":"2022-01-03T00:40:01.659585Z","shell.execute_reply":"2022-01-03T00:40:19.486119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom itertools import cycle\nfrom random import randint\n\nfrom statsmodels.tsa.api import STLForecast\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\nfrom deap import creator as ga_cr, base as ga_b, algorithms as ga_algo, tools as ga_t\n\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2022-01-03T00:50:47.088766Z","iopub.execute_input":"2022-01-03T00:50:47.089485Z","iopub.status.idle":"2022-01-03T00:50:48.563233Z","shell.execute_reply.started":"2022-01-03T00:50:47.089435Z","shell.execute_reply":"2022-01-03T00:50:48.562506Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'","metadata":{"execution":{"iopub.status.busy":"2022-01-03T00:50:48.564616Z","iopub.execute_input":"2022-01-03T00:50:48.565663Z","iopub.status.idle":"2022-01-03T00:50:48.570296Z","shell.execute_reply.started":"2022-01-03T00:50:48.565629Z","shell.execute_reply":"2022-01-03T00:50:48.569246Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"path = Path().cwd().parent / 'input'\nfiles = list(path.rglob('*'))\nfiles","metadata":{"execution":{"iopub.status.busy":"2022-01-03T00:50:48.571854Z","iopub.execute_input":"2022-01-03T00:50:48.572314Z","iopub.status.idle":"2022-01-03T00:50:48.589868Z","shell.execute_reply.started":"2022-01-03T00:50:48.572276Z","shell.execute_reply":"2022-01-03T00:50:48.588981Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[PosixPath('/kaggle/input/tabular-playground-series-jan-2022'),\n PosixPath('/kaggle/input/tabular-playground-series-jan-2022/sample_submission.csv'),\n PosixPath('/kaggle/input/tabular-playground-series-jan-2022/train.csv'),\n PosixPath('/kaggle/input/tabular-playground-series-jan-2022/test.csv')]"},"metadata":{}}]},{"cell_type":"code","source":"train = pd.read_csv(files[2])\ntrain['date'] = pd.to_datetime(train['date'], errors='coerce')\ntrain = train.set_index('date')\n\ntest = pd.read_csv(files[3])\ntest['date'] = pd.to_datetime(test['date'], errors='coerce')\ntest = test.set_index('date')\n\ntrain\ntest","metadata":{"execution":{"iopub.status.busy":"2022-01-03T00:50:48.591740Z","iopub.execute_input":"2022-01-03T00:50:48.591978Z","iopub.status.idle":"2022-01-03T00:50:48.710193Z","shell.execute_reply.started":"2022-01-03T00:50:48.591950Z","shell.execute_reply":"2022-01-03T00:50:48.709422Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"            row_id  country       store         product  num_sold\ndate                                                             \n2015-01-01       0  Finland  KaggleMart      Kaggle Mug       329\n2015-01-01       1  Finland  KaggleMart      Kaggle Hat       520\n2015-01-01       2  Finland  KaggleMart  Kaggle Sticker       146\n2015-01-01       3  Finland  KaggleRama      Kaggle Mug       572\n2015-01-01       4  Finland  KaggleRama      Kaggle Hat       911\n...            ...      ...         ...             ...       ...\n2018-12-31   26293   Sweden  KaggleMart      Kaggle Hat       823\n2018-12-31   26294   Sweden  KaggleMart  Kaggle Sticker       250\n2018-12-31   26295   Sweden  KaggleRama      Kaggle Mug      1004\n2018-12-31   26296   Sweden  KaggleRama      Kaggle Hat      1441\n2018-12-31   26297   Sweden  KaggleRama  Kaggle Sticker       388\n\n[26298 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>country</th>\n      <th>store</th>\n      <th>product</th>\n      <th>num_sold</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-01</th>\n      <td>0</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Mug</td>\n      <td>329</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>1</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Hat</td>\n      <td>520</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>2</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Sticker</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>3</td>\n      <td>Finland</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Mug</td>\n      <td>572</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>4</td>\n      <td>Finland</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Hat</td>\n      <td>911</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>26293</td>\n      <td>Sweden</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Hat</td>\n      <td>823</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>26294</td>\n      <td>Sweden</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Sticker</td>\n      <td>250</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>26295</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Mug</td>\n      <td>1004</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>26296</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Hat</td>\n      <td>1441</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>26297</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Sticker</td>\n      <td>388</td>\n    </tr>\n  </tbody>\n</table>\n<p>26298 rows × 5 columns</p>\n</div>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"            row_id  country       store         product\ndate                                                   \n2019-01-01   26298  Finland  KaggleMart      Kaggle Mug\n2019-01-01   26299  Finland  KaggleMart      Kaggle Hat\n2019-01-01   26300  Finland  KaggleMart  Kaggle Sticker\n2019-01-01   26301  Finland  KaggleRama      Kaggle Mug\n2019-01-01   26302  Finland  KaggleRama      Kaggle Hat\n...            ...      ...         ...             ...\n2019-12-31   32863   Sweden  KaggleMart      Kaggle Hat\n2019-12-31   32864   Sweden  KaggleMart  Kaggle Sticker\n2019-12-31   32865   Sweden  KaggleRama      Kaggle Mug\n2019-12-31   32866   Sweden  KaggleRama      Kaggle Hat\n2019-12-31   32867   Sweden  KaggleRama  Kaggle Sticker\n\n[6570 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>country</th>\n      <th>store</th>\n      <th>product</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-01-01</th>\n      <td>26298</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Mug</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>26299</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Hat</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>26300</td>\n      <td>Finland</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Sticker</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>26301</td>\n      <td>Finland</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Mug</td>\n    </tr>\n    <tr>\n      <th>2019-01-01</th>\n      <td>26302</td>\n      <td>Finland</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Hat</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2019-12-31</th>\n      <td>32863</td>\n      <td>Sweden</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Hat</td>\n    </tr>\n    <tr>\n      <th>2019-12-31</th>\n      <td>32864</td>\n      <td>Sweden</td>\n      <td>KaggleMart</td>\n      <td>Kaggle Sticker</td>\n    </tr>\n    <tr>\n      <th>2019-12-31</th>\n      <td>32865</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Mug</td>\n    </tr>\n    <tr>\n      <th>2019-12-31</th>\n      <td>32866</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Hat</td>\n    </tr>\n    <tr>\n      <th>2019-12-31</th>\n      <td>32867</td>\n      <td>Sweden</td>\n      <td>KaggleRama</td>\n      <td>Kaggle Sticker</td>\n    </tr>\n  </tbody>\n</table>\n<p>6570 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Checking\n\ndef train_valid(df_wide):\n    train_dfs, train_ids = {}, {}\n    valid_dfs, valid_ids = {}, {}\n    for cat in df_wide['country'].unique():\n        for cat_ in df_wide['store'].unique():\n            for cat__ in df_wide['product'].unique():\n                mask = (df_wide['country']==cat) & (df_wide['store']==cat_) & (df_wide['product']==cat__)\n                df = df_wide[mask]\n                #train_ids[cat+cat_+cat__] = df['row_id']\n                df = df.groupby(['country', 'store', 'product']).resample('D').sum()['num_sold']\n                df = df.reset_index(level=[0,1,2], drop=True).squeeze()\n                df.name = cat+cat_+cat__\n                thresh = int(len(df)*0.8)\n                df_train = df.iloc[:thresh]\n                df_valid = df.iloc[thresh:]\n                train_dfs[cat+cat_+cat__] = df_train\n                valid_dfs[cat+cat_+cat__] = df_valid\n                print(df_wide[mask].shape[0] == (df_train.shape[0] + df_valid.shape[0])) \n    return train_dfs, valid_dfs\n\ntrain_dfs, valid_dfs = train_valid(train)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T00:50:48.711519Z","iopub.execute_input":"2022-01-03T00:50:48.711813Z","iopub.status.idle":"2022-01-03T00:50:49.041324Z","shell.execute_reply.started":"2022-01-03T00:50:48.711780Z","shell.execute_reply":"2022-01-03T00:50:49.040316Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"True\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n","output_type":"stream"}]},{"cell_type":"code","source":"class GA_Statsmodels():\n    def __init__(self, \n                 params, \n                 eval_func,\n                 eval_weights,\n                 #\n                 train_df,\n                 valid_df,\n                 #\n                 sel_tournsize=2,\n                 cx_uniform_prob=0.5, \n                 mut_shuffle_idx_prob=0.1, \n                 n_pop=10, \n                 n_gen=10, \n                 n_hof=1, \n                 cx_prob=0.5, \n                 mut_prob=0.1, \n                 n_jobs=1\n                ):\n        self.params = params\n        self.eval_func = eval_func\n        self.eval_weights = eval_weights\n        \n        self.train_df = train_df\n        self.valid_df = valid_df\n        \n        self.sel_tournsize = sel_tournsize\n        self.cx_uniform_prob = cx_uniform_prob\n        self.mut_shuffle_idx_prob = mut_shuffle_idx_prob\n        self.n_pop = n_pop\n        self.n_gen = n_gen\n        self.n_hof = n_hof\n        self.cx_prob = cx_prob\n        self.mut_prob = mut_prob\n        \n        self.n_jobs = n_jobs\n\n        self._pad_params()\n        self._create_fitness_and_indiv()\n        self._register_indiv_and_pop_generators()\n        self._register_eval_func()\n        self._register_selection_crossover_mutation_methods()\n\n    def _pad_params(self):\n        \"\"\"Pad params for crossover shuffle idx method\"\"\"\n        assert isinstance(self.params, dict), 'Params must be a dict, i.e. estimator.get_params()'\n        params_count = {k: len(v) for k,v in self.params.items()}\n        max_length, max_key = -99, ''\n        for k, v in params_count.items():\n            if v <= max_length:\n                continue\n            else:\n                max_key = k\n                max_length = v\n        assert isinstance(max_length, int), 'The max length between all params must be an int'\n        # cycle through params for max length param, otherwise infinite cycle\n        values_padded = (cycle(v) if k!=max_key else v for k,v in self.params.items())\n        values_padded = zip(*values_padded)  # ('a', 1, 14), ('b', 2, 16), ('c', 3, 16) ...\n        values_padded = zip(*values_padded)  # ('a', 'b', 'c'), (1, 2, 3), (14, 15, 16)...\n        padded_params = {}\n        for k, v in zip(self.params, values_padded):\n            padded_params[k] = v\n        self.padded_params = padded_params\n        print('Params padded')\n\n    def _create_fitness_and_indiv(self):\n        \"\"\"Create GA individual and fitness entities (classes)\"\"\"\n        ga_cr.create('Fitness', ga_b.Fitness, weights=self.eval_weights)\n        ga_cr.create('Individual', list, fitness=ga_cr.Fitness)\n        print('GA entities created')\n\n    def _gen_params_to_ga(self):\n        \"\"\"Generate index for each param for individual\"\"\"\n        max_dict = len(self.padded_params)\n        max_length = len(list(self.padded_params.values())[0])\n        idxs = [randint(0, max_length-1) for _ in range(max_dict)]\n        return idxs\n    \n    def _register_indiv_and_pop_generators(self):\n        \"\"\"Register GA individual and population generators\"\"\"\n        self.tb = ga_b.Toolbox()\n\n        if self.n_jobs > 1:\n            from multiprocessing import Pool\n            pool = Pool()\n            self.tb.register(\"map\", pool.map)\n\n        self.tb.register(\"individual\", ga_t.initIterate, ga_cr.Individual, self._gen_params_to_ga)\n        #print('indiv', self.tb.individual())\n        self.tb.register(\"population\", ga_t.initRepeat, list, self.tb.individual)\n        #print('population', self.tb.population(n=2))\n        print('GA entities\\' methods registered')\n        \n    def _register_eval_func(self):\n        \"\"\"Set GA evaluate individual function\"\"\"\n        self.tb.register(\"evaluate\",\n                        self.eval_func,\n                        padded_params=self.padded_params,\n                        train_df=self.train_df,\n                        valid_df=self.valid_df,\n                        )\n        #print(list(self.tb.evaluate(indiv) for indiv in self.tb.population(3)))\n        print('GA eval function registered')\n    \n    def _register_selection_crossover_mutation_methods(self):\n        self.tb.register(\"select\", ga_t.selTournament, tournsize=self.sel_tournsize)\n        self.tb.register(\"mate\", ga_t.cxUniform, indpb=self.cx_uniform_prob)\n        self.tb.register(\"mutate\", ga_t.mutShuffleIndexes, indpb=self.mut_shuffle_idx_prob)\n        print('GA sel-cx-mut methods registered')\n        \n    def run_ga_search(self):\n        \"\"\"GA Search\"\"\"\n        pop = self.tb.population(n=self.n_pop)\n        hof = ga_t.HallOfFame(self.n_hof)\n\n        # Stats stdout\n        stats = ga_t.Statistics(lambda ind: ind.fitness.values )\n        #stats1 = ga_t.Statistics(lambda ind: ind.fitness.values[0] )\n        #stats2 = ga_t.Statistics(lambda ind: ind.fitness.values[1] )\n        #stats3 = ga_t.Statistics(lambda ind: ind.fitness.values[2] )\n        stats = ga_t.MultiStatistics(accuracy=stats)\n        stats.register(\"avg\", np.mean)\n        #stats.register(\"std\", np.std)\n        #stats.register(\"min\", np.min)\n        #stats.register(\"max\", np.max)\n\n        # History\n        #hist = tools.History()\n        #toolbox.decorate(\"select\", hist.decorator)\n        #tb.decorate(\"mate\", hist.decorator)\n        #tb.decorate(\"mutate\", hist.decorator)\n        #hist.update(pop)\n\n        # GA Run\n        pop, log = ga_algo.eaSimple(pop, self.tb, cxpb=self.cx_prob, \n                                    mutpb=self.mut_prob, ngen=self.n_gen, \n                                    stats=stats, halloffame=hof, verbose=True)\n        \n        # Convert back params\n        hof_ = {}\n        for i in range(self.n_hof):\n            hof_['hof_' + str(i)] = self._ga_to_params(hof[i])\n\n        return pop, log, hof_\n    \n    def _ga_to_params(self, idx_params):\n        \"\"\"Convert back idx to params\"\"\"\n        res = {}\n        for (k,v), idx in zip(self.padded_params.items(), idx_params):\n            res[k] = v[idx]\n        return res","metadata":{"execution":{"iopub.status.busy":"2022-01-03T00:50:49.043685Z","iopub.execute_input":"2022-01-03T00:50:49.043906Z","iopub.status.idle":"2022-01-03T00:50:49.066475Z","shell.execute_reply.started":"2022-01-03T00:50:49.043880Z","shell.execute_reply":"2022-01-03T00:50:49.065516Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"helper = np.linspace(3, 50, 20).astype(int)\n\nts_params = {\n    'ar': np.linspace(0, 19, 20).astype(int),\n    'd': np.linspace(0, 19, 20).astype(int),\n    'ma': np.linspace(0, 19, 20).astype(int),\n    #'split': np.linspace(0.65, 0.9, num=10),\n    'seasonal': helper[(helper%2)==True],\n}\n\ndef ts_eval_indiv(individual, padded_params, train_df, valid_df):\n    \"\"\"Evaluate individual's genes (estimator's params)\"\"\"\n    # Params\n    p = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual)}\n    \n    # Data\n\n    # Model\n    try:\n        res = STLForecast(train_df, \n                          ARIMA, \n                          model_kwargs={'order': (p['ar'], p['d'], p['ma'])},\n                          seasonal=p['seasonal']\n                         ).fit()\n        forec = res.forecast(int(365*0.8))\n        forec.name = train_df.name + '_F'\n        valid = pd.merge(left=valid_df, right=forec, left_index=True, right_index=True)\n        # TODO errors metrics\n        err = mean_squared_error(valid.iloc[:, 0], valid.iloc[:, 1])\n        \n    except BaseException as e:\n        print('=> Error:', e)\n        return 1000000,\n\n    # Risk\n    #inputs = inputs.to(device)\n    #risk = mean(prod(net(inputs)*10, dim=1))\n    #if isnan(risk):\n    #    risk = 10\n    #else:\n    #    risk = float(risk)\n        \n    # Complexity\n    #compl = net.count_weights_biases()\n\n    return (err,)\n\nts_weights = (-1,)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T00:50:49.067654Z","iopub.execute_input":"2022-01-03T00:50:49.067883Z","iopub.status.idle":"2022-01-03T00:50:49.098655Z","shell.execute_reply.started":"2022-01-03T00:50:49.067853Z","shell.execute_reply":"2022-01-03T00:50:49.097825Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# testing\nnames = list(train_dfs.keys())\ntemp = train_dfs[names[0]]\n\nnames = list(valid_dfs.keys())\ntemp_ = valid_dfs[names[0]]\n# TODO loop each train dataset \n\nga_ts = GA_Statsmodels(ts_params, ts_eval_indiv, ts_weights, temp, temp_)\npop, log, hof = ga_ts.run_ga_search()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T00:50:49.928092Z","iopub.execute_input":"2022-01-03T00:50:49.928412Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Params padded\nGA entities created\nGA entities' methods registered\nGA eval function registered\nGA sel-cx-mut methods registered\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n  warn('Non-invertible starting MA parameters found.'\n/opt/conda/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n  warn('Non-invertible starting MA parameters found.'\n/opt/conda/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n  warn('Non-stationary starting autoregressive parameters'\n/opt/conda/lib/python3.7/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n  warn('Non-invertible starting MA parameters found.'\n/opt/conda/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n  warn('Non-invertible starting MA parameters found.'\n/opt/conda/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n  warn('Non-invertible starting MA parameters found.'\n/opt/conda/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n  warn('Non-invertible starting MA parameters found.'\n","output_type":"stream"}]},{"cell_type":"code","source":"list(hof['hof_0'].values())","metadata":{"execution":{"iopub.status.busy":"2022-01-02T23:32:48.063198Z","iopub.execute_input":"2022-01-02T23:32:48.063901Z","iopub.status.idle":"2022-01-02T23:32:48.07195Z","shell.execute_reply.started":"2022-01-02T23:32:48.063842Z","shell.execute_reply":"2022-01-02T23:32:48.070351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(hof['hof_0'].values())\nres = STLForecast(temp, \n                  ARIMA, \n                  model_kwargs={'order': list(hof['hof_0'].values())[:3] },\n                  seasonal=list(hof['hof_0'].values())[3],\n                 ).fit()\nforec = res.forecast(365)\nforec.name = temp.name + '_f'\n\nfig, ax = plt.subplots(figsize=(12,6))\n_ = ax.plot(temp)\n_ = ax.plot(temp_)\n_ = ax.plot(forec)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T23:32:05.475233Z","iopub.execute_input":"2022-01-02T23:32:05.475533Z","iopub.status.idle":"2022-01-02T23:32:06.639823Z","shell.execute_reply.started":"2022-01-02T23:32:05.475504Z","shell.execute_reply":"2022-01-02T23:32:06.638947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if False:\n    res = ARIMA(temp, (2,2,0)).fit(disp=0)\n    forec_periods = 24\n    forec, stderr, conf_int = res.forecast(forec_periods)\n    forec = pd.Series(forec, index=[temp.index.max()+pd.DateOffset(months=i+1) for i in range(forec_periods)])\n    forec\n\n    fig, ax = plt.subplots(figsize=(12,6))\n    _ = ax.plot(temp)\n    _ = ax.plot(forec)\n    \n    a = np.linspace(3, 50, 20).astype(int)\n    a\n    np.column_stack((\n        a,\n        (a%2)==True,\n        a//2,\n        (a//2)%2,\n        ((a//2)%2)==True,\n    ))\n    a[(a%2)==True]","metadata":{"execution":{"iopub.status.busy":"2022-01-02T23:07:04.025774Z","iopub.execute_input":"2022-01-02T23:07:04.026238Z","iopub.status.idle":"2022-01-02T23:07:04.035184Z","shell.execute_reply.started":"2022-01-02T23:07:04.026206Z","shell.execute_reply":"2022-01-02T23:07:04.034044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}