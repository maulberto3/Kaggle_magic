{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf66752f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:19:20.097808Z",
     "iopub.status.busy": "2022-01-15T07:19:20.096579Z",
     "iopub.status.idle": "2022-01-15T07:19:20.202739Z",
     "shell.execute_reply": "2022-01-15T07:19:20.203269Z",
     "shell.execute_reply.started": "2022-01-15T07:13:36.202063Z"
    },
    "papermill": {
     "duration": 0.126765,
     "end_time": "2022-01-15T07:19:20.203596",
     "exception": false,
     "start_time": "2022-01-15T07:19:20.076831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset -sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb278f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:19:20.237790Z",
     "iopub.status.busy": "2022-01-15T07:19:20.237111Z",
     "iopub.status.idle": "2022-01-15T07:19:20.239733Z",
     "shell.execute_reply": "2022-01-15T07:19:20.240175Z",
     "shell.execute_reply.started": "2022-01-15T07:13:36.343458Z"
    },
    "papermill": {
     "duration": 0.021792,
     "end_time": "2022-01-15T07:19:20.240356",
     "exception": false,
     "start_time": "2022-01-15T07:19:20.218564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8de4216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:19:20.274715Z",
     "iopub.status.busy": "2022-01-15T07:19:20.274048Z",
     "iopub.status.idle": "2022-01-15T07:19:21.382284Z",
     "shell.execute_reply": "2022-01-15T07:19:21.381269Z",
     "shell.execute_reply.started": "2022-01-15T07:13:36.358198Z"
    },
    "papermill": {
     "duration": 1.125332,
     "end_time": "2022-01-15T07:19:21.382461",
     "exception": false,
     "start_time": "2022-01-15T07:19:20.257129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Device: cpu\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda import is_available\n",
    "\n",
    "DEVI = \"cuda\" if is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(\"==> Device:\", DEVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e87f14e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:19:21.418253Z",
     "iopub.status.busy": "2022-01-15T07:19:21.417470Z",
     "iopub.status.idle": "2022-01-15T07:19:21.420571Z",
     "shell.execute_reply": "2022-01-15T07:19:21.420056Z",
     "shell.execute_reply.started": "2022-01-15T07:13:36.374855Z"
    },
    "papermill": {
     "duration": 0.022683,
     "end_time": "2022-01-15T07:19:21.420716",
     "exception": false,
     "start_time": "2022-01-15T07:19:21.398033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LR = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ede4f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:19:21.456914Z",
     "iopub.status.busy": "2022-01-15T07:19:21.455998Z",
     "iopub.status.idle": "2022-01-15T07:19:21.464236Z",
     "shell.execute_reply": "2022-01-15T07:19:21.464890Z",
     "shell.execute_reply.started": "2022-01-15T07:13:36.390381Z"
    },
    "papermill": {
     "duration": 0.028926,
     "end_time": "2022-01-15T07:19:21.465067",
     "exception": false,
     "start_time": "2022-01-15T07:19:21.436141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd26c382b50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import manual_seed\n",
    "manual_seed(16)\n",
    "from random import seed\n",
    "seed(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4fbdd6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:19:21.499477Z",
     "iopub.status.busy": "2022-01-15T07:19:21.498465Z",
     "iopub.status.idle": "2022-01-15T07:19:21.957235Z",
     "shell.execute_reply": "2022-01-15T07:19:21.956666Z",
     "shell.execute_reply.started": "2022-01-15T07:13:36.406628Z"
    },
    "papermill": {
     "duration": 0.477066,
     "end_time": "2022-01-15T07:19:21.957400",
     "exception": false,
     "start_time": "2022-01-15T07:19:21.480334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 28, 28]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import load, long\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "class DS(Dataset):\n",
    "    def __init__(self, maps, labels) -> None:\n",
    "        self.maps = maps\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.maps[idx]\n",
    "        #X = X.reshape(1, -1)\n",
    "        X = X.unsqueeze(0)\n",
    "        y = self.labels[idx]\n",
    "        return X.to(DEVI, dtype=pt_float), y.to(DEVI, dtype=long)\n",
    "\n",
    "# Data\n",
    "X_train, y_train = load('/kaggle/input/pytorch-mnist/training.pt')\n",
    "X_test, y_test = load('/kaggle/input/pytorch-mnist/test.pt')\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4333db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:19:21.999036Z",
     "iopub.status.busy": "2022-01-15T07:19:21.998016Z",
     "iopub.status.idle": "2022-01-15T07:19:22.121461Z",
     "shell.execute_reply": "2022-01-15T07:19:22.122075Z",
     "shell.execute_reply.started": "2022-01-15T07:13:36.473644Z"
    },
    "papermill": {
     "duration": 0.148631,
     "end_time": "2022-01-15T07:19:22.122303",
     "exception": false,
     "start_time": "2022-01-15T07:19:21.973672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dry run: torch.Size([1, 10])'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import float as pt_float, ones\n",
    "\n",
    "class NET(nn.Module):\n",
    "    def __init__(self, \n",
    "                 l1, k1, a1, l2, k2, a2, l3, k3, a3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.LazyConv2d(l1, k1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.__getattribute__(a1)())\n",
    "        \n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.LazyConv2d(l2, k2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.__getattribute__(a2)())\n",
    "\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.LazyConv2d(l3, k3),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.__getattribute__(a3)())\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(10),\n",
    "            nn.LogSoftmax(dim=-1))\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            self.cnn1,\n",
    "            self.cnn2,\n",
    "            self.cnn3,\n",
    "            self.out\n",
    "        )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        return self.model(x)\n",
    "    \n",
    "    def count_weights_biases(self):\n",
    "        return int(sum(p.numel() for p in self.parameters() if p.requires_grad))\n",
    "    \n",
    "net = NET(10, 2, 'SELU', 10, 2, 'SELU', 10, 2, 'SELU').to(DEVI)\n",
    "f'Dry run: {net(ones(1, 1, 28, 28).to(DEVI, dtype=pt_float)).shape}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a42e48e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:19:22.159915Z",
     "iopub.status.busy": "2022-01-15T07:19:22.158800Z",
     "iopub.status.idle": "2022-01-15T07:19:22.189529Z",
     "shell.execute_reply": "2022-01-15T07:19:22.190083Z",
     "shell.execute_reply.started": "2022-01-15T07:13:36.506898Z"
    },
    "papermill": {
     "duration": 0.051105,
     "end_time": "2022-01-15T07:19:22.190259",
     "exception": false,
     "start_time": "2022-01-15T07:19:22.139154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GA_Pytorch():\n",
    "    def __init__(self, \n",
    "                 params, \n",
    "                 eval_func,\n",
    "                 eval_weights,\n",
    "                 X_train,\n",
    "                 X_test,\n",
    "                 y_train,\n",
    "                 y_test,\n",
    "                 batch_size=64,\n",
    "                 lr=0.0001,\n",
    "                 sel_tournsize=2, \n",
    "                 cx_uniform_prob=0.5, \n",
    "                 mut_shuffle_idx_prob=0.1, \n",
    "                 n_pop=30, \n",
    "                 n_gen=15, \n",
    "                 n_hof=5, \n",
    "                 cx_prob=0.5, \n",
    "                 mut_prob=0.1, \n",
    "                 n_jobs=1\n",
    "                ):\n",
    "        self.params = params\n",
    "        self.eval_func = eval_func\n",
    "        self.eval_weights = eval_weights\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.sel_tournsize = sel_tournsize\n",
    "        self.cx_uniform_prob = cx_uniform_prob\n",
    "        self.mut_shuffle_idx_prob = mut_shuffle_idx_prob\n",
    "        self.n_pop = n_pop\n",
    "        self.n_gen = n_gen\n",
    "        self.n_hof = n_hof\n",
    "        self.cx_prob = cx_prob\n",
    "        self.mut_prob = mut_prob\n",
    "        \n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        self._pad_params()\n",
    "        self._create_fitness_and_indiv()\n",
    "        self._register_indiv_and_pop_generators()\n",
    "        self._register_eval_func()\n",
    "        self._register_selection_crossover_mutation_methods()\n",
    "\n",
    "    def _pad_params(self):\n",
    "        \"\"\"Pad params for crossover shuffle idx method\"\"\"\n",
    "        assert isinstance(self.params, dict), 'Params must be a dict, i.e. estimator.get_params()'\n",
    "        params_count = {k: len(v) for k,v in self.params.items()}\n",
    "        max_length, max_key = -99, ''\n",
    "        for k, v in params_count.items():\n",
    "            if v <= max_length:\n",
    "                continue\n",
    "            else:\n",
    "                max_key = k\n",
    "                max_length = v\n",
    "        assert isinstance(max_length, int), 'The max length between all params must be an int'\n",
    "        # cycle through params for max length param, otherwise infinite cycle\n",
    "        values_padded = (cycle(v) if k!=max_key else v for k,v in self.params.items())\n",
    "        values_padded = zip(*values_padded)  # ('a', 1, 14), ('b', 2, 16), ('c', 3, 16) ...\n",
    "        values_padded = zip(*values_padded)  # ('a', 'b', 'c'), (1, 2, 3), (14, 15, 16)...\n",
    "        padded_params = {}\n",
    "        for k, v in zip(self.params, values_padded):\n",
    "            padded_params[k] = v\n",
    "        self.padded_params = padded_params\n",
    "        print('Params padded')\n",
    "\n",
    "    def _create_fitness_and_indiv(self):\n",
    "        \"\"\"Create GA individual and fitness entities (classes)\"\"\"\n",
    "        ga_cr.create('Fitness', ga_b.Fitness, weights=self.eval_weights)\n",
    "        ga_cr.create('Individual', list, fitness=ga_cr.Fitness)\n",
    "        print('GA entities created')\n",
    "\n",
    "    def _gen_params_to_ga(self):\n",
    "        \"\"\"Generate index for each param for individual\"\"\"\n",
    "        max_dict = len(self.padded_params)\n",
    "        max_length = len(list(self.padded_params.values())[0])\n",
    "        idxs = [randint(0, max_length-1) for _ in range(max_dict)]\n",
    "        return idxs\n",
    "    \n",
    "    def _register_indiv_and_pop_generators(self):\n",
    "        \"\"\"Register GA individual and population generators\"\"\"\n",
    "        self.tb = ga_b.Toolbox()\n",
    "\n",
    "        if self.n_jobs > 1:\n",
    "            from multiprocessing import Pool\n",
    "            pool = Pool()\n",
    "            self.tb.register(\"map\", pool.map)\n",
    "\n",
    "        self.tb.register(\"individual\", ga_t.initIterate, ga_cr.Individual, self._gen_params_to_ga)\n",
    "        self.tb.register(\"population\", ga_t.initRepeat, list, self.tb.individual)\n",
    "        print('GA entities\\' methods registered')\n",
    "        \n",
    "    def _register_eval_func(self):\n",
    "        \"\"\"Set GA evaluate individual function\"\"\"\n",
    "        self.tb.register(\"evaluate\",\n",
    "                        self.eval_func,\n",
    "                        padded_params=self.padded_params,\n",
    "                        X_train=self.X_train,\n",
    "                        X_test=self.X_test, \n",
    "                        y_train=self.y_train, \n",
    "                        y_test=self.y_test,\n",
    "                        batch_size=self.batch_size,\n",
    "                        lr=self.lr)\n",
    "        #print(list(self.tb.evaluate(indiv) for indiv in self.tb.population(3)))\n",
    "        print('GA eval function registered')\n",
    "    \n",
    "    def _register_selection_crossover_mutation_methods(self):\n",
    "        self.tb.register(\"select\", ga_t.selTournament, tournsize=self.sel_tournsize)\n",
    "        self.tb.register(\"mate\", ga_t.cxUniform, indpb=self.cx_uniform_prob)\n",
    "        self.tb.register(\"mutate\", ga_t.mutShuffleIndexes, indpb=self.mut_shuffle_idx_prob)\n",
    "        print('GA sel-cx-mut methods registered')\n",
    "        \n",
    "    def run_ga_search(self):\n",
    "        \"\"\"GA Search\"\"\"\n",
    "        pop = self.tb.population(n=self.n_pop)\n",
    "        hof = ga_t.HallOfFame(self.n_hof)\n",
    "\n",
    "        # Stats stdout\n",
    "        #stats = ga_t.Statistics(lambda ind: ind.fitness.values )\n",
    "        stats1 = ga_t.Statistics(lambda ind: ind.fitness.values[0] )\n",
    "        stats2 = ga_t.Statistics(lambda ind: ind.fitness.values[1] )\n",
    "        stats3 = ga_t.Statistics(lambda ind: ind.fitness.values[2] )\n",
    "        stats = ga_t.MultiStatistics(accuracy=stats1, risk=stats2, complexity=stats3)\n",
    "        stats.register(\"avg\", mean)\n",
    "        #stats.register(\"std\", np.std)\n",
    "        #stats.register(\"min\", np.min)\n",
    "        #stats.register(\"max\", np.max)\n",
    "\n",
    "        # History\n",
    "        #hist = tools.History()\n",
    "        #toolbox.decorate(\"select\", hist.decorator)\n",
    "        #tb.decorate(\"mate\", hist.decorator)\n",
    "        #tb.decorate(\"mutate\", hist.decorator)\n",
    "        #hist.update(pop)\n",
    "\n",
    "        # GA Run\n",
    "        pop, log = ga_algo.eaSimple(pop, self.tb, cxpb=self.cx_prob, \n",
    "                                    mutpb=self.mut_prob, ngen=self.n_gen, \n",
    "                                    stats=stats, halloffame=hof, verbose=True)\n",
    "        \n",
    "        # Convert back params\n",
    "        hof_ = {}\n",
    "        for i in range(self.n_hof):\n",
    "            hof_['hof_' + str(i)] = self._ga_to_params(hof[i])\n",
    "\n",
    "        return pop, log, hof_\n",
    "    \n",
    "    def _ga_to_params(self, idx_params):\n",
    "        \"\"\"Convert back idx to params\"\"\"\n",
    "        res = {}\n",
    "        for (k,v), idx in zip(self.padded_params.items(), idx_params):\n",
    "            res[k] = v[idx]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140ce1ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:19:22.227602Z",
     "iopub.status.busy": "2022-01-15T07:19:22.226541Z",
     "iopub.status.idle": "2022-01-15T07:19:22.248703Z",
     "shell.execute_reply": "2022-01-15T07:19:22.249268Z",
     "shell.execute_reply.started": "2022-01-15T07:13:36.541115Z"
    },
    "papermill": {
     "duration": 0.042736,
     "end_time": "2022-01-15T07:19:22.249450",
     "exception": false,
     "start_time": "2022-01-15T07:19:22.206714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import mean, linspace, inf\n",
    "\n",
    "net_params = {\n",
    "    'l1': linspace(1,20,20).astype(int),\n",
    "    'k1': linspace(1,20,20).astype(int),\n",
    "    'a1': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n",
    "    'l2': linspace(1,20,20).astype(int),\n",
    "    'k2': linspace(1,20,20).astype(int),\n",
    "    'a2': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n",
    "    'l3': linspace(1,20,20).astype(int),\n",
    "    'k3': linspace(1,20,20).astype(int),\n",
    "    'a3': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n",
    "}\n",
    "\n",
    "def net_eval_indiv(individual, padded_params, X_train, X_test, y_train, y_test, batch_size, lr):\n",
    "    \"\"\"Evaluate individual's genes (estimator's params)\"\"\"\n",
    "\n",
    "    # Params\n",
    "    indiv_params = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual)}\n",
    "    \n",
    "    # Net\n",
    "    net = NET(**indiv_params).to(DEVI)\n",
    "    try:\n",
    "        net(ones(1,1,28,28).to(DEVI))\n",
    "    except BaseException as e:\n",
    "        print('=> Possible Arch Error:', e)\n",
    "        return (0.01, (1/10)**10, inf)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Train\n",
    "    train_ds = DS(X_train, y_train)  # TODO refactor out\n",
    "    train_dl = DataLoader(train_ds,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=2,\n",
    "                        drop_last=True,\n",
    "                         )\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for i, (inputs, labels) in enumerate(train_dl):\n",
    "            if i <= 100:\n",
    "                outputs = net(inputs.to(DEVI))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(outputs, labels).mean()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, predicted = pt_max(outputs.data, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    # Eval\n",
    "    with no_grad():\n",
    "        net = net.eval()\n",
    "        test_ds = DS(X_test, y_test)  # TODO refactor out\n",
    "        test_dl = DataLoader(test_ds,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=True)\n",
    "        #running_loss = []\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        for i, (inputs, labels) in enumerate(test_dl):\n",
    "            if i <= 50:\n",
    "                outputs = net(inputs.to(DEVI))\n",
    "\n",
    "                _, predicted = pt_max(outputs.data, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "                test_accuracy = test_correct / test_total * 100\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    # Risk\n",
    "    risk = median(prod(net(inputs).exp()*10, dim=1))\n",
    "    if isnan(risk):\n",
    "        risk = 10\n",
    "    else:\n",
    "        risk = float(risk)\n",
    "        \n",
    "    # Complexity\n",
    "    compl = net.count_weights_biases()\n",
    "\n",
    "    return (test_accuracy, risk, compl,)\n",
    "\n",
    "net_weights = (1, -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36c6787a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:19:22.285850Z",
     "iopub.status.busy": "2022-01-15T07:19:22.284916Z",
     "iopub.status.idle": "2022-01-15T07:44:47.594521Z",
     "shell.execute_reply": "2022-01-15T07:44:47.595055Z",
     "shell.execute_reply.started": "2022-01-15T07:13:36.567918Z"
    },
    "papermill": {
     "duration": 1525.329467,
     "end_time": "2022-01-15T07:44:47.595237",
     "exception": false,
     "start_time": "2022-01-15T07:19:22.265770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params padded\n",
      "GA entities created\n",
      "GA entities' methods registered\n",
      "GA eval function registered\n",
      "GA sel-cx-mut methods registered\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (9 x 9). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Expected more than 1 value per channel when training, got input size torch.Size([1, 14, 1, 1])\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (3 x 3). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (5 x 5). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (2 x 2). Kernel size: (17 x 17). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (13 x 13). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (10 x 10). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (15 x 15). Kernel size: (17 x 17). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Expected more than 1 value per channel when training, got input size torch.Size([1, 4, 1, 1])\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (13 x 13). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (3 x 3). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (12 x 12). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (5 x 5). Kernel size: (12 x 12). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (12 x 12). Kernel size can't be greater than actual input size\n",
      "   \t      \t       accuracy       \t      complexity      \t             risk             \n",
      "   \t      \t----------------------\t----------------------\t------------------------------\n",
      "gen\tnevals\tavg    \tgen\tnevals\tavg\tgen\tnevals\tavg     \tgen\tnevals\n",
      "0  \t30    \t22.9414\t0  \t30    \tinf\t0  \t30    \t0.183297\t0  \t30    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (17 x 17). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (6 x 6). Kernel size: (13 x 13). Kernel size can't be greater than actual input size\n",
      "1  \t14    \t34.0662\t1  \t14    \tinf\t1  \t14    \t0.287688\t1  \t14    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (18 x 18). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (11 x 11). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (17 x 17). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (12 x 12). Kernel size: (13 x 13). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (15 x 15). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Expected more than 1 value per channel when training, got input size torch.Size([1, 3, 1, 1])\n",
      "2  \t21    \t40.9368\t2  \t21    \tinf\t2  \t21    \t0.249693\t2  \t21    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (9 x 9). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (11 x 11). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "3  \t17    \t52.3247\t3  \t17    \tinf\t3  \t17    \t0.176337\t3  \t17    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (10 x 10). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "4  \t15    \t64.0935\t4  \t15    \tinf\t4  \t15    \t0.0919738\t4  \t15    \n",
      "5  \t18    \t70.7373\t5  \t18    \t36822.9\t5  \t18    \t0.0207017\t5  \t18    \n",
      "6  \t17    \t72.5419\t6  \t17    \t48354.9\t6  \t17    \t0.0416877\t6  \t17    \n",
      "7  \t19    \t75.6464\t7  \t19    \t54319.3\t7  \t19    \t0.0376058\t7  \t19    \n",
      "8  \t19    \t80.3687\t8  \t19    \t67025.5\t8  \t19    \t0.0256571\t8  \t19    \n",
      "9  \t11    \t82.5858\t9  \t11    \t77409.7\t9  \t11    \t0.00715648\t9  \t11    \n",
      "10 \t22    \t84.0074\t10 \t22    \t80010  \t10 \t22    \t3.55708e-08\t10 \t22    \n",
      "11 \t14    \t82.7717\t11 \t14    \t74717.5\t11 \t14    \t0.014576   \t11 \t14    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (15 x 15). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "12 \t15    \t80.1208\t12 \t15    \tinf    \t12 \t15    \t0.0122945  \t12 \t15    \n",
      "13 \t11    \t85.1328\t13 \t11    \t78762.1\t13 \t11    \t3.2424e-16 \t13 \t11    \n",
      "14 \t12    \t85.2022\t14 \t12    \t75309.8\t14 \t12    \t1.90204e-18\t14 \t12    \n",
      "15 \t9     \t85.3799\t15 \t9     \t73158.8\t15 \t9     \t3.77678e-18\t15 \t9     \n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "from deap import creator as ga_cr, base as ga_b, algorithms as ga_algo, tools as ga_t\n",
    "from random import randint\n",
    "from numpy import mean\n",
    "from torch.optim import Adam\n",
    "from torch import max as pt_max, no_grad, median, prod, isnan\n",
    "\n",
    "net_ga_params = GA_Pytorch(net_params, \n",
    "                           net_eval_indiv, \n",
    "                           net_weights,\n",
    "                           X_train, \n",
    "                           X_test, \n",
    "                           y_train, \n",
    "                           y_test)\n",
    "pop, log, hof = net_ga_params.run_ga_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c41a05b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:44:47.653942Z",
     "iopub.status.busy": "2022-01-15T07:44:47.653241Z",
     "iopub.status.idle": "2022-01-15T07:44:47.731081Z",
     "shell.execute_reply": "2022-01-15T07:44:47.731560Z",
     "shell.execute_reply.started": "2022-01-15T07:14:14.845687Z"
    },
    "papermill": {
     "duration": 0.110306,
     "end_time": "2022-01-15T07:44:47.731734",
     "exception": false,
     "start_time": "2022-01-15T07:44:47.621428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hof_0</th>\n",
       "      <th>hof_1</th>\n",
       "      <th>hof_2</th>\n",
       "      <th>hof_3</th>\n",
       "      <th>hof_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>l1</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2</th>\n",
       "      <td>Softsign</td>\n",
       "      <td>Softsign</td>\n",
       "      <td>CELU</td>\n",
       "      <td>Softsign</td>\n",
       "      <td>CELU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l3</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a3</th>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hof_0     hof_1 hof_2     hof_3 hof_4\n",
       "l1        14        14    14        14    14\n",
       "k1         1         1     1         5     5\n",
       "a1      SELU      SELU  SELU      SELU  SELU\n",
       "l2        18        17    18        17    17\n",
       "k2         3         3     3         3     3\n",
       "a2  Softsign  Softsign  CELU  Softsign  CELU\n",
       "l3        18        18    18        18    18\n",
       "k3         4         4     4         4     4\n",
       "a3      SELU      SELU  SELU      SELU  SELU"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['best_params.json']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving params\n",
    "\n",
    "from pandas import DataFrame\n",
    "from joblib import dump, load\n",
    "\n",
    "DataFrame(hof)\n",
    "dump(hof, 'best_params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0363a491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T07:44:47.790970Z",
     "iopub.status.busy": "2022-01-15T07:44:47.790257Z",
     "iopub.status.idle": "2022-01-15T07:50:55.520188Z",
     "shell.execute_reply": "2022-01-15T07:50:55.519477Z",
     "shell.execute_reply.started": "2022-01-15T07:15:54.790478Z"
    },
    "papermill": {
     "duration": 367.761481,
     "end_time": "2022-01-15T07:50:55.520347",
     "exception": false,
     "start_time": "2022-01-15T07:44:47.758866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN 89.85 % => TEST 96.18 %\n",
      "TRAIN 95.04 % => TEST 97.40 %\n",
      "TRAIN 95.83 % => TEST 97.27 %\n",
      "TRAIN 96.27 % => TEST 98.09 %\n",
      "TRAIN 96.51 % => TEST 97.80 %\n"
     ]
    }
   ],
   "source": [
    "# Full train\n",
    "EPOCHS = 5\n",
    "\n",
    "# Params\n",
    "params = load('best_params.json')['hof_0']\n",
    "\n",
    "# Net\n",
    "net = NET(**params).to(DEVI)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(net.parameters(), lr=LR)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Data\n",
    "train_ds = DS(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, \n",
    "               batch_size=BATCH_SIZE, \n",
    "               num_workers=2,\n",
    "               drop_last=True,\n",
    "               shuffle=True)\n",
    "\n",
    "test_ds = DS(X_test, y_test)\n",
    "test_dl = DataLoader(test_ds,\n",
    "               batch_size=BATCH_SIZE, \n",
    "               num_workers=2,\n",
    "               drop_last=True,\n",
    "               shuffle=True)\n",
    "\n",
    "# Train\n",
    "for epoch in range(EPOCHS):\n",
    "    net = net.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for i, (inputs, labels) in enumerate(train_dl):\n",
    "        outputs = net(inputs.to(DEVI))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels.to(DEVI)).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = pt_max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "    print(f'TRAIN {train_correct / train_total * 100:^5.2f} %', end=' ')\n",
    "    \n",
    "    # Eval\n",
    "    with no_grad():\n",
    "        net = net.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        for i, (inputs, labels) in enumerate(test_dl):\n",
    "            outputs = net(inputs.to(DEVI))\n",
    "            _, predicted = pt_max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "            test_accuracy = test_correct / test_total * 100\n",
    "    print(f'=> TEST {test_accuracy:^5.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5412a",
   "metadata": {
    "papermill": {
     "duration": 0.030779,
     "end_time": "2022-01-15T07:50:55.582332",
     "exception": false,
     "start_time": "2022-01-15T07:50:55.551553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4c561",
   "metadata": {
    "papermill": {
     "duration": 0.030361,
     "end_time": "2022-01-15T07:50:55.643769",
     "exception": false,
     "start_time": "2022-01-15T07:50:55.613408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c87c478",
   "metadata": {
    "papermill": {
     "duration": 0.031706,
     "end_time": "2022-01-15T07:50:55.705999",
     "exception": false,
     "start_time": "2022-01-15T07:50:55.674293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60709ac9",
   "metadata": {
    "papermill": {
     "duration": 0.030092,
     "end_time": "2022-01-15T07:50:55.767444",
     "exception": false,
     "start_time": "2022-01-15T07:50:55.737352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f33f571",
   "metadata": {
    "papermill": {
     "duration": 0.030785,
     "end_time": "2022-01-15T07:50:55.828689",
     "exception": false,
     "start_time": "2022-01-15T07:50:55.797904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1906.073193,
   "end_time": "2022-01-15T07:50:56.674267",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-15T07:19:10.601074",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
