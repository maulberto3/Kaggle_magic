{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac7627b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:52:37.381160Z",
     "iopub.status.busy": "2022-03-24T00:52:37.380474Z",
     "iopub.status.idle": "2022-03-24T00:52:37.480471Z",
     "shell.execute_reply": "2022-03-24T00:52:37.481117Z",
     "shell.execute_reply.started": "2022-03-23T22:52:46.527705Z"
    },
    "papermill": {
     "duration": 0.128564,
     "end_time": "2022-03-24T00:52:37.481432",
     "exception": false,
     "start_time": "2022-03-24T00:52:37.352868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset -sf\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a18cd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:52:37.513405Z",
     "iopub.status.busy": "2022-03-24T00:52:37.512699Z",
     "iopub.status.idle": "2022-03-24T00:52:38.683233Z",
     "shell.execute_reply": "2022-03-24T00:52:38.682546Z",
     "shell.execute_reply.started": "2022-03-23T22:52:46.642225Z"
    },
    "papermill": {
     "duration": 1.187069,
     "end_time": "2022-03-24T00:52:38.683377",
     "exception": false,
     "start_time": "2022-03-24T00:52:37.496308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Device: cpu\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda import is_available\n",
    "\n",
    "DEVI = \"cuda\" if is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(\"==> Device:\", DEVI)\n",
    "\n",
    "# Disabling this I get more resilient results, i.e. robust to any initialization\n",
    "# from torch import manual_seed\n",
    "# manual_seed(16)\n",
    "# from random import seed\n",
    "# seed(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f83beef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:52:38.718995Z",
     "iopub.status.busy": "2022-03-24T00:52:38.718328Z",
     "iopub.status.idle": "2022-03-24T00:52:38.720434Z",
     "shell.execute_reply": "2022-03-24T00:52:38.720941Z",
     "shell.execute_reply.started": "2022-03-23T22:53:17.404592Z"
    },
    "papermill": {
     "duration": 0.02329,
     "end_time": "2022-03-24T00:52:38.721133",
     "exception": false,
     "start_time": "2022-03-24T00:52:38.697843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A few HPs\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6956048d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:52:38.755934Z",
     "iopub.status.busy": "2022-03-24T00:52:38.755240Z",
     "iopub.status.idle": "2022-03-24T00:52:39.179698Z",
     "shell.execute_reply": "2022-03-24T00:52:39.178729Z",
     "shell.execute_reply.started": "2022-03-23T22:54:51.443498Z"
    },
    "papermill": {
     "duration": 0.444185,
     "end_time": "2022-03-24T00:52:39.179852",
     "exception": false,
     "start_time": "2022-03-24T00:52:38.735667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 28, 28]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "from torch import load\n",
    "\n",
    "X_train, y_train = load('/kaggle/input/pytorch-mnist/training.pt')\n",
    "X_test, y_test = load('/kaggle/input/pytorch-mnist/test.pt')\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152e9bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:52:39.212266Z",
     "iopub.status.busy": "2022-03-24T00:52:39.211542Z",
     "iopub.status.idle": "2022-03-24T00:52:39.218795Z",
     "shell.execute_reply": "2022-03-24T00:52:39.219384Z",
     "shell.execute_reply.started": "2022-03-23T22:54:52.312746Z"
    },
    "papermill": {
     "duration": 0.025172,
     "end_time": "2022-03-24T00:52:39.219585",
     "exception": false,
     "start_time": "2022-03-24T00:52:39.194413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset class (how to get samples from dataset, i.e. idx-style)\n",
    "\n",
    "from torch import nn, load\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DS(Dataset):\n",
    "    def __init__(self, maps, labels) -> None:\n",
    "        self.maps = maps\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.maps[idx]\n",
    "        #X = X.reshape(1, -1)\n",
    "        X = X.unsqueeze(0)\n",
    "        y = self.labels[idx]\n",
    "        return X.to(DEVI, dtype=pt_float), y.to(DEVI, dtype=long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7bb32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:52:39.251745Z",
     "iopub.status.busy": "2022-03-24T00:52:39.251103Z",
     "iopub.status.idle": "2022-03-24T00:52:39.267970Z",
     "shell.execute_reply": "2022-03-24T00:52:39.268608Z",
     "shell.execute_reply.started": "2022-03-23T22:55:06.651925Z"
    },
    "papermill": {
     "duration": 0.034663,
     "end_time": "2022-03-24T00:52:39.268780",
     "exception": false,
     "start_time": "2022-03-24T00:52:39.234117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5923),\n",
       " (1, 6742),\n",
       " (2, 5958),\n",
       " (3, 6131),\n",
       " (4, 5842),\n",
       " (5, 5421),\n",
       " (6, 5918),\n",
       " (7, 6265),\n",
       " (8, 5851),\n",
       " (9, 5949)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.WeightedRandomSampler at 0x7fb1871a87d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small utility for equal sampling while training\n",
    "\n",
    "from numpy import bincount\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# balanced sampler\n",
    "counts = bincount(y_train)\n",
    "labels_weights = 1. / counts\n",
    "list(zip(range(10), counts))\n",
    "weights = labels_weights[y_train]\n",
    "ws = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0f18ef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:52:39.308503Z",
     "iopub.status.busy": "2022-03-24T00:52:39.307778Z",
     "iopub.status.idle": "2022-03-24T00:52:39.461976Z",
     "shell.execute_reply": "2022-03-24T00:52:39.461446Z",
     "shell.execute_reply.started": "2022-03-23T23:02:22.751274Z"
    },
    "papermill": {
     "duration": 0.178098,
     "end_time": "2022-03-24T00:52:39.462155",
     "exception": false,
     "start_time": "2022-03-24T00:52:39.284057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Before 1st forward => no weights (connections between layers) initialized:'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "NET(\n",
       "  (cnn1): Sequential(\n",
       "    (0): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): SELU()\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (cnn4): Sequential(\n",
       "    (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       "    (2): LogSoftmax(dim=-1)\n",
       "  )\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): SELU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       "      (2): LogSoftmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'After 1st forward => weights (connections between layers) initialized:'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "NET(\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): SELU()\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (cnn4): Sequential(\n",
       "    (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=5760, out_features=10, bias=True)\n",
       "    (2): LogSoftmax(dim=-1)\n",
       "  )\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): SELU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=5760, out_features=10, bias=True)\n",
       "      (2): LogSoftmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'This LAZY PyTorch functionality is what I take advantage of with Genetic \\nAlgorithms (GA), simply put: I use GA for hyperparameter tuning.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (LAZY) Net\n",
    "\n",
    "from torch import float as pt_float, ones\n",
    "\n",
    "class NET(nn.Module):\n",
    "    def __init__(self, l1, k1, a1, l2, k2, a2, l3, k3, a3, l4, k4, a4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.LazyConv2d(l1, k1),  # lazy module...\n",
    "            nn.Dropout(0.5),\n",
    "            nn.__getattribute__(a1)())\n",
    "        \n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.LazyBatchNorm2d(), # lazy module...\n",
    "            nn.LazyConv2d(l2, k2), # lazy module... and so on\n",
    "            nn.Dropout(0.5),  # Heavy anti-overfitting just in case...\n",
    "            nn.__getattribute__(a2)())\n",
    "\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.LazyConv2d(l3, k3),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.__getattribute__(a3)())\n",
    "\n",
    "        self.cnn4 = nn.Sequential(\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.LazyConv2d(l4, k4),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.__getattribute__(a4)())\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(10),\n",
    "            nn.LogSoftmax(dim=-1))\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            self.cnn1,\n",
    "            self.cnn2,\n",
    "            self.cnn3,\n",
    "            self.cnn4,\n",
    "            self.out\n",
    "        )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        return self.model(x)\n",
    "    \n",
    "    def count_weights_biases(self):\n",
    "        return int(sum(p.numel() for p in self.parameters() if p.requires_grad))\n",
    "    \n",
    "\n",
    "net = NET(10, 2, 'SELU', 10, 2, 'SELU', 10, 2, 'SELU', 10, 2, 'SELU', ).to(DEVI)\n",
    "f'Before 1st forward => no weights (connections between layers) initialized:'\n",
    "net\n",
    "f'After 1st forward => weights (connections between layers) initialized:'\n",
    "_ = net(ones(1, 1, 28, 28))\n",
    "net\n",
    "\n",
    "\"\"\"This LAZY PyTorch functionality is what I take advantage of with Genetic \n",
    "Algorithms (GA), simply put: I use GA for hyperparameter tuning.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618cc907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:52:39.501134Z",
     "iopub.status.busy": "2022-03-24T00:52:39.499953Z",
     "iopub.status.idle": "2022-03-24T00:52:39.531667Z",
     "shell.execute_reply": "2022-03-24T00:52:39.532407Z",
     "shell.execute_reply.started": "2022-03-23T23:15:06.083533Z"
    },
    "papermill": {
     "duration": 0.053287,
     "end_time": "2022-03-24T00:52:39.532591",
     "exception": false,
     "start_time": "2022-03-24T00:52:39.479304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom class to put things in order\n",
    "\n",
    "class GA_Pytorch():\n",
    "    def __init__(self, \n",
    "                 params, \n",
    "                 eval_func,\n",
    "                 eval_weights,\n",
    "                 #\n",
    "                 X_train,\n",
    "                 X_test,\n",
    "                 y_train,\n",
    "                 y_test,\n",
    "                 #\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 lr=LR,\n",
    "                 #\n",
    "                 sel_tournsize=2, \n",
    "                 cx_uniform_prob=0.5, \n",
    "                 mut_shuffle_idx_prob=0.1,\n",
    "                 #\n",
    "                 n_pop=20,  # throw 20 different NN architectures...\n",
    "                 n_gen=10,  # ... for 10 generations...\n",
    "                 #\n",
    "                 n_hof=5,  # ... and return me the best 5 architectures (Hall of Fame)!\n",
    "                 cx_prob=0.5, \n",
    "                 mut_prob=0.1, \n",
    "                 n_jobs=1\n",
    "                ):\n",
    "        self.params = params\n",
    "        self.eval_func = eval_func\n",
    "        self.eval_weights = eval_weights\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.sel_tournsize = sel_tournsize\n",
    "        self.cx_uniform_prob = cx_uniform_prob\n",
    "        self.mut_shuffle_idx_prob = mut_shuffle_idx_prob\n",
    "        self.n_pop = n_pop\n",
    "        self.n_gen = n_gen\n",
    "        self.n_hof = n_hof\n",
    "        self.cx_prob = cx_prob\n",
    "        self.mut_prob = mut_prob\n",
    "        \n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        self._pad_params()\n",
    "        self._create_fitness_and_indiv()\n",
    "        self._register_indiv_and_pop_generators()\n",
    "        self._register_eval_func()\n",
    "        self._register_selection_crossover_mutation_methods()\n",
    "\n",
    "    def _pad_params(self):\n",
    "        \"\"\"Pad params for crossover shuffle idx method\"\"\"\n",
    "        assert isinstance(self.params, dict), 'Params must be a dict, i.e. estimator.get_params()'\n",
    "        params_count = {k: len(v) for k,v in self.params.items()}\n",
    "        max_length, max_key = -99, ''\n",
    "        for k, v in params_count.items():\n",
    "            if v <= max_length:\n",
    "                continue\n",
    "            else:\n",
    "                max_key = k\n",
    "                max_length = v\n",
    "        assert isinstance(max_length, int), 'The max length between all params must be an int'\n",
    "        # cycle through params for max length param, otherwise infinite cycle\n",
    "        values_padded = (cycle(v) if k!=max_key else v for k,v in self.params.items())\n",
    "        values_padded = zip(*values_padded)  # ('a', 1, 14), ('b', 2, 16), ('c', 3, 16) ...\n",
    "        values_padded = zip(*values_padded)  # ('a', 'b', 'c'), (1, 2, 3), (14, 15, 16)...\n",
    "        padded_params = {}\n",
    "        for k, v in zip(self.params, values_padded):\n",
    "            padded_params[k] = v\n",
    "        self.padded_params = padded_params\n",
    "        print('Params padded')\n",
    "\n",
    "    def _create_fitness_and_indiv(self):\n",
    "        \"\"\"Create GA individual and fitness entities (classes)\"\"\"\n",
    "        ga_cr.create('Fitness', ga_b.Fitness, weights=self.eval_weights)\n",
    "        ga_cr.create('Individual', list, fitness=ga_cr.Fitness)\n",
    "        print('GA entities created')\n",
    "\n",
    "    def _gen_params_to_ga(self):\n",
    "        \"\"\"Generate index for each param for individual\"\"\"\n",
    "        max_dict = len(self.padded_params)\n",
    "        max_length = len(list(self.padded_params.values())[0])\n",
    "        idxs = [randint(0, max_length-1) for _ in range(max_dict)]\n",
    "        return idxs\n",
    "    \n",
    "    def _register_indiv_and_pop_generators(self):\n",
    "        \"\"\"Register GA individual and population generators\"\"\"\n",
    "        self.tb = ga_b.Toolbox()\n",
    "\n",
    "        if self.n_jobs > 1:\n",
    "            from multiprocessing import Pool\n",
    "            pool = Pool()\n",
    "            self.tb.register(\"map\", pool.map)\n",
    "\n",
    "        self.tb.register(\"individual\", ga_t.initIterate, ga_cr.Individual, self._gen_params_to_ga)\n",
    "        # Uncomment to see an example\n",
    "        # print(self.tb.individual())\n",
    "        self.tb.register(\"population\", ga_t.initRepeat, list, self.tb.individual)\n",
    "        # Uncomment to see an example\n",
    "        # print(self.tb.population(3))\n",
    "        print('GA entities\\' methods registered')\n",
    "        \n",
    "    def _register_eval_func(self):\n",
    "        \"\"\"Set GA evaluate individual function\"\"\"\n",
    "        self.tb.register(\"evaluate\",\n",
    "                        self.eval_func,\n",
    "                        padded_params=self.padded_params,\n",
    "                        X_train=self.X_train,\n",
    "                        X_test=self.X_test, \n",
    "                        y_train=self.y_train, \n",
    "                        y_test=self.y_test,\n",
    "                        batch_size=self.batch_size,\n",
    "                        lr=self.lr)\n",
    "        #print(list(self.tb.evaluate(indiv) for indiv in self.tb.population(3)))\n",
    "        print('GA eval function registered')\n",
    "    \n",
    "    def _register_selection_crossover_mutation_methods(self):\n",
    "        self.tb.register(\"select\", ga_t.selTournament, tournsize=self.sel_tournsize)\n",
    "        self.tb.register(\"mate\", ga_t.cxUniform, indpb=self.cx_uniform_prob)\n",
    "        self.tb.register(\"mutate\", ga_t.mutShuffleIndexes, indpb=self.mut_shuffle_idx_prob)\n",
    "        print('GA sel-cx-mut methods registered')\n",
    "        \n",
    "    def run_ga_search(self):\n",
    "        \"\"\"GA Search\"\"\"\n",
    "        pop = self.tb.population(n=self.n_pop)\n",
    "        hof = ga_t.HallOfFame(self.n_hof)\n",
    "\n",
    "        # Stats stdout\n",
    "        #stats = ga_t.Statistics(lambda ind: ind.fitness.values )\n",
    "        stats1 = ga_t.Statistics(lambda ind: ind.fitness.values[0] )\n",
    "        stats2 = ga_t.Statistics(lambda ind: ind.fitness.values[1] )\n",
    "        stats3 = ga_t.Statistics(lambda ind: ind.fitness.values[2] )\n",
    "        stats = ga_t.MultiStatistics(accuracy=stats1, risk=stats2, complexity=stats3)\n",
    "        stats.register(\"avg\", mean)\n",
    "        #stats.register(\"std\", np.std)\n",
    "        #stats.register(\"min\", np.min)\n",
    "        #stats.register(\"max\", np.max)\n",
    "\n",
    "        # History\n",
    "        #hist = tools.History()\n",
    "        #toolbox.decorate(\"select\", hist.decorator)\n",
    "        #tb.decorate(\"mate\", hist.decorator)\n",
    "        #tb.decorate(\"mutate\", hist.decorator)\n",
    "        #hist.update(pop)\n",
    "\n",
    "        # GA Run\n",
    "        pop, log = ga_algo.eaSimple(pop, self.tb, cxpb=self.cx_prob, \n",
    "                                    mutpb=self.mut_prob, ngen=self.n_gen, \n",
    "                                    stats=stats, halloffame=hof, verbose=True)\n",
    "        \n",
    "        # Convert back params\n",
    "        hof_ = {}\n",
    "        for i in range(self.n_hof):\n",
    "            hof_['hof_' + str(i)] = self._ga_to_params(hof[i])\n",
    "\n",
    "        return pop, log, hof_\n",
    "    \n",
    "    def _ga_to_params(self, idx_params):\n",
    "        \"\"\"Convert back idx to params\"\"\"\n",
    "        res = {}\n",
    "        for (k,v), idx in zip(self.padded_params.items(), idx_params):\n",
    "            res[k] = v[idx]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a2cdeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:52:39.590626Z",
     "iopub.status.busy": "2022-03-24T00:52:39.589458Z",
     "iopub.status.idle": "2022-03-24T00:52:39.598945Z",
     "shell.execute_reply": "2022-03-24T00:52:39.599611Z",
     "shell.execute_reply.started": "2022-03-23T23:09:27.336278Z"
    },
    "papermill": {
     "duration": 0.047018,
     "end_time": "2022-03-24T00:52:39.599785",
     "exception": false,
     "start_time": "2022-03-24T00:52:39.552767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GA will search best params among supplied\n",
    "\n",
    "from numpy import mean, linspace, inf\n",
    "\n",
    "# How many different NN architectures can we do\n",
    "# with all these params...?\n",
    "# GA will find the best ones!\n",
    "\n",
    "net_params = {\n",
    "    'l1': linspace(1,20,20).astype(int),\n",
    "    'k1': linspace(1,20,20).astype(int),\n",
    "    'a1': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n",
    "    'l2': linspace(1,20,20).astype(int),\n",
    "    'k2': linspace(1,20,20).astype(int),\n",
    "    'a2': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n",
    "    'l3': linspace(1,20,20).astype(int),\n",
    "    'k3': linspace(1,20,20).astype(int),\n",
    "    'a3': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n",
    "    'l4': linspace(1,20,20).astype(int),\n",
    "    'k4': linspace(1,20,20).astype(int),\n",
    "    'a4': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n",
    "}\n",
    "\n",
    "# Criteria for GA to see what NN architecture (params) are best\n",
    "# so as to keep doing its GA search:\n",
    "# 1. (Probabilistically) Select best individuals, according to fitness\n",
    "# 2. (Probabilistically) Mate (crossover) pairs => offsrpings, new individuals\n",
    "# 3. (Probabilistically) Mutate them\n",
    "# At end of generations, search stops, returns best individuals (params)\n",
    "\n",
    "def net_eval_indiv(individual, padded_params, X_train, X_test, y_train, y_test, batch_size, lr):\n",
    "    \"\"\"Evaluate individual's genes (estimator's params)\"\"\"\n",
    "\n",
    "    # Params\n",
    "    indiv_params = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual)}\n",
    "    \n",
    "    # Net\n",
    "    net = NET(**indiv_params).to(DEVI)\n",
    "    try:\n",
    "        net(ones(1,1,28,28).to(DEVI))\n",
    "    except BaseException as e:\n",
    "        # At runtime, GA may select some params from space that\n",
    "        # may not be compatible with the NN, \n",
    "        # i.e. due to initial heavy convolution, image went 1x1 pixels and \n",
    "        # can't go into later NN layers!\n",
    "        # If this is the case, this params are not good, so\n",
    "        # give them a very bad fitness, so\n",
    "        # GA most likely won't select them in later generations\n",
    "        print('=> Possible Arch Error:', e)\n",
    "        return (0.01, (1/10)**10, 1000000)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Train\n",
    "    train_ds = DS(X_train, y_train)  # TODO refactor out\n",
    "    train_dl = DataLoader(train_ds,\n",
    "                        batch_size=batch_size,\n",
    "                        #shuffle=True,\n",
    "                        sampler=ws,\n",
    "                        num_workers=3,\n",
    "                        drop_last=True,\n",
    "                         )\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for i, (inputs, labels) in enumerate(train_dl):\n",
    "            # Since I just want a \"taste\" of the current params\n",
    "            # I don't train on all samples, just a few batches\n",
    "            # Later, I will indeed use the best params and\n",
    "            # do a full train, i.e. GA only for search\n",
    "            if i <= 50:\n",
    "                outputs = net(inputs.to(DEVI))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(outputs, labels).mean()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, predicted = pt_max(outputs.data, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    # Eval\n",
    "    with no_grad():\n",
    "        net = net.eval()\n",
    "        test_ds = DS(X_test, y_test)\n",
    "        test_dl = DataLoader(test_ds,\n",
    "                            batch_size=batch_size,\n",
    "                            num_workers=3,\n",
    "                            shuffle=True,\n",
    "                            drop_last=True)\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        for i, (inputs, labels) in enumerate(test_dl):\n",
    "            if i <= 50:\n",
    "                outputs = net(inputs.to(DEVI))\n",
    "\n",
    "                _, predicted = pt_max(outputs.data, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "                test_accuracy = test_correct / test_total * 100\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    # ADVANTAGE:\n",
    "    # the nice thing about GAs is that it doesn't care about the search\n",
    "    # of only NN params, i.e. as Scikit-learn search does,\n",
    "    # I can rely on many criteria for its fitness evaluation criteria, so,\n",
    "    # I figured, among all possible \"good\" NN architectures, I want\n",
    "    # the one with less risk, i.e. where the product of its probabilities is \n",
    "    # the least, \n",
    "    # Also I am asking for the least complex, i.e. least amount of parameters, \n",
    "    # small NN, not one with millions and millions of parameters\n",
    "    # that's why this fitness function returns 3 results\n",
    "    # Lastly, the directions point to where is better:\n",
    "    # positive is higher is better, negative is lower is better\n",
    "    \n",
    "    # Risk\n",
    "    risk = median(prod(net(inputs).exp()*10, dim=1))\n",
    "    if isnan(risk):\n",
    "        risk = 10\n",
    "    else:\n",
    "        risk = float(risk)\n",
    "        \n",
    "    # Complexity\n",
    "    compl = net.count_weights_biases()\n",
    "\n",
    "    return (test_accuracy, risk, compl,)\n",
    "\n",
    "net_weights = (1, -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b062991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:52:39.637433Z",
     "iopub.status.busy": "2022-03-24T00:52:39.636727Z",
     "iopub.status.idle": "2022-03-24T00:56:25.788848Z",
     "shell.execute_reply": "2022-03-24T00:56:25.789651Z",
     "shell.execute_reply.started": "2022-03-23T23:29:12.796191Z"
    },
    "papermill": {
     "duration": 226.173073,
     "end_time": "2022-03-24T00:56:25.789852",
     "exception": false,
     "start_time": "2022-03-24T00:52:39.616779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params padded\n",
      "GA entities created\n",
      "GA entities' methods registered\n",
      "GA eval function registered\n",
      "GA sel-cx-mut methods registered\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (9 x 9). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (13 x 13). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (15 x 15). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (14 x 14). Kernel size: (15 x 15). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (10 x 10). Kernel size: (13 x 13). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (10 x 10). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (15 x 15). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (10 x 10). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (11 x 11). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (12 x 12). Kernel size: (15 x 15). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (11 x 11). Kernel size: (12 x 12). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (10 x 10). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (17 x 17). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (5 x 5). Kernel size can't be greater than actual input size\n",
      "   \t      \t       accuracy       \t      complexity      \t             risk             \n",
      "   \t      \t----------------------\t----------------------\t------------------------------\n",
      "gen\tnevals\tavg    \tgen\tnevals\tavg   \tgen\tnevals\tavg      \tgen\tnevals\n",
      "0  \t20    \t3.23204\t0  \t20    \t901668\t0  \t20    \t0.0643734\t0  \t20    \n",
      "=> Possible Arch Error: Expected more than 1 value per channel when training, got input size torch.Size([1, 8, 1, 1])\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (17 x 17). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (12 x 12). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (10 x 10). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (10 x 10). Kernel size: (13 x 13). Kernel size can't be greater than actual input size\n",
      "1  \t11    \t6.32437\t1  \t11    \t852309\t1  \t11    \t0.048298 \t1  \t11    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (10 x 10). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (10 x 10). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (18 x 18). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "2  \t11    \t15.6489\t2  \t11    \t707009\t2  \t11    \t0.123349 \t2  \t11    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (18 x 18). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (12 x 12). Kernel size: (17 x 17). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (5 x 5). Kernel size: (13 x 13). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (12 x 12). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "3  \t10    \t18.587 \t3  \t10    \t711725\t3  \t10    \t0.110847 \t3  \t10    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (17 x 17). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (6 x 6). Kernel size: (9 x 9). Kernel size can't be greater than actual input size\n",
      "4  \t10    \t24.1783\t4  \t10    \t558120\t4  \t10    \t0.203126 \t4  \t10    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (2 x 2). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (18 x 18). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "5  \t10    \t40.7638\t5  \t10    \t264404\t5  \t10    \t0.375342 \t5  \t10    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "6  \t12    \t48.9236\t6  \t12    \t71210.6\t6  \t12    \t0.461122 \t6  \t12    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (9 x 9). Kernel size can't be greater than actual input size\n",
      "7  \t13    \t57.9938\t7  \t13    \t79389.1\t7  \t13    \t0.286176 \t7  \t13    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (9 x 9). Kernel size can't be greater than actual input size\n",
      "8  \t16    \t64.5777\t8  \t16    \t84671.4\t8  \t16    \t0.180678 \t8  \t16    \n",
      "9  \t12    \t73.03  \t9  \t12    \t49528.6\t9  \t12    \t0.0680266\t9  \t12    \n",
      "10 \t10    \t75.8946\t10 \t10    \t48417.9\t10 \t10    \t0.033337 \t10 \t10    \n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "from deap import creator as ga_cr, base as ga_b, algorithms as ga_algo, tools as ga_t\n",
    "from random import randint, random\n",
    "from numpy import mean\n",
    "from torch.optim import Adam\n",
    "from torch import max as pt_max, no_grad, median, prod, isnan, long\n",
    "\n",
    "# Here is just instantiate the (hybrid) class\n",
    "# and ask for it to start the search\n",
    "\n",
    "net_ga_params = GA_Pytorch(net_params, \n",
    "                           net_eval_indiv, \n",
    "                           net_weights,\n",
    "                           X_train, \n",
    "                           X_test, \n",
    "                           y_train, \n",
    "                           y_test)\n",
    "pop, log, hof = net_ga_params.run_ga_search()\n",
    "\n",
    "# Notice how GA starts to find not-error NN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "002c4862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:56:25.845607Z",
     "iopub.status.busy": "2022-03-24T00:56:25.842718Z",
     "iopub.status.idle": "2022-03-24T00:56:25.935619Z",
     "shell.execute_reply": "2022-03-24T00:56:25.934960Z",
     "shell.execute_reply.started": "2022-03-23T23:40:54.457491Z"
    },
    "papermill": {
     "duration": 0.121189,
     "end_time": "2022-03-24T00:56:25.935754",
     "exception": false,
     "start_time": "2022-03-24T00:56:25.814565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hof_0</th>\n",
       "      <th>hof_1</th>\n",
       "      <th>hof_2</th>\n",
       "      <th>hof_3</th>\n",
       "      <th>hof_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>l1</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>ELU</td>\n",
       "      <td>CELU</td>\n",
       "      <td>ELU</td>\n",
       "      <td>ELU</td>\n",
       "      <td>Softsign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2</th>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l3</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a3</th>\n",
       "      <td>CELU</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>CELU</td>\n",
       "      <td>CELU</td>\n",
       "      <td>CELU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l4</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a4</th>\n",
       "      <td>ReLU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>ELU</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>ELU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hof_0 hof_1 hof_2 hof_3     hof_4\n",
       "l1     6    17    17    17        17\n",
       "k1     4     3     4     4        11\n",
       "a1   ELU  CELU   ELU   ELU  Softsign\n",
       "l2     6    11    17    11        11\n",
       "k2     2     2     6     2         2\n",
       "a2  SELU  SELU  SELU  SELU      SELU\n",
       "l3    11     4    11     4         4\n",
       "k3     1     4     1     1         1\n",
       "a3  CELU  ReLU  CELU  CELU      CELU\n",
       "l4    15    15     5    15        15\n",
       "k4     9     1     1     1         1\n",
       "a4  ReLU  SELU   ELU  ReLU       ELU"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['best_params.json']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persisting best params\n",
    "\n",
    "from pandas import DataFrame\n",
    "from joblib import dump, load\n",
    "\n",
    "DataFrame(hof)\n",
    "dump(hof, 'best_params.json')\n",
    "\n",
    "# Notice how the best individuals (NN architectures)\n",
    "# has these genes (params)\n",
    "# it seems Softsign activation didn't make it to the hall of fame\n",
    "# Also, notice the interesting kernels, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cacc6a9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T00:56:26.001635Z",
     "iopub.status.busy": "2022-03-24T00:56:26.000507Z",
     "iopub.status.idle": "2022-03-24T01:01:02.397162Z",
     "shell.execute_reply": "2022-03-24T01:01:02.396560Z",
     "shell.execute_reply.started": "2022-03-23T23:47:00.723727Z"
    },
    "papermill": {
     "duration": 276.436469,
     "end_time": "2022-03-24T01:01:02.397324",
     "exception": false,
     "start_time": "2022-03-24T00:56:25.960855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.12% 45.09% 48.74% 60.59% 68.74% 71.47% 74.07% 74.16% 76.06% 76.75% 77.30% 77.70% 78.42% 79.21% 80.29% 80.52% 81.22% 81.48% => TEST 96.05%\n",
      "Train: 93.58% 93.67% 94.34% 94.37% 94.48% 94.47% 94.51% 94.51% 94.61% 94.62% 94.64% 94.67% 94.68% 94.69% => TEST 97.41%\n",
      "Train: 95.42% 95.36% 95.44% 95.49% 95.45% 95.56% 95.67% 95.67% 95.61% 95.64% 95.73% 95.77% 95.75% 95.78% 95.72% 95.74% 95.79% 95.76% 95.76% 95.78% 95.83% 95.84% 95.86% 95.90% 95.89% 95.89% 95.91% => TEST 97.95%\n",
      "Train: 97.27% 96.56% 96.49% 96.51% 96.51% 96.52% 96.49% 96.49% 96.50% 96.50% 96.50% 96.50% 96.50% 96.47% 96.47% 96.46% 96.46% 96.48% 96.48% 96.52% => TEST 98.17%\n",
      "Train: 96.56% 96.74% 96.81% 96.80% 96.83% 96.86% 96.87% 96.89% 96.90% 96.93% 96.94% 96.94% 96.94% 96.95% 96.95% 96.96% 96.97% 97.00% 97.02% => TEST 98.23%\n"
     ]
    }
   ],
   "source": [
    "# Ok, now here full train with best params\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "# Params\n",
    "params = load('best_params.json')['hof_0']\n",
    "\n",
    "# Net\n",
    "net = NET(**params).to(DEVI)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(net.parameters(), lr=LR*.75)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Data\n",
    "train_ds = DS(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, \n",
    "               batch_size=BATCH_SIZE*2,  # Just preventing overfitting via here\n",
    "               num_workers=3,\n",
    "               drop_last=True,\n",
    "               #shuffle=True\n",
    "                sampler=ws\n",
    "                     )\n",
    "\n",
    "test_ds = DS(X_test, y_test)\n",
    "test_dl = DataLoader(test_ds,\n",
    "               batch_size=BATCH_SIZE*2, \n",
    "               num_workers=3,\n",
    "               shuffle=True)\n",
    "\n",
    "# Train\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Train:', end=' ')\n",
    "    net = net.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for i, (inputs, labels) in enumerate(train_dl):\n",
    "        outputs = net(inputs.to(DEVI))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels.to(DEVI)).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = pt_max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "        if random()>0.95: print(f'{train_correct / train_total * 100:^5.2f}%', end=' ')\n",
    "    \n",
    "    # Eval\n",
    "    with no_grad():\n",
    "        net = net.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        for i, (inputs, labels) in enumerate(test_dl):\n",
    "            outputs = net(inputs.to(DEVI))\n",
    "            _, predicted = pt_max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "            test_accuracy = test_correct / test_total * 100\n",
    "    print(f'=> TEST {test_accuracy:^5.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63237ab",
   "metadata": {
    "papermill": {
     "duration": 0.057158,
     "end_time": "2022-03-24T01:01:02.512272",
     "exception": false,
     "start_time": "2022-03-24T01:01:02.455114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c04426",
   "metadata": {
    "papermill": {
     "duration": 0.056574,
     "end_time": "2022-03-24T01:01:02.624834",
     "exception": false,
     "start_time": "2022-03-24T01:01:02.568260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74302c77",
   "metadata": {
    "papermill": {
     "duration": 0.055556,
     "end_time": "2022-03-24T01:01:02.736680",
     "exception": false,
     "start_time": "2022-03-24T01:01:02.681124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 515.928973,
   "end_time": "2022-03-24T01:01:03.607909",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-24T00:52:27.678936",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
