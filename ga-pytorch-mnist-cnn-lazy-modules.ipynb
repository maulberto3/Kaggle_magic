{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565a71dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:07:37.945681Z",
     "iopub.status.busy": "2022-03-24T03:07:37.943822Z",
     "iopub.status.idle": "2022-03-24T03:07:38.051116Z",
     "shell.execute_reply": "2022-03-24T03:07:38.051685Z",
     "shell.execute_reply.started": "2022-03-23T22:52:46.527705Z"
    },
    "papermill": {
     "duration": 0.127267,
     "end_time": "2022-03-24T03:07:38.051990",
     "exception": false,
     "start_time": "2022-03-24T03:07:37.924723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset -sf\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689d9412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:07:38.081185Z",
     "iopub.status.busy": "2022-03-24T03:07:38.080147Z",
     "iopub.status.idle": "2022-03-24T03:07:39.240742Z",
     "shell.execute_reply": "2022-03-24T03:07:39.239774Z",
     "shell.execute_reply.started": "2022-03-23T22:52:46.642225Z"
    },
    "papermill": {
     "duration": 1.17613,
     "end_time": "2022-03-24T03:07:39.240902",
     "exception": false,
     "start_time": "2022-03-24T03:07:38.064772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Device: cpu\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda import is_available\n",
    "\n",
    "DEVI = \"cuda\" if is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(\"==> Device:\", DEVI)\n",
    "\n",
    "# from torch import manual_seed\n",
    "# manual_seed(16)\n",
    "# from random import seed\n",
    "# seed(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb888b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:07:39.274547Z",
     "iopub.status.busy": "2022-03-24T03:07:39.273766Z",
     "iopub.status.idle": "2022-03-24T03:07:39.276983Z",
     "shell.execute_reply": "2022-03-24T03:07:39.276407Z",
     "shell.execute_reply.started": "2022-03-23T22:53:17.404592Z"
    },
    "papermill": {
     "duration": 0.022949,
     "end_time": "2022-03-24T03:07:39.277133",
     "exception": false,
     "start_time": "2022-03-24T03:07:39.254184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A few HPs\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c2b6e0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:07:39.308934Z",
     "iopub.status.busy": "2022-03-24T03:07:39.308220Z",
     "iopub.status.idle": "2022-03-24T03:07:39.999528Z",
     "shell.execute_reply": "2022-03-24T03:07:40.000063Z",
     "shell.execute_reply.started": "2022-03-23T22:54:51.443498Z"
    },
    "papermill": {
     "duration": 0.710085,
     "end_time": "2022-03-24T03:07:40.000246",
     "exception": false,
     "start_time": "2022-03-24T03:07:39.290161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 28, 28]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "from torch import load\n",
    "\n",
    "X_train, y_train = load('/kaggle/input/pytorch-mnist/training.pt')\n",
    "X_test, y_test = load('/kaggle/input/pytorch-mnist/test.pt')\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1032e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:07:40.037739Z",
     "iopub.status.busy": "2022-03-24T03:07:40.036880Z",
     "iopub.status.idle": "2022-03-24T03:07:40.038426Z",
     "shell.execute_reply": "2022-03-24T03:07:40.038920Z",
     "shell.execute_reply.started": "2022-03-23T22:54:52.312746Z"
    },
    "papermill": {
     "duration": 0.023551,
     "end_time": "2022-03-24T03:07:40.039097",
     "exception": false,
     "start_time": "2022-03-24T03:07:40.015546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset class (how to get samples from dataset, i.e. idx-style)\n",
    "\n",
    "from torch import nn, load\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DS(Dataset):\n",
    "    def __init__(self, maps, labels) -> None:\n",
    "        self.maps = maps\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.maps[idx]\n",
    "        #X = X.reshape(1, -1)\n",
    "        X = X.unsqueeze(0)\n",
    "        y = self.labels[idx]\n",
    "        return X.to(DEVI, dtype=pt_float), y.to(DEVI, dtype=long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0ba489d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:07:40.069929Z",
     "iopub.status.busy": "2022-03-24T03:07:40.069231Z",
     "iopub.status.idle": "2022-03-24T03:07:40.087450Z",
     "shell.execute_reply": "2022-03-24T03:07:40.088009Z",
     "shell.execute_reply.started": "2022-03-23T22:55:06.651925Z"
    },
    "papermill": {
     "duration": 0.035314,
     "end_time": "2022-03-24T03:07:40.088186",
     "exception": false,
     "start_time": "2022-03-24T03:07:40.052872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5923),\n",
       " (1, 6742),\n",
       " (2, 5958),\n",
       " (3, 6131),\n",
       " (4, 5842),\n",
       " (5, 5421),\n",
       " (6, 5918),\n",
       " (7, 6265),\n",
       " (8, 5851),\n",
       " (9, 5949)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.WeightedRandomSampler at 0x7fcc9b56a810>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small utility for equal sampling while training\n",
    "# i.e. how to deal with few (relatively) 5's and a lot of 1's\n",
    "\n",
    "from numpy import bincount\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# balanced sampler\n",
    "counts = bincount(y_train)\n",
    "labels_weights = 1. / counts\n",
    "list(zip(range(10), counts))\n",
    "weights = labels_weights[y_train]\n",
    "ws = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aaa80a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:07:40.119438Z",
     "iopub.status.busy": "2022-03-24T03:07:40.118747Z",
     "iopub.status.idle": "2022-03-24T03:07:40.282547Z",
     "shell.execute_reply": "2022-03-24T03:07:40.281627Z",
     "shell.execute_reply.started": "2022-03-23T23:02:22.751274Z"
    },
    "papermill": {
     "duration": 0.180617,
     "end_time": "2022-03-24T03:07:40.282708",
     "exception": false,
     "start_time": "2022-03-24T03:07:40.102091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Before 1st forward => no weights (connections between layers) initialized:'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "NET(\n",
       "  (cnn1): Sequential(\n",
       "    (0): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): SELU()\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (cnn4): Sequential(\n",
       "    (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       "    (2): LogSoftmax(dim=-1)\n",
       "  )\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): SELU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): LazyConv2d(0, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       "      (2): LogSoftmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'After 1st forward => weights (connections between layers) initialized:'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "NET(\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): SELU()\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (cnn4): Sequential(\n",
       "    (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=5760, out_features=10, bias=True)\n",
       "    (2): LogSoftmax(dim=-1)\n",
       "  )\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): SELU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(10, 10, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): SELU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=5760, out_features=10, bias=True)\n",
       "      (2): LogSoftmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'This LAZY PyTorch functionality is what I take advantage of with Genetic \\nAlgorithms (GA), simply put: I use GA for hyperparameter tuning.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (LAZY) Net\n",
    "\n",
    "from torch import float as pt_float, ones\n",
    "\n",
    "class NET(nn.Module):\n",
    "    \"\"\"Simple CNN Lazy Net\"\"\"\n",
    "    def __init__(self, l1, k1, a1, l2, k2, a2, l3, k3, a3, l4, k4, a4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.LazyConv2d(l1, k1),  # lazy module, only specify out features...\n",
    "            nn.Dropout(0.5),\n",
    "            nn.__getattribute__(a1)())\n",
    "        \n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.LazyBatchNorm2d(), # lazy module...\n",
    "            nn.LazyConv2d(l2, k2), # lazy module... and so on\n",
    "            nn.Dropout(0.5),  # Heavy anti-overfitting just in case...\n",
    "            nn.__getattribute__(a2)())\n",
    "\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.LazyConv2d(l3, k3),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.__getattribute__(a3)())\n",
    "\n",
    "        self.cnn4 = nn.Sequential(\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.LazyConv2d(l4, k4),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.__getattribute__(a4)())\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(10),\n",
    "            nn.LogSoftmax(dim=-1))\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            self.cnn1,\n",
    "            self.cnn2,\n",
    "            self.cnn3,\n",
    "            self.cnn4,\n",
    "            self.out\n",
    "        )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        return self.model(x)\n",
    "    \n",
    "    def count_weights_biases(self):\n",
    "        return int(sum(p.numel() for p in self.parameters() if p.requires_grad))\n",
    "    \n",
    "\n",
    "net = NET(10, 2, 'SELU', 10, 2, 'SELU', 10, 2, 'SELU', 10, 2, 'SELU', ).to(DEVI)\n",
    "f'Before 1st forward => no weights (connections between layers) initialized:'\n",
    "net\n",
    "f'After 1st forward => weights (connections between layers) initialized:'\n",
    "_ = net(ones(1, 1, 28, 28))\n",
    "net\n",
    "\n",
    "\"\"\"This LAZY PyTorch functionality is what I take advantage of with Genetic \n",
    "Algorithms (GA), simply put: I use GA for hyperparameter tuning.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7401d3b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:07:40.318812Z",
     "iopub.status.busy": "2022-03-24T03:07:40.317980Z",
     "iopub.status.idle": "2022-03-24T03:07:40.348983Z",
     "shell.execute_reply": "2022-03-24T03:07:40.349596Z",
     "shell.execute_reply.started": "2022-03-23T23:15:06.083533Z"
    },
    "papermill": {
     "duration": 0.051095,
     "end_time": "2022-03-24T03:07:40.349801",
     "exception": false,
     "start_time": "2022-03-24T03:07:40.298706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom class to put things in order, give it \n",
    "# params, data, etc.\n",
    "\n",
    "class GA_Pytorch():\n",
    "    def __init__(self, \n",
    "                 params, \n",
    "                 eval_func,\n",
    "                 eval_weights,\n",
    "                 #\n",
    "                 X_train,\n",
    "                 X_test,\n",
    "                 y_train,\n",
    "                 y_test,\n",
    "                 #\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 lr=LR,\n",
    "                 #\n",
    "                 sel_tournsize=2, \n",
    "                 cx_uniform_prob=0.5, \n",
    "                 mut_shuffle_idx_prob=0.1,\n",
    "                 #\n",
    "                 n_pop=30,  # try 30 different NN architectures...\n",
    "                 n_gen=10,  # ... for 10 generations...\n",
    "                 #\n",
    "                 n_hof=5,  # ... and return me the best 5 architectures (Hall of Fame)!\n",
    "                 cx_prob=0.5, \n",
    "                 mut_prob=0.1, \n",
    "                 n_jobs=1\n",
    "                ):\n",
    "        self.params = params\n",
    "        self.eval_func = eval_func\n",
    "        self.eval_weights = eval_weights\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.sel_tournsize = sel_tournsize\n",
    "        self.cx_uniform_prob = cx_uniform_prob\n",
    "        self.mut_shuffle_idx_prob = mut_shuffle_idx_prob\n",
    "        self.n_pop = n_pop\n",
    "        self.n_gen = n_gen\n",
    "        self.n_hof = n_hof\n",
    "        self.cx_prob = cx_prob\n",
    "        self.mut_prob = mut_prob\n",
    "        \n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        self._pad_params()\n",
    "        self._create_fitness_and_indiv()\n",
    "        self._register_indiv_and_pop_generators()\n",
    "        self._register_eval_func()\n",
    "        self._register_selection_crossover_mutation_methods()\n",
    "\n",
    "    def _pad_params(self):\n",
    "        \"\"\"Pad params for crossover shuffle idx method\"\"\"\n",
    "        assert isinstance(self.params, dict), 'Params must be a dict, i.e. estimator.get_params()'\n",
    "        params_count = {k: len(v) for k,v in self.params.items()}\n",
    "        max_length, max_key = -99, ''\n",
    "        for k, v in params_count.items():\n",
    "            if v <= max_length:\n",
    "                continue\n",
    "            else:\n",
    "                max_key = k\n",
    "                max_length = v\n",
    "        assert isinstance(max_length, int), 'The max length between all params must be an int'\n",
    "        # cycle through params for max length param, otherwise infinite cycle\n",
    "        values_padded = (cycle(v) if k!=max_key else v for k,v in self.params.items())\n",
    "        values_padded = zip(*values_padded)  # ('a', 1, 14), ('b', 2, 16), ('c', 3, 16) ...\n",
    "        values_padded = zip(*values_padded)  # ('a', 'b', 'c'), (1, 2, 3), (14, 15, 16)...\n",
    "        padded_params = {}\n",
    "        for k, v in zip(self.params, values_padded):\n",
    "            padded_params[k] = v\n",
    "        self.padded_params = padded_params\n",
    "        print('Params padded')\n",
    "\n",
    "    def _create_fitness_and_indiv(self):\n",
    "        \"\"\"Create GA individual and fitness entities (classes)\"\"\"\n",
    "        ga_cr.create('Fitness', ga_b.Fitness, weights=self.eval_weights)\n",
    "        ga_cr.create('Individual', list, fitness=ga_cr.Fitness)\n",
    "        print('GA entities created')\n",
    "\n",
    "    def _gen_params_to_ga(self):\n",
    "        \"\"\"Generate index for each param for individual\"\"\"\n",
    "        max_dict = len(self.padded_params)\n",
    "        max_length = len(list(self.padded_params.values())[0])\n",
    "        idxs = [randint(0, max_length-1) for _ in range(max_dict)]\n",
    "        return idxs\n",
    "    \n",
    "    def _register_indiv_and_pop_generators(self):\n",
    "        \"\"\"Register GA individual and population generators\"\"\"\n",
    "        self.tb = ga_b.Toolbox()\n",
    "\n",
    "        if self.n_jobs > 1:\n",
    "            from multiprocessing import Pool\n",
    "            pool = Pool()\n",
    "            self.tb.register(\"map\", pool.map)\n",
    "\n",
    "        self.tb.register(\"individual\", ga_t.initIterate, ga_cr.Individual, self._gen_params_to_ga)\n",
    "        # Uncomment to see an example\n",
    "        # print(self.tb.individual())\n",
    "        self.tb.register(\"population\", ga_t.initRepeat, list, self.tb.individual)\n",
    "        # Uncomment to see an example\n",
    "        # print(self.tb.population(3))\n",
    "        print('GA entities\\' methods registered')\n",
    "        \n",
    "    def _register_eval_func(self):\n",
    "        \"\"\"Set GA evaluate individual function\"\"\"\n",
    "        self.tb.register(\"evaluate\",\n",
    "                        self.eval_func,\n",
    "                        padded_params=self.padded_params,\n",
    "                        X_train=self.X_train,\n",
    "                        X_test=self.X_test, \n",
    "                        y_train=self.y_train, \n",
    "                        y_test=self.y_test,\n",
    "                        batch_size=self.batch_size,\n",
    "                        lr=self.lr)\n",
    "        #print(list(self.tb.evaluate(indiv) for indiv in self.tb.population(3)))\n",
    "        print('GA eval function registered')\n",
    "    \n",
    "    def _register_selection_crossover_mutation_methods(self):\n",
    "        self.tb.register(\"select\", ga_t.selTournament, tournsize=self.sel_tournsize)\n",
    "        self.tb.register(\"mate\", ga_t.cxUniform, indpb=self.cx_uniform_prob)\n",
    "        self.tb.register(\"mutate\", ga_t.mutShuffleIndexes, indpb=self.mut_shuffle_idx_prob)\n",
    "        print('GA sel-cx-mut methods registered')\n",
    "        \n",
    "    def run_ga_search(self):\n",
    "        \"\"\"GA Search\"\"\"\n",
    "        pop = self.tb.population(n=self.n_pop)\n",
    "        hof = ga_t.HallOfFame(self.n_hof)\n",
    "\n",
    "        # Stats stdout\n",
    "        #stats = ga_t.Statistics(lambda ind: ind.fitness.values )\n",
    "        stats1 = ga_t.Statistics(lambda ind: ind.fitness.values[0] )\n",
    "        stats2 = ga_t.Statistics(lambda ind: ind.fitness.values[1] )\n",
    "        stats3 = ga_t.Statistics(lambda ind: ind.fitness.values[2] )\n",
    "        stats = ga_t.MultiStatistics(accuracy=stats1, risk=stats2, complexity=stats3)\n",
    "        stats.register(\"avg\", mean)\n",
    "        #stats.register(\"std\", np.std)\n",
    "        #stats.register(\"min\", np.min)\n",
    "        #stats.register(\"max\", np.max)\n",
    "\n",
    "        # History\n",
    "        #hist = tools.History()\n",
    "        #toolbox.decorate(\"select\", hist.decorator)\n",
    "        #tb.decorate(\"mate\", hist.decorator)\n",
    "        #tb.decorate(\"mutate\", hist.decorator)\n",
    "        #hist.update(pop)\n",
    "\n",
    "        # GA Run\n",
    "        pop, log = ga_algo.eaSimple(pop, self.tb, cxpb=self.cx_prob, \n",
    "                                    mutpb=self.mut_prob, ngen=self.n_gen, \n",
    "                                    stats=stats, halloffame=hof, verbose=True)\n",
    "        \n",
    "        # Convert back params\n",
    "        hof_ = {}\n",
    "        for i in range(self.n_hof):\n",
    "            hof_['hof_' + str(i)] = self._ga_to_params(hof[i])\n",
    "\n",
    "        return pop, log, hof_\n",
    "    \n",
    "    def _ga_to_params(self, idx_params):\n",
    "        \"\"\"Convert back idx to params\"\"\"\n",
    "        res = {}\n",
    "        for (k,v), idx in zip(self.padded_params.items(), idx_params):\n",
    "            res[k] = v[idx]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf7c7b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:07:40.386872Z",
     "iopub.status.busy": "2022-03-24T03:07:40.385988Z",
     "iopub.status.idle": "2022-03-24T03:07:40.411341Z",
     "shell.execute_reply": "2022-03-24T03:07:40.410649Z",
     "shell.execute_reply.started": "2022-03-23T23:09:27.336278Z"
    },
    "papermill": {
     "duration": 0.045385,
     "end_time": "2022-03-24T03:07:40.411514",
     "exception": false,
     "start_time": "2022-03-24T03:07:40.366129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GA will search best params among supplied\n",
    "\n",
    "from numpy import mean, linspace, inf\n",
    "\n",
    "# How many different NN architectures can we do\n",
    "# with all these params...?\n",
    "# GA will find the best ones!\n",
    "\n",
    "net_params = {\n",
    "    'l1': linspace(1,20,20).astype(int),\n",
    "    'k1': linspace(1,20,20).astype(int),\n",
    "    'a1': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n",
    "    'l2': linspace(1,20,20).astype(int),\n",
    "    'k2': linspace(1,20,20).astype(int),\n",
    "    'a2': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n",
    "    'l3': linspace(1,20,20).astype(int),\n",
    "    'k3': linspace(1,20,20).astype(int),\n",
    "    'a3': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n",
    "    'l4': linspace(1,20,20).astype(int),\n",
    "    'k4': linspace(1,20,20).astype(int),\n",
    "    'a4': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n",
    "}\n",
    "\n",
    "# Below is criteria for GA to see what NN architecture (params) are best\n",
    "# 1. (Probabilistically) Select best individuals, according to fitness\n",
    "# 2. (Probabilistically) Mate (crossover) pairs => offsrpings, new individuals\n",
    "# 3. (Probabilistically) Mutate them\n",
    "# At the end of generations, search stops, returns best individuals (params)\n",
    "\n",
    "def net_eval_indiv(individual, padded_params, X_train, X_test, y_train, y_test, batch_size, lr):\n",
    "    \"\"\"Evaluate individual's genes (estimator's params)\"\"\"\n",
    "\n",
    "    # Params\n",
    "    indiv_params = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual)}\n",
    "    \n",
    "    # Net\n",
    "    net = NET(**indiv_params).to(DEVI)\n",
    "    try:\n",
    "        net(ones(1,1,28,28).to(DEVI))\n",
    "    except BaseException as e:\n",
    "        # At runtime, GA may select some params from space that\n",
    "        # may not be compatible with the NN, \n",
    "        # i.e. due to initial heavy convolution, image went 1x1 pixels and \n",
    "        # can't go into later NN layers, error!\n",
    "        # If this is the case, these params are not good, so\n",
    "        # then give them a very bad (fixed) fitness, so\n",
    "        # GA most likely won't select them in later generations\n",
    "        print('=> Possible Arch Error:', e)\n",
    "        return (0.01, (1/10)**10, 1000000)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Train\n",
    "    train_ds = DS(X_train, y_train)\n",
    "    train_dl = DataLoader(train_ds,\n",
    "                        batch_size=batch_size,\n",
    "                        #shuffle=True,\n",
    "                        sampler=ws,\n",
    "                        num_workers=3,\n",
    "                        drop_last=True,\n",
    "                         )\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for i, (inputs, labels) in enumerate(train_dl):\n",
    "            # Since I just want a \"taste\" of the current params\n",
    "            # I don't train on all samples, just a few batches\n",
    "            # Later, I will indeed use the best params and\n",
    "            # do a full train, i.e. GA only for search\n",
    "            if i <= 50:\n",
    "                outputs = net(inputs.to(DEVI))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(outputs, labels).mean()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, predicted = pt_max(outputs.data, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    # Eval\n",
    "    with no_grad():\n",
    "        net = net.eval()\n",
    "        test_ds = DS(X_test, y_test)\n",
    "        test_dl = DataLoader(test_ds,\n",
    "                            batch_size=batch_size,\n",
    "                            num_workers=3,\n",
    "                            shuffle=True,\n",
    "                            drop_last=True)\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        for i, (inputs, labels) in enumerate(test_dl):\n",
    "            if i <= 50:\n",
    "                outputs = net(inputs.to(DEVI))\n",
    "\n",
    "                _, predicted = pt_max(outputs.data, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "                test_accuracy = test_correct / test_total * 100\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    # ADVANTAGE:\n",
    "    # the nice thing about GAs is that it doesn't care about the search\n",
    "    # of only NN params, i.e. as Scikit-learn search does,\n",
    "    # It can rely on many criteria for its fitness evaluation criteria, so,\n",
    "    # I figured, among all possible \"good\" NN architectures, I want\n",
    "    # the one with less risk, i.e. where the product of its probabilities is the least, \n",
    "    # Also I am asking for the least complex, i.e. least amount of parameters, \n",
    "    # small NN, not one with millions and millions of parameters,\n",
    "    # that's why this fitness function returns 3 results\n",
    "    \n",
    "    # Lastly, the directions point to where is better:\n",
    "    # positive is higher is better, negative is lower is better\n",
    "    \n",
    "    # Risk\n",
    "    risk = median(prod(net(inputs).exp()*10, dim=1))\n",
    "    if isnan(risk):\n",
    "        risk = 10\n",
    "    else:\n",
    "        risk = float(risk)\n",
    "        \n",
    "    # Complexity\n",
    "    compl = net.count_weights_biases()\n",
    "\n",
    "    return (test_accuracy, risk, compl,)\n",
    "\n",
    "net_weights = (1, -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0e753c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:07:40.450720Z",
     "iopub.status.busy": "2022-03-24T03:07:40.449964Z",
     "iopub.status.idle": "2022-03-24T03:20:14.530043Z",
     "shell.execute_reply": "2022-03-24T03:20:14.530598Z",
     "shell.execute_reply.started": "2022-03-23T23:29:12.796191Z"
    },
    "papermill": {
     "duration": 754.10325,
     "end_time": "2022-03-24T03:20:14.530787",
     "exception": false,
     "start_time": "2022-03-24T03:07:40.427537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params padded\n",
      "GA entities created\n",
      "GA entities' methods registered\n",
      "GA eval function registered\n",
      "GA sel-cx-mut methods registered\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (11 x 11). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (12 x 12). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (15 x 15). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (9 x 9). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Expected more than 1 value per channel when training, got input size torch.Size([1, 20, 1, 1])\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (12 x 12). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (2 x 2). Kernel size: (8 x 8). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (3 x 3). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (15 x 15). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (14 x 14). Kernel size: (17 x 17). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (11 x 11). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (3 x 3). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (11 x 11). Kernel size: (13 x 13). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (3 x 3). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (12 x 12). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (17 x 17). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (10 x 10). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (10 x 10). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (15 x 15). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (17 x 17). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (14 x 14). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "   \t      \t       accuracy       \t      complexity      \t             risk             \n",
      "   \t      \t----------------------\t----------------------\t------------------------------\n",
      "gen\tnevals\tavg    \tgen\tnevals\tavg   \tgen\tnevals\tavg      \tgen\tnevals\n",
      "0  \t30    \t5.00492\t0  \t30    \t901889\t0  \t30    \t0.0401869\t0  \t30    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (9 x 9). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Expected more than 1 value per channel when training, got input size torch.Size([1, 20, 1, 1])\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (11 x 11). Kernel size: (12 x 12). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (10 x 10). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (5 x 5). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (15 x 15). Kernel size: (17 x 17). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (15 x 15). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (15 x 15). Kernel size: (20 x 20). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (3 x 3). Kernel size: (11 x 11). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (2 x 2). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "1  \t13    \t10.6211\t1  \t13    \t838175\t1  \t13    \t0.0127228\t1  \t13    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (11 x 11). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (10 x 10). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (10 x 10). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (5 x 5). Kernel size: (8 x 8). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (11 x 11). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "2  \t17    \t23.4118\t2  \t17    \t611135\t2  \t17    \t0.0120803\t2  \t17    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (15 x 15). Kernel size: (17 x 17). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (10 x 10). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (2 x 2). Kernel size: (8 x 8). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (3 x 3). Kernel size: (11 x 11). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (7 x 7). Kernel size: (12 x 12). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (11 x 11). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (2 x 2). Kernel size: (11 x 11). Kernel size can't be greater than actual input size\n",
      "3  \t20    \t30.5595\t3  \t20    \t512731\t3  \t20    \t0.0119948\t3  \t20    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (18 x 18). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (2 x 2). Kernel size: (11 x 11). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (10 x 10). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (4 x 4). Kernel size: (19 x 19). Kernel size can't be greater than actual input size\n",
      "4  \t16    \t52.2858\t4  \t16    \t253097\t4  \t16    \t0.00967914\t4  \t16    \n",
      "=> Possible Arch Error: Calculated padded input size per channel: (2 x 2). Kernel size: (11 x 11). Kernel size can't be greater than actual input size\n",
      "=> Possible Arch Error: Calculated padded input size per channel: (5 x 5). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n",
      "5  \t22    \t64.6637\t5  \t22    \t90640.4\t5  \t22    \t0.00079081\t5  \t22    \n",
      "6  \t20    \t73.6305\t6  \t20    \t25638  \t6  \t20    \t0.000301645\t6  \t20    \n",
      "7  \t20    \t75.1083\t7  \t20    \t24586  \t7  \t20    \t0.0228233  \t7  \t20    \n",
      "8  \t21    \t75.5494\t8  \t21    \t23581.5\t8  \t21    \t0.03248    \t8  \t21    \n",
      "9  \t18    \t77.4734\t9  \t18    \t23872.2\t9  \t18    \t0.000615874\t9  \t18    \n",
      "10 \t19    \t76.5656\t10 \t19    \t23743.1\t10 \t19    \t2.0524e-05 \t10 \t19    \n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "from deap import creator as ga_cr, base as ga_b, algorithms as ga_algo, tools as ga_t\n",
    "from random import randint, random\n",
    "from numpy import mean\n",
    "from torch.optim import Adam\n",
    "from torch import max as pt_max, no_grad, median, prod, isnan, long\n",
    "\n",
    "# Here I just instantiate the (hybrid NN-GA) class\n",
    "# and ask for it to start the search\n",
    "\n",
    "net_ga_params = GA_Pytorch(net_params, \n",
    "                           net_eval_indiv, \n",
    "                           net_weights,\n",
    "                           X_train, \n",
    "                           X_test, \n",
    "                           y_train, \n",
    "                           y_test)\n",
    "pop, log, hof = net_ga_params.run_ga_search()\n",
    "\n",
    "# Notice how GA learns to find not-error'ed NN architectures..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "600bd59a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:20:14.583859Z",
     "iopub.status.busy": "2022-03-24T03:20:14.583106Z",
     "iopub.status.idle": "2022-03-24T03:20:14.678769Z",
     "shell.execute_reply": "2022-03-24T03:20:14.678093Z",
     "shell.execute_reply.started": "2022-03-23T23:40:54.457491Z"
    },
    "papermill": {
     "duration": 0.123845,
     "end_time": "2022-03-24T03:20:14.678915",
     "exception": false,
     "start_time": "2022-03-24T03:20:14.555070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hof_0</th>\n",
       "      <th>hof_1</th>\n",
       "      <th>hof_2</th>\n",
       "      <th>hof_3</th>\n",
       "      <th>hof_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>l1</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>CELU</td>\n",
       "      <td>CELU</td>\n",
       "      <td>CELU</td>\n",
       "      <td>CELU</td>\n",
       "      <td>CELU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2</th>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l3</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a3</th>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>Softsign</td>\n",
       "      <td>Softsign</td>\n",
       "      <td>ELU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l4</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a4</th>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "      <td>SELU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hof_0 hof_1     hof_2     hof_3 hof_4\n",
       "l1    12    12        12        12    12\n",
       "k1     2     2         2         2     2\n",
       "a1  CELU  CELU      CELU      CELU  CELU\n",
       "l2     9     9         9         9     9\n",
       "k2     2     2         2         2     2\n",
       "a2  SELU  SELU      SELU      SELU  SELU\n",
       "l3    13    13        13        13    13\n",
       "k3     8     8         8         8     8\n",
       "a3  SELU  SELU  Softsign  Softsign   ELU\n",
       "l4     7     6         6         7     7\n",
       "k4     4     4         8         3     8\n",
       "a4  SELU  SELU      SELU      SELU  SELU"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['best_params.json']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persisting best params (hall of fame)\n",
    "\n",
    "from pandas import DataFrame\n",
    "from joblib import dump, load\n",
    "\n",
    "DataFrame(hof)\n",
    "dump(hof, 'best_params.json')\n",
    "\n",
    "# Notice the best individuals' genes (NN architectures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d968386a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:20:14.744538Z",
     "iopub.status.busy": "2022-03-24T03:20:14.739001Z",
     "iopub.status.idle": "2022-03-24T03:25:14.208798Z",
     "shell.execute_reply": "2022-03-24T03:25:14.208161Z",
     "shell.execute_reply.started": "2022-03-23T23:47:00.723727Z"
    },
    "papermill": {
     "duration": 299.504172,
     "end_time": "2022-03-24T03:25:14.208976",
     "exception": false,
     "start_time": "2022-03-24T03:20:14.704804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.43% 50.66% 56.00% 58.08% 59.34% 65.39% 66.80% 71.19% 71.39% 73.13% 75.09% 77.52% 77.63% 77.68% 78.85% 78.96% 79.30% 79.83% 80.78% 80.88% 81.64% 81.78% 81.96% 82.10% 82.18% 82.72% 83.25% ===> TEST 93.99%\n",
      "TRAIN\n",
      "92.76% 93.08% 93.12% 93.14% 93.17% 93.29% 93.41% 93.49% 93.64% 93.87% 93.88% 94.05% 94.05% 94.08% 94.08% 94.11% 94.17% 94.35% 94.35% 94.36% 94.40% ===> TEST 96.18%\n",
      "TRAIN\n",
      "94.89% 95.22% 95.19% 95.23% 95.21% 95.21% 95.27% 95.31% 95.36% 95.36% 95.42% 95.42% 95.48% 95.48% 95.47% 95.50% 95.57% 95.59% 95.62% 95.65% 95.66% 95.68% ===> TEST 96.68%\n",
      "TRAIN\n",
      "96.33% 96.14% 95.73% 95.77% 95.91% 95.92% 95.96% 96.09% 96.09% 96.17% 96.20% 96.22% 96.22% 96.23% 96.28% ===> TEST 97.35%\n",
      "TRAIN\n",
      "96.21% 96.36% 96.68% 96.72% 96.75% 96.74% 96.75% 96.76% 96.77% 96.78% 96.79% 96.82% 96.75% 96.74% 96.71% 96.70% 96.64% 96.65% 96.64% 96.65% 96.64% 96.65% 96.65% 96.68% 96.68% ===> TEST 97.72%\n"
     ]
    }
   ],
   "source": [
    "# Ok, now here full train with best params\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "# Params\n",
    "params = load('best_params.json')['hof_0']\n",
    "\n",
    "# Net\n",
    "net = NET(**params).to(DEVI)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(net.parameters(), lr=LR*.75)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Data\n",
    "train_ds = DS(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, \n",
    "               batch_size=BATCH_SIZE*2,  # Just preventing overfitting via here\n",
    "               num_workers=3,\n",
    "               drop_last=True,\n",
    "               #shuffle=True\n",
    "                sampler=ws\n",
    "                     )\n",
    "\n",
    "test_ds = DS(X_test, y_test)\n",
    "test_dl = DataLoader(test_ds,\n",
    "               batch_size=BATCH_SIZE*2, \n",
    "               num_workers=3,\n",
    "               shuffle=True)\n",
    "\n",
    "# Train\n",
    "for epoch in range(EPOCHS):\n",
    "    print('TRAIN')\n",
    "    net = net.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for i, (inputs, labels) in enumerate(train_dl):\n",
    "        outputs = net(inputs.to(DEVI))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels.to(DEVI)).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = pt_max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "        if random()>0.95: print(f'{train_correct / train_total * 100:^5.2f}%', end=' ')\n",
    "    \n",
    "    # Eval\n",
    "    with no_grad():\n",
    "        net = net.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        for i, (inputs, labels) in enumerate(test_dl):\n",
    "            outputs = net(inputs.to(DEVI))\n",
    "            _, predicted = pt_max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels.to(DEVI)).sum().item()\n",
    "            test_accuracy = test_correct / test_total * 100\n",
    "    print(f'===> TEST {test_accuracy:^5.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38b7348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T03:25:14.335392Z",
     "iopub.status.busy": "2022-03-24T03:25:14.334723Z",
     "iopub.status.idle": "2022-03-24T03:25:14.340064Z",
     "shell.execute_reply": "2022-03-24T03:25:14.339368Z"
    },
    "papermill": {
     "duration": 0.071576,
     "end_time": "2022-03-24T03:25:14.340224",
     "exception": false,
     "start_time": "2022-03-24T03:25:14.268648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1067.528973,
   "end_time": "2022-03-24T03:25:15.319338",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-24T03:07:27.790365",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
