{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%reset -sf\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'","metadata":{"execution":{"iopub.status.busy":"2022-01-24T07:01:22.608324Z","iopub.execute_input":"2022-01-24T07:01:22.608924Z","iopub.status.idle":"2022-01-24T07:01:22.818883Z","shell.execute_reply.started":"2022-01-24T07:01:22.608870Z","shell.execute_reply":"2022-01-24T07:01:22.817524Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"from torch.cuda import is_available\n\nDEVI = \"cuda\" if is_available() else \"cpu\"\n# device = \"cpu\"\nprint(\"==> Device:\", DEVI)\n\nfrom torch import manual_seed\nmanual_seed(16)\nfrom random import seed\nseed(16)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T07:01:22.821950Z","iopub.execute_input":"2022-01-24T07:01:22.822612Z","iopub.status.idle":"2022-01-24T07:01:22.835011Z","shell.execute_reply.started":"2022-01-24T07:01:22.822538Z","shell.execute_reply":"2022-01-24T07:01:22.833634Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"==> Device: cpu\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7fbb9c4dfb70>"},"metadata":{}}]},{"cell_type":"code","source":"BATCH_SIZE = 64\nLR = 0.0005","metadata":{"execution":{"iopub.status.busy":"2022-01-24T07:01:22.838058Z","iopub.execute_input":"2022-01-24T07:01:22.839026Z","iopub.status.idle":"2022-01-24T07:01:22.844111Z","shell.execute_reply.started":"2022-01-24T07:01:22.838971Z","shell.execute_reply":"2022-01-24T07:01:22.843185Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"from torch import nn, load\nfrom torch.utils.data import Dataset, DataLoader\n\nclass DS(Dataset):\n    def __init__(self, maps, labels) -> None:\n        self.maps = maps\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        X = self.maps[idx]\n        #X = X.reshape(1, -1)\n        X = X.unsqueeze(0)\n        y = self.labels[idx]\n        return X.to(DEVI, dtype=pt_float), y.to(DEVI, dtype=long)\n\n# Data\nX_train, y_train = load('/kaggle/input/pytorch-mnist/training.pt')\nX_test, y_test = load('/kaggle/input/pytorch-mnist/test.pt')\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-24T07:01:22.846350Z","iopub.execute_input":"2022-01-24T07:01:22.846890Z","iopub.status.idle":"2022-01-24T07:01:22.974945Z","shell.execute_reply.started":"2022-01-24T07:01:22.846853Z","shell.execute_reply":"2022-01-24T07:01:22.973804Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"(torch.Size([60000, 28, 28]),\n torch.Size([60000]),\n torch.Size([10000, 28, 28]),\n torch.Size([10000]))"},"metadata":{}}]},{"cell_type":"code","source":"from numpy import bincount\nfrom torch.utils.data import WeightedRandomSampler\n\n# balanced sampler\ncounts = bincount(y_train)\nlabels_weights = 1. / counts\nlist(zip(range(10), counts))\nweights = labels_weights[y_train]\nws = WeightedRandomSampler(weights, len(weights), replacement=True)\nws","metadata":{"execution":{"iopub.status.busy":"2022-01-24T07:08:12.318322Z","iopub.execute_input":"2022-01-24T07:08:12.318727Z","iopub.status.idle":"2022-01-24T07:08:12.332785Z","shell.execute_reply.started":"2022-01-24T07:08:12.318689Z","shell.execute_reply":"2022-01-24T07:08:12.331781Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"[(0, 5923),\n (1, 6742),\n (2, 5958),\n (3, 6131),\n (4, 5842),\n (5, 5421),\n (6, 5918),\n (7, 6265),\n (8, 5851),\n (9, 5949)]"},"metadata":{}},{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.sampler.WeightedRandomSampler at 0x7fbb8472af50>"},"metadata":{}}]},{"cell_type":"code","source":"from torch import float as pt_float, ones\n\nclass NET(nn.Module):\n    def __init__(self, \n                 l1, k1, a1, l2, k2, a2, l3, k3, a3, l4, k4, a4):\n        super().__init__()\n        \n        self.cnn1 = nn.Sequential(\n            nn.LazyConv2d(l1, k1),\n            nn.Dropout(0.5),\n            nn.__getattribute__(a1)())\n        \n        self.cnn2 = nn.Sequential(\n            nn.LazyBatchNorm2d(),\n            nn.LazyConv2d(l2, k2),\n            nn.Dropout(0.5),\n            nn.__getattribute__(a2)())\n\n        self.cnn3 = nn.Sequential(\n            nn.LazyBatchNorm2d(),\n            nn.LazyConv2d(l3, k3),\n            nn.Dropout(0.5),\n            nn.__getattribute__(a3)())\n\n        self.cnn4 = nn.Sequential(\n            nn.LazyBatchNorm2d(),\n            nn.LazyConv2d(l4, k4),\n            nn.Dropout(0.5),\n            nn.__getattribute__(a4)())\n\n        self.out = nn.Sequential(\n            nn.Flatten(),\n            nn.LazyLinear(10),\n            nn.LogSoftmax(dim=-1))\n        \n        self.model = nn.Sequential(\n            self.cnn1,\n            self.cnn2,\n            self.cnn3,\n            self.cnn4,\n            self.out\n        )\n                \n    def forward(self, x):\n        \"\"\"Forward\"\"\"\n        return self.model(x)\n    \n    def count_weights_biases(self):\n        return int(sum(p.numel() for p in self.parameters() if p.requires_grad))\n    \nnet = NET(10, 2, 'SELU', 10, 2, 'SELU', 10, 2, 'SELU', 10, 2, 'SELU', ).to(DEVI)\nf'Dry run: {net(ones(1, 1, 28, 28).to(DEVI, dtype=pt_float)).shape}'","metadata":{"execution":{"iopub.status.busy":"2022-01-24T07:01:22.992819Z","iopub.execute_input":"2022-01-24T07:01:22.993383Z","iopub.status.idle":"2022-01-24T07:01:23.022968Z","shell.execute_reply.started":"2022-01-24T07:01:22.993335Z","shell.execute_reply":"2022-01-24T07:01:23.021983Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"'Dry run: torch.Size([1, 10])'"},"metadata":{}}]},{"cell_type":"code","source":"class GA_Pytorch():\n    def __init__(self, \n                 params, \n                 eval_func,\n                 eval_weights,\n                 #\n                 X_train,\n                 X_test,\n                 y_train,\n                 y_test,\n                 #\n                 batch_size=BATCH_SIZE,\n                 lr=LR,\n                 #\n                 sel_tournsize=2, \n                 cx_uniform_prob=0.5, \n                 mut_shuffle_idx_prob=0.1,\n                 #\n                 n_pop=10, \n                 n_gen=5, \n                 #\n                 n_hof=5, \n                 cx_prob=0.5, \n                 mut_prob=0.1, \n                 n_jobs=1\n                ):\n        self.params = params\n        self.eval_func = eval_func\n        self.eval_weights = eval_weights\n        \n        self.X_train = X_train\n        self.X_test = X_test\n        self.y_train = y_train\n        self.y_test = y_test\n        self.batch_size = batch_size\n        self.lr = lr\n        \n        self.sel_tournsize = sel_tournsize\n        self.cx_uniform_prob = cx_uniform_prob\n        self.mut_shuffle_idx_prob = mut_shuffle_idx_prob\n        self.n_pop = n_pop\n        self.n_gen = n_gen\n        self.n_hof = n_hof\n        self.cx_prob = cx_prob\n        self.mut_prob = mut_prob\n        \n        self.n_jobs = n_jobs\n\n        self._pad_params()\n        self._create_fitness_and_indiv()\n        self._register_indiv_and_pop_generators()\n        self._register_eval_func()\n        self._register_selection_crossover_mutation_methods()\n\n    def _pad_params(self):\n        \"\"\"Pad params for crossover shuffle idx method\"\"\"\n        assert isinstance(self.params, dict), 'Params must be a dict, i.e. estimator.get_params()'\n        params_count = {k: len(v) for k,v in self.params.items()}\n        max_length, max_key = -99, ''\n        for k, v in params_count.items():\n            if v <= max_length:\n                continue\n            else:\n                max_key = k\n                max_length = v\n        assert isinstance(max_length, int), 'The max length between all params must be an int'\n        # cycle through params for max length param, otherwise infinite cycle\n        values_padded = (cycle(v) if k!=max_key else v for k,v in self.params.items())\n        values_padded = zip(*values_padded)  # ('a', 1, 14), ('b', 2, 16), ('c', 3, 16) ...\n        values_padded = zip(*values_padded)  # ('a', 'b', 'c'), (1, 2, 3), (14, 15, 16)...\n        padded_params = {}\n        for k, v in zip(self.params, values_padded):\n            padded_params[k] = v\n        self.padded_params = padded_params\n        print('Params padded')\n\n    def _create_fitness_and_indiv(self):\n        \"\"\"Create GA individual and fitness entities (classes)\"\"\"\n        ga_cr.create('Fitness', ga_b.Fitness, weights=self.eval_weights)\n        ga_cr.create('Individual', list, fitness=ga_cr.Fitness)\n        print('GA entities created')\n\n    def _gen_params_to_ga(self):\n        \"\"\"Generate index for each param for individual\"\"\"\n        max_dict = len(self.padded_params)\n        max_length = len(list(self.padded_params.values())[0])\n        idxs = [randint(0, max_length-1) for _ in range(max_dict)]\n        return idxs\n    \n    def _register_indiv_and_pop_generators(self):\n        \"\"\"Register GA individual and population generators\"\"\"\n        self.tb = ga_b.Toolbox()\n\n        if self.n_jobs > 1:\n            from multiprocessing import Pool\n            pool = Pool()\n            self.tb.register(\"map\", pool.map)\n\n        self.tb.register(\"individual\", ga_t.initIterate, ga_cr.Individual, self._gen_params_to_ga)\n        self.tb.register(\"population\", ga_t.initRepeat, list, self.tb.individual)\n        print('GA entities\\' methods registered')\n        \n    def _register_eval_func(self):\n        \"\"\"Set GA evaluate individual function\"\"\"\n        self.tb.register(\"evaluate\",\n                        self.eval_func,\n                        padded_params=self.padded_params,\n                        X_train=self.X_train,\n                        X_test=self.X_test, \n                        y_train=self.y_train, \n                        y_test=self.y_test,\n                        batch_size=self.batch_size,\n                        lr=self.lr)\n        #print(list(self.tb.evaluate(indiv) for indiv in self.tb.population(3)))\n        print('GA eval function registered')\n    \n    def _register_selection_crossover_mutation_methods(self):\n        self.tb.register(\"select\", ga_t.selTournament, tournsize=self.sel_tournsize)\n        self.tb.register(\"mate\", ga_t.cxUniform, indpb=self.cx_uniform_prob)\n        self.tb.register(\"mutate\", ga_t.mutShuffleIndexes, indpb=self.mut_shuffle_idx_prob)\n        print('GA sel-cx-mut methods registered')\n        \n    def run_ga_search(self):\n        \"\"\"GA Search\"\"\"\n        pop = self.tb.population(n=self.n_pop)\n        hof = ga_t.HallOfFame(self.n_hof)\n\n        # Stats stdout\n        #stats = ga_t.Statistics(lambda ind: ind.fitness.values )\n        stats1 = ga_t.Statistics(lambda ind: ind.fitness.values[0] )\n        stats2 = ga_t.Statistics(lambda ind: ind.fitness.values[1] )\n        stats3 = ga_t.Statistics(lambda ind: ind.fitness.values[2] )\n        stats = ga_t.MultiStatistics(accuracy=stats1, risk=stats2, complexity=stats3)\n        stats.register(\"avg\", mean)\n        #stats.register(\"std\", np.std)\n        #stats.register(\"min\", np.min)\n        #stats.register(\"max\", np.max)\n\n        # History\n        #hist = tools.History()\n        #toolbox.decorate(\"select\", hist.decorator)\n        #tb.decorate(\"mate\", hist.decorator)\n        #tb.decorate(\"mutate\", hist.decorator)\n        #hist.update(pop)\n\n        # GA Run\n        pop, log = ga_algo.eaSimple(pop, self.tb, cxpb=self.cx_prob, \n                                    mutpb=self.mut_prob, ngen=self.n_gen, \n                                    stats=stats, halloffame=hof, verbose=True)\n        \n        # Convert back params\n        hof_ = {}\n        for i in range(self.n_hof):\n            hof_['hof_' + str(i)] = self._ga_to_params(hof[i])\n\n        return pop, log, hof_\n    \n    def _ga_to_params(self, idx_params):\n        \"\"\"Convert back idx to params\"\"\"\n        res = {}\n        for (k,v), idx in zip(self.padded_params.items(), idx_params):\n            res[k] = v[idx]\n        return res","metadata":{"execution":{"iopub.status.busy":"2022-01-24T07:01:23.024976Z","iopub.execute_input":"2022-01-24T07:01:23.025374Z","iopub.status.idle":"2022-01-24T07:01:23.058118Z","shell.execute_reply.started":"2022-01-24T07:01:23.025345Z","shell.execute_reply":"2022-01-24T07:01:23.056880Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"from numpy import mean, linspace, inf\n\nnet_params = {\n    'l1': linspace(1,20,20).astype(int),\n    'k1': linspace(1,20,20).astype(int),\n    'a1': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n    'l2': linspace(1,20,20).astype(int),\n    'k2': linspace(1,20,20).astype(int),\n    'a2': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n    'l3': linspace(1,20,20).astype(int),\n    'k3': linspace(1,20,20).astype(int),\n    'a3': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n    'l4': linspace(1,20,20).astype(int),\n    'k4': linspace(1,20,20).astype(int),\n    'a4': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n}\n\ndef net_eval_indiv(individual, padded_params, X_train, X_test, y_train, y_test, batch_size, lr):\n    \"\"\"Evaluate individual's genes (estimator's params)\"\"\"\n\n    # Params\n    indiv_params = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual)}\n    \n    # Net\n    net = NET(**indiv_params).to(DEVI)\n    try:\n        net(ones(1,1,28,28).to(DEVI))\n    except BaseException as e:\n        print('=> Possible Arch Error:', e)\n        return (0.01, (1/10)**10, 1000000)\n    \n    # Optimizer\n    optimizer = Adam(net.parameters(), lr=lr)\n    criterion = nn.NLLLoss()\n    \n    # Train\n    train_ds = DS(X_train, y_train)  # TODO refactor out\n    train_dl = DataLoader(train_ds,\n                        batch_size=batch_size,\n                        #shuffle=True,\n                        sampler=ws,\n                        num_workers=3,\n                        drop_last=True,\n                         )\n    \n    for epoch in range(1):\n        train_correct = 0\n        train_total = 0\n        for i, (inputs, labels) in enumerate(train_dl):\n            if i <= 50:\n                outputs = net(inputs.to(DEVI))\n\n                optimizer.zero_grad()\n                loss = criterion(outputs, labels).mean()\n                loss.backward()\n                optimizer.step()\n\n                _, predicted = pt_max(outputs.data, 1)\n                train_total += labels.size(0)\n                train_correct += (predicted == labels.to(DEVI)).sum().item()\n            else:\n                break\n        \n    # Eval\n    with no_grad():\n        net = net.eval()\n        test_ds = DS(X_test, y_test)  # TODO refactor out\n        test_dl = DataLoader(test_ds,\n                            batch_size=batch_size,\n                            num_workers=3,\n                            shuffle=True,\n                            drop_last=True)\n        #running_loss = []\n        test_correct = 0\n        test_total = 0\n        for i, (inputs, labels) in enumerate(test_dl):\n            if i <= 50:\n                outputs = net(inputs.to(DEVI))\n\n                _, predicted = pt_max(outputs.data, 1)\n                test_total += labels.size(0)\n                test_correct += (predicted == labels.to(DEVI)).sum().item()\n                test_accuracy = test_correct / test_total * 100\n            else:\n                break\n        \n    # Risk\n    risk = median(prod(net(inputs).exp()*10, dim=1))\n    if isnan(risk):\n        risk = 10\n    else:\n        risk = float(risk)\n        \n    # Complexity\n    compl = net.count_weights_biases()\n\n    return (test_accuracy, risk, compl,)\n\nnet_weights = (1, -1, -1)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T07:01:23.060115Z","iopub.execute_input":"2022-01-24T07:01:23.060694Z","iopub.status.idle":"2022-01-24T07:01:23.088188Z","shell.execute_reply.started":"2022-01-24T07:01:23.060650Z","shell.execute_reply":"2022-01-24T07:01:23.086790Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"from itertools import cycle\nfrom deap import creator as ga_cr, base as ga_b, algorithms as ga_algo, tools as ga_t\nfrom random import randint\nfrom numpy import mean\nfrom torch.optim import Adam\nfrom torch import max as pt_max, no_grad, median, prod, isnan, long\n\nnet_ga_params = GA_Pytorch(net_params, \n                           net_eval_indiv, \n                           net_weights,\n                           X_train, \n                           X_test, \n                           y_train, \n                           y_test)\npop, log, hof = net_ga_params.run_ga_search()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T07:01:23.089625Z","iopub.execute_input":"2022-01-24T07:01:23.090277Z","iopub.status.idle":"2022-01-24T07:02:24.815808Z","shell.execute_reply.started":"2022-01-24T07:01:23.090237Z","shell.execute_reply":"2022-01-24T07:02:24.813264Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Params padded\nGA entities created\nGA entities' methods registered\nGA eval function registered\nGA sel-cx-mut methods registered\n=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Fitness' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n  RuntimeWarning)\n/opt/conda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n  RuntimeWarning)\n","output_type":"stream"},{"name":"stdout","text":"=> Possible Arch Error: Calculated padded input size per channel: (9 x 9). Kernel size: (15 x 15). Kernel size can't be greater than actual input size\n=> Possible Arch Error: Expected more than 1 value per channel when training, got input size torch.Size([1, 14, 1, 1])\n=> Possible Arch Error: Calculated padded input size per channel: (12 x 12). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (16 x 16). Kernel size can't be greater than actual input size\n=> Possible Arch Error: Expected more than 1 value per channel when training, got input size torch.Size([1, 6, 1, 1])\n=> Possible Arch Error: Expected more than 1 value per channel when training, got input size torch.Size([1, 2, 1, 1])\n   \t      \t       accuracy       \t      complexity      \t             risk             \n   \t      \t----------------------\t----------------------\t------------------------------\ngen\tnevals\tavg    \tgen\tnevals\tavg   \tgen\tnevals\tavg      \tgen\tnevals\n0  \t10    \t15.1632\t0  \t10    \t708404\t0  \t10    \t0.0106069\t0  \t10    \n=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n=> Possible Arch Error: Calculated padded input size per channel: (13 x 13). Kernel size: (14 x 14). Kernel size can't be greater than actual input size\n1  \t2     \t45.0204\t1  \t2     \t231634\t1  \t2     \t0.00780816\t1  \t2     \n2  \t2     \t54.9295\t2  \t2     \t39023.8\t2  \t2     \t0.0153818 \t2  \t2     \n=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (11 x 11). Kernel size can't be greater than actual input size\n=> Possible Arch Error: Calculated padded input size per channel: (8 x 8). Kernel size: (9 x 9). Kernel size can't be greater than actual input size\n3  \t6     \t48.5529\t3  \t6     \t236572 \t3  \t6     \t0.00612861\t3  \t6     \n4  \t2     \t58.7081\t4  \t2     \t148324 \t4  \t2     \t0.0136245 \t4  \t2     \n=> Possible Arch Error: Expected more than 1 value per channel when training, got input size torch.Size([1, 18, 1, 1])\n5  \t7     \t61.6891\t5  \t7     \t148919 \t5  \t7     \t0.00379801\t5  \t7     \n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving params\n\nfrom pandas import DataFrame\nfrom joblib import dump, load\n\nDataFrame(hof)\ndump(hof, 'best_params.json')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T07:02:24.819111Z","iopub.execute_input":"2022-01-24T07:02:24.820238Z","iopub.status.idle":"2022-01-24T07:02:24.845432Z","shell.execute_reply.started":"2022-01-24T07:02:24.820172Z","shell.execute_reply":"2022-01-24T07:02:24.844403Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"       hof_0     hof_1     hof_2 hof_3 hof_4\nl1         1         1         1     1     1\nk1         5         5         5     5     5\na1  Softsign      SELU      SELU  SELU  SELU\nl2        13        13        13    13    13\nk2         5         5         5    12    12\na2      CELU  Softsign  Softsign  CELU  CELU\nl3        18        10        10    18    18\nk3         2         2         2     2     2\na3      SELU      SELU      SELU  SELU  SELU\nl4        20        20        20    20    20\nk4        11         9         9    11    11\na4      ReLU      ReLU      ReLU  ReLU  ReLU","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hof_0</th>\n      <th>hof_1</th>\n      <th>hof_2</th>\n      <th>hof_3</th>\n      <th>hof_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>l1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>k1</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>a1</th>\n      <td>Softsign</td>\n      <td>SELU</td>\n      <td>SELU</td>\n      <td>SELU</td>\n      <td>SELU</td>\n    </tr>\n    <tr>\n      <th>l2</th>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>k2</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>12</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>a2</th>\n      <td>CELU</td>\n      <td>Softsign</td>\n      <td>Softsign</td>\n      <td>CELU</td>\n      <td>CELU</td>\n    </tr>\n    <tr>\n      <th>l3</th>\n      <td>18</td>\n      <td>10</td>\n      <td>10</td>\n      <td>18</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>k3</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>a3</th>\n      <td>SELU</td>\n      <td>SELU</td>\n      <td>SELU</td>\n      <td>SELU</td>\n      <td>SELU</td>\n    </tr>\n    <tr>\n      <th>l4</th>\n      <td>20</td>\n      <td>20</td>\n      <td>20</td>\n      <td>20</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>k4</th>\n      <td>11</td>\n      <td>9</td>\n      <td>9</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>a4</th>\n      <td>ReLU</td>\n      <td>ReLU</td>\n      <td>ReLU</td>\n      <td>ReLU</td>\n      <td>ReLU</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"['best_params.json']"},"metadata":{}}]},{"cell_type":"code","source":"# Full train\nEPOCHS = 5\n\n# Params\nparams = load('best_params.json')['hof_0']\n\n# Net\nnet = NET(**params).to(DEVI)\n\n# Optimizer\noptimizer = Adam(net.parameters(), lr=LR*.75)\ncriterion = nn.NLLLoss()\n\n# Data\ntrain_ds = DS(X_train, y_train)\ntrain_dl = DataLoader(train_ds, \n               batch_size=BATCH_SIZE*2, \n               num_workers=3,\n               drop_last=True,\n               #shuffle=True\n                sampler=ws\n                     )\n\ntest_ds = DS(X_test, y_test)\ntest_dl = DataLoader(test_ds,\n               batch_size=BATCH_SIZE*2, \n               num_workers=3,\n               shuffle=True)\n\n# Train\nfor epoch in range(EPOCHS):\n    net = net.train()\n    train_correct = 0\n    train_total = 0\n    for i, (inputs, labels) in enumerate(train_dl):\n        outputs = net(inputs.to(DEVI))\n\n        optimizer.zero_grad()\n        loss = criterion(outputs, labels.to(DEVI)).mean()\n        loss.backward()\n        optimizer.step()\n\n        _, predicted = pt_max(outputs.data, 1)\n        train_total += labels.size(0)\n        train_correct += (predicted == labels.to(DEVI)).sum().item()\n    print(f'TRAIN {train_correct / train_total * 100:^5.2f} %', end=' ')\n    \n    # Eval\n    with no_grad():\n        net = net.eval()\n        test_correct = 0\n        test_total = 0\n        for i, (inputs, labels) in enumerate(test_dl):\n            outputs = net(inputs.to(DEVI))\n            _, predicted = pt_max(outputs.data, 1)\n            test_total += labels.size(0)\n            test_correct += (predicted == labels.to(DEVI)).sum().item()\n            test_accuracy = test_correct / test_total * 100\n    print(f'=> TEST {test_accuracy:^5.2f} %')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T07:02:24.846948Z","iopub.execute_input":"2022-01-24T07:02:24.847490Z","iopub.status.idle":"2022-01-24T07:07:17.350762Z","shell.execute_reply.started":"2022-01-24T07:02:24.847426Z","shell.execute_reply":"2022-01-24T07:07:17.349076Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n  warnings.warn('Lazy modules are a new feature under heavy development '\n","output_type":"stream"},{"name":"stdout","text":"TRAIN 77.89 % => TEST 94.38 %\nTRAIN 90.96 % => TEST 96.28 %\nTRAIN 93.01 % => TEST 96.95 %\nTRAIN 94.39 % => TEST 97.63 %\nTRAIN 94.87 % => TEST 97.98 %\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}