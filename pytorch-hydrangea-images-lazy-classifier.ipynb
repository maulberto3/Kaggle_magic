{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:27.002612Z","iopub.execute_input":"2022-01-14T23:15:27.002854Z","iopub.status.idle":"2022-01-14T23:15:27.007264Z","shell.execute_reply.started":"2022-01-14T23:15:27.002829Z","shell.execute_reply":"2022-01-14T23:15:27.006458Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"from torch import manual_seed\nfrom random import seed\nmanual_seed(16)\nseed(16)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:27.009735Z","iopub.execute_input":"2022-01-14T23:15:27.010019Z","iopub.status.idle":"2022-01-14T23:15:27.025146Z","shell.execute_reply.started":"2022-01-14T23:15:27.009989Z","shell.execute_reply":"2022-01-14T23:15:27.024643Z"},"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7ff9a1ad5990>"},"metadata":{}}]},{"cell_type":"code","source":"from pprint import pprint\nfrom pathlib import Path\n\npath = Path('/kaggle/input/hydrangea-dataset-compressed/data_CNN')\nlist(path.glob('*'))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:27.026323Z","iopub.execute_input":"2022-01-14T23:15:27.026783Z","iopub.status.idle":"2022-01-14T23:15:27.044678Z","shell.execute_reply.started":"2022-01-14T23:15:27.026753Z","shell.execute_reply":"2022-01-14T23:15:27.043681Z"},"trusted":true},"execution_count":119,"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"[PosixPath('/kaggle/input/hydrangea-dataset-compressed/data_CNN/test'),\n PosixPath('/kaggle/input/hydrangea-dataset-compressed/data_CNN/train')]"},"metadata":{}}]},{"cell_type":"code","source":"train_path = path / 'train'\ntest_path = path / 'test'","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:27.046782Z","iopub.execute_input":"2022-01-14T23:15:27.047016Z","iopub.status.idle":"2022-01-14T23:15:27.053931Z","shell.execute_reply.started":"2022-01-14T23:15:27.046983Z","shell.execute_reply":"2022-01-14T23:15:27.052391Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"from torch.cuda import is_available\n\ndevi = 'cuda' if is_available() else 'cpu'\ndevi","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:27.055009Z","iopub.execute_input":"2022-01-14T23:15:27.055520Z","iopub.status.idle":"2022-01-14T23:15:27.067098Z","shell.execute_reply.started":"2022-01-14T23:15:27.055489Z","shell.execute_reply":"2022-01-14T23:15:27.066175Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"'cpu'"},"metadata":{}}]},{"cell_type":"code","source":"EPOCHS = 10\nBATCH_SIZE = 128\nLR = 0.0005","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:27.068342Z","iopub.execute_input":"2022-01-14T23:15:27.068769Z","iopub.status.idle":"2022-01-14T23:15:27.080071Z","shell.execute_reply.started":"2022-01-14T23:15:27.068736Z","shell.execute_reply":"2022-01-14T23:15:27.079210Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import Compose, ToTensor, Normalize, Resize, ColorJitter, GaussianBlur, RandomHorizontalFlip, RandomVerticalFlip\n\ntransf = Compose([\n    RandomHorizontalFlip(),\n    RandomVerticalFlip(),\n    ColorJitter(0.1, 0.1, 0.1),\n    GaussianBlur(1),\n    Resize((95,95)),\n    ToTensor(),\n    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\nimg_tr = ImageFolder(train_path, transform=transf)\nimg_tr[0][0].shape\n\nimg_te = ImageFolder(test_path, transform=transf)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:27.081493Z","iopub.execute_input":"2022-01-14T23:15:27.081863Z","iopub.status.idle":"2022-01-14T23:15:27.128339Z","shell.execute_reply.started":"2022-01-14T23:15:27.081829Z","shell.execute_reply":"2022-01-14T23:15:27.127149Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"torch.Size([3, 95, 95])"},"metadata":{}}]},{"cell_type":"code","source":"from torch import nn\nfrom torch import float as pt_float, ones\n\nclass NET(nn.Module):\n    def __init__(self, \n                 l1, k1, a1, l2, k2, a2, l3, k3, a3):\n        super().__init__()\n        \n        self.cnn1 = nn.Sequential(\n            nn.LazyConv2d(l1, k1),\n            nn.Dropout(0.5),\n            nn.__getattribute__(a1)())\n        \n        self.cnn2 = nn.Sequential(\n            nn.LazyConv2d(l2, k2),\n            nn.Dropout(0.5),\n            nn.__getattribute__(a2)())\n\n        self.cnn3 = nn.Sequential(\n            nn.LazyConv2d(l3, k3),\n            nn.Dropout(0.5),\n            nn.__getattribute__(a3)())\n\n        self.out = nn.Sequential(\n            nn.Flatten(),\n            nn.LazyLinear(10),\n            nn.LogSoftmax(dim=-1))\n        \n        self.model = nn.Sequential(\n            self.cnn1,\n            self.cnn2,\n            self.cnn3,\n            self.out\n        )\n                \n    def forward(self, x):\n        \"\"\"Forward\"\"\"\n        return self.model(x)\n    \n    def count_weights_biases(self):\n        return int(sum(p.numel() for p in self.parameters() if p.requires_grad))\n    \nnet = NET(10, 2, 'SELU', 10, 2, 'SELU', 10, 2, 'SELU').to(devi)\nf'Dry run: {net(ones(1, 1, 28, 28).to(devi, dtype=pt_float)).shape}'","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:27.130058Z","iopub.execute_input":"2022-01-14T23:15:27.130275Z","iopub.status.idle":"2022-01-14T23:15:27.157909Z","shell.execute_reply.started":"2022-01-14T23:15:27.130247Z","shell.execute_reply":"2022-01-14T23:15:27.156989Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"'Dry run: torch.Size([1, 10])'"},"metadata":{}}]},{"cell_type":"code","source":"class GA_Pytorch():\n    def __init__(self, \n                 params, \n                 eval_func,\n                 eval_weights,\n                 #\n                 train_df,\n                 test_df,\n                 #\n                 sel_tournsize=2, \n                 cx_uniform_prob=0.5, \n                 mut_shuffle_idx_prob=0.1, \n                 n_pop=50, \n                 n_gen=20, \n                 n_hof=5, \n                 cx_prob=0.5, \n                 mut_prob=0.1, \n                 #\n                 n_jobs=1\n                ):\n        self.params = params\n        self.eval_func = eval_func\n        self.eval_weights = eval_weights\n        \n        self.train_df=train_df\n        self.test_df=test_df\n        \n        self.sel_tournsize = sel_tournsize\n        self.cx_uniform_prob = cx_uniform_prob\n        self.mut_shuffle_idx_prob = mut_shuffle_idx_prob\n        self.n_pop = n_pop\n        self.n_gen = n_gen\n        self.n_hof = n_hof\n        self.cx_prob = cx_prob\n        self.mut_prob = mut_prob\n        \n        self.n_jobs = n_jobs\n\n        self._pad_params()\n        self._create_fitness_and_indiv()\n        self._register_indiv_and_pop_generators()\n        self._register_eval_func()\n        self._register_selection_crossover_mutation_methods()\n\n    def _pad_params(self):\n        \"\"\"Pad params for crossover shuffle idx method\"\"\"\n        assert isinstance(self.params, dict), 'Params must be a dict, i.e. estimator.get_params()'\n        params_count = {k: len(v) for k,v in self.params.items()}\n        max_length, max_key = -99, ''\n        for k, v in params_count.items():\n            if v <= max_length:\n                continue\n            else:\n                max_key = k\n                max_length = v\n        assert isinstance(max_length, int), 'The max length between all params must be an int'\n        # cycle through params for max length param, otherwise infinite cycle\n        values_padded = (cycle(v) if k!=max_key else v for k,v in self.params.items())\n        values_padded = zip(*values_padded)  # ('a', 1, 14), ('b', 2, 16), ('c', 3, 16) ...\n        values_padded = zip(*values_padded)  # ('a', 'b', 'c'), (1, 2, 3), (14, 15, 16)...\n        padded_params = {}\n        for k, v in zip(self.params, values_padded):\n            padded_params[k] = v\n        self.padded_params = padded_params\n        print('Params padded')\n\n    def _create_fitness_and_indiv(self):\n        \"\"\"Create GA individual and fitness entities (classes)\"\"\"\n        ga_cr.create('Fitness', ga_b.Fitness, weights=self.eval_weights)\n        ga_cr.create('Individual', list, fitness=ga_cr.Fitness)\n        print('GA entities created')\n\n    def _gen_params_to_ga(self):\n        \"\"\"Generate index for each param for individual\"\"\"\n        max_dict = len(self.padded_params)\n        max_length = len(list(self.padded_params.values())[0])\n        idxs = [randint(0, max_length-1) for _ in range(max_dict)]\n        return idxs\n    \n    def _register_indiv_and_pop_generators(self):\n        \"\"\"Register GA individual and population generators\"\"\"\n        self.tb = ga_b.Toolbox()\n\n        if self.n_jobs > 1:\n            from multiprocessing import Pool\n            pool = Pool()\n            self.tb.register(\"map\", pool.map)\n\n        self.tb.register(\"individual\", ga_t.initIterate, ga_cr.Individual, self._gen_params_to_ga)\n        self.tb.register(\"population\", ga_t.initRepeat, list, self.tb.individual)\n        print('GA entities\\' methods registered')\n        \n    def _register_eval_func(self):\n        \"\"\"Set GA evaluate individual function\"\"\"\n        self.tb.register(\"evaluate\",\n                        self.eval_func,\n                        padded_params=self.padded_params,\n                        train_path=self.train_df,\n                        test_path=self.test_df,\n                        batch_size=BATCH_SIZE,\n                        lr=LR)\n        #print(list(self.tb.evaluate(indiv) for indiv in self.tb.population(3)))\n        print('GA eval function registered')\n    \n    def _register_selection_crossover_mutation_methods(self):\n        self.tb.register(\"select\", ga_t.selTournament, tournsize=self.sel_tournsize)\n        self.tb.register(\"mate\", ga_t.cxUniform, indpb=self.cx_uniform_prob)\n        self.tb.register(\"mutate\", ga_t.mutShuffleIndexes, indpb=self.mut_shuffle_idx_prob)\n        print('GA sel-cx-mut methods registered')\n        \n    def run_ga_search(self):\n        \"\"\"GA Search\"\"\"\n        pop = self.tb.population(n=self.n_pop)\n        hof = ga_t.HallOfFame(self.n_hof)\n\n        # Stats stdout\n        #stats = ga_t.Statistics(lambda ind: ind.fitness.values )\n        stats1 = ga_t.Statistics(lambda ind: ind.fitness.values[0] )\n        stats2 = ga_t.Statistics(lambda ind: ind.fitness.values[1] )\n        stats3 = ga_t.Statistics(lambda ind: ind.fitness.values[2] )\n        stats = ga_t.MultiStatistics(accuracy=stats1, risk=stats2, complexity=stats3)\n        stats.register(\"avg\", mean)\n        #stats.register(\"std\", np.std)\n        #stats.register(\"min\", np.min)\n        #stats.register(\"max\", np.max)\n\n        # History\n        #hist = tools.History()\n        #toolbox.decorate(\"select\", hist.decorator)\n        #tb.decorate(\"mate\", hist.decorator)\n        #tb.decorate(\"mutate\", hist.decorator)\n        #hist.update(pop)\n\n        # GA Run\n        pop, log = ga_algo.eaSimple(pop, self.tb, cxpb=self.cx_prob, \n                                    mutpb=self.mut_prob, ngen=self.n_gen, \n                                    stats=stats, halloffame=hof, verbose=True)\n        \n        # Convert back params\n        hof_ = {}\n        for i in range(self.n_hof):\n            hof_['hof_' + str(i)] = self._ga_to_params(hof[i])\n\n        return pop, log, hof_\n    \n    def _ga_to_params(self, idx_params):\n        \"\"\"Convert back idx to params\"\"\"\n        res = {}\n        for (k,v), idx in zip(self.padded_params.items(), idx_params):\n            res[k] = v[idx]\n        return res","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:27.160326Z","iopub.execute_input":"2022-01-14T23:15:27.160902Z","iopub.status.idle":"2022-01-14T23:15:27.196388Z","shell.execute_reply.started":"2022-01-14T23:15:27.160871Z","shell.execute_reply":"2022-01-14T23:15:27.194941Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"from numpy import mean, linspace, inf\n\nnet_params = {\n    'l1': linspace(1,20,20).astype(int),\n    'k1': linspace(1,20,20).astype(int),\n    'a1': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n    'l2': linspace(1,20,20).astype(int),\n    'k2': linspace(1,20,20).astype(int),\n    'a2': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n    'l3': linspace(1,20,20).astype(int),\n    'k3': linspace(1,20,20).astype(int),\n    'a3': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n}\n\ndef net_eval_indiv(individual, padded_params, train_path, test_path, batch_size, lr):\n    \"\"\"Evaluate individual's genes (estimator's params)\"\"\"\n\n    # Params\n    indiv_params = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual)}\n    \n    # Net\n    net = NET(**indiv_params).to(devi)\n    try:\n        net(ones(1,3,95,95).to(devi))\n    except BaseException as e:\n        print('=> Possible Arch Error:', e)\n        return (0.01, (1/10)**10, 1000000)\n    \n    # Optimizer\n    optimizer = Adam(net.parameters(), lr=lr)\n    criterion = nn.NLLLoss()\n    \n    # Data\n    train_dl = DataLoader(img_tr, \n                   batch_size=batch_size, \n                   #num_workers=2,\n                   drop_last=True,\n                   shuffle=True)\n    \n    test_dl = DataLoader(img_te, \n                   batch_size=batch_size, \n                   #num_workers=2,\n                   drop_last=True,\n                   shuffle=True)\n    \n    # Train\n    for epoch in range(EPOCHS):\n        train_correct = 0\n        train_total = 0\n        for i, (inputs, labels) in enumerate(train_dl):\n            if i <= 100:\n                outputs = net(inputs)\n\n                optimizer.zero_grad()\n                loss = criterion(outputs, labels).mean()\n                loss.backward()\n                optimizer.step()\n\n                _, predicted = pt_max(outputs.data, 1)\n                train_total += labels.size(0)\n                train_correct += (predicted == labels).sum().item()\n            else:\n                break\n        #print(f'TRAIN {train_correct / train_total * 100:^5.2f} %', end=' ')\n        \n    # Eval\n    with no_grad():\n        net = net.eval()\n        test_correct = 0\n        test_total = 0\n        for i, (inputs, labels) in enumerate(test_dl):\n            if i <= 50:\n                outputs = net(inputs)\n                _, predicted = pt_max(outputs.data, 1)\n                test_total += labels.size(0)\n                test_correct += (predicted == labels).sum().item()\n                test_accuracy = test_correct / test_total * 100\n            else:\n                break\n        #print(f'TEST {test_accuracy:^5.2f} %')\n        \n    # Risk\n    risk = median(prod(net(inputs).exp()*10, dim=1))\n    if isnan(risk):\n        risk = 10\n    else:\n        risk = float(risk)\n        \n    # Complexity\n    compl = net.count_weights_biases()\n\n    return (test_accuracy, risk, compl,)\n\nnet_weights = (1, -1, -1)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:27.198376Z","iopub.execute_input":"2022-01-14T23:15:27.198681Z","iopub.status.idle":"2022-01-14T23:15:27.225602Z","shell.execute_reply.started":"2022-01-14T23:15:27.198651Z","shell.execute_reply":"2022-01-14T23:15:27.224711Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"from itertools import cycle\nfrom deap import creator as ga_cr, base as ga_b, algorithms as ga_algo, tools as ga_t\nfrom random import randint\nfrom numpy import mean\nfrom torch.optim import Adam\nfrom torch import max as pt_max, no_grad, median, prod, isnan\n\nnet_ga_params = GA_Pytorch(net_params, \n                           net_eval_indiv, \n                           net_weights,\n                           img_tr,\n                           img_te)\npop, log, hof = net_ga_params.run_ga_search()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:27.226622Z","iopub.execute_input":"2022-01-14T23:15:27.226816Z","iopub.status.idle":"2022-01-14T23:15:43.411033Z","shell.execute_reply.started":"2022-01-14T23:15:27.226788Z","shell.execute_reply":"2022-01-14T23:15:43.409324Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stdout","text":"Params padded\nGA entities created\nGA entities' methods registered\nGA eval function registered\nGA sel-cx-mut methods registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/1997626226.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                            \u001b[0mimg_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                            img_te)\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_ga_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_ga_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_33/1744784874.py\u001b[0m in \u001b[0;36mrun_ga_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         pop, log = ga_algo.eaSimple(pop, self.tb, cxpb=self.cx_prob, \n\u001b[1;32m    136\u001b[0m                                     \u001b[0mmutpb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmut_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                                     stats=stats, halloffame=hof, verbose=True)\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Convert back params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/1419247334.py\u001b[0m in \u001b[0;36mnet_eval_indiv\u001b[0;34m(individual, padded_params, train_path, test_path, batch_size, lr)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### HPs\n***","metadata":{}},{"cell_type":"code","source":"EPOCHS = 10\nBATCH_SIZE = 128\nLR = 0.0005","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:43.412215Z","iopub.status.idle":"2022-01-14T23:15:43.412571Z","shell.execute_reply.started":"2022-01-14T23:15:43.412368Z","shell.execute_reply":"2022-01-14T23:15:43.412386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data\n***","metadata":{}},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import Compose, ToTensor, Normalize, Resize, ColorJitter, GaussianBlur, RandomHorizontalFlip, RandomVerticalFlip\n\ntransf = Compose([\n    RandomHorizontalFlip(),\n    RandomVerticalFlip(),\n    ColorJitter(0.1, 0.1, 0.1),\n    GaussianBlur(1),\n    Resize((95,95)),\n    ToTensor(),\n    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrain_path\nimg_tr = ImageFolder(train_path, transform=transf)\nimg_tr[0][0].shape\ntr_dl = DataLoader(img_tr, \n                   batch_size=BATCH_SIZE, \n                   num_workers=1,\n                   drop_last=True)\n\nimg_te = ImageFolder(test_path, transform=transf)\nte_dl = DataLoader(img_tr, \n                   batch_size=BATCH_SIZE, \n                   num_workers=1,\n                   drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:43.414240Z","iopub.status.idle":"2022-01-14T23:15:43.414664Z","shell.execute_reply.started":"2022-01-14T23:15:43.414466Z","shell.execute_reply":"2022-01-14T23:15:43.414489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline\n***","metadata":{}},{"cell_type":"code","source":"from torch import nn, numel, float as pt_float, long as pt_long, mean, as_tensor, rand\nfrom torch.optim import Adam","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:43.416740Z","iopub.status.idle":"2022-01-14T23:15:43.417184Z","shell.execute_reply.started":"2022-01-14T23:15:43.416958Z","shell.execute_reply":"2022-01-14T23:15:43.416980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# linear, no dropout, no batchnorm, no cnn, \n\nclass BL_NET(nn.Module):\n    def __init__(self, in_features=3*95*95):\n        super().__init__()\n        self.in_features = in_features\n        \n        self.model = nn.Sequential(\n            nn.Flatten(),  # C * H * W\n            nn.Linear(self.in_features, 64),\n            nn.ReLU(),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 2),\n            nn.LogSoftmax(dim=-1)\n        )\n        \n        self.count_w_b()\n    \n    def forward(self, x):\n        return self.model(x)\n    \n    def count_w_b(self):\n        print(f'# Params: {sum(numel(p) for p in self.parameters()):,}')\n    \nbl_net = BL_NET().to(devi)\n#bl_net.count_w_b()\n#bl_net(next(iter(tr_dl))[0]).shape\n\nopt = Adam(bl_net.parameters(), lr=LR)\ncriterion = nn.NLLLoss(reduction='mean')\n\nbl_net = bl_net.train()\nfor epoch in range(EPOCHS):\n    running_acc = []\n    running_loss = []\n    for images, labels in tr_dl:\n        images = images.to(devi, dtype=pt_float)\n        labels = labels.to(devi, dtype=pt_long)\n\n        out = bl_net(images)\n        loss = criterion(out, labels)\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n        running_acc.append( (out.argmax(dim=1) == labels).sum() / len(labels) )\n        running_loss.append(loss)\n        \n    print(f'Epoch {epoch:^3} | Accuracy {mean(as_tensor(running_acc)):^3.2f} | Loss: {mean(as_tensor(running_loss)):^3.2f}')\n    \nbl_net = bl_net.eval()\ntest_acc = []\nfor images, labels in te_dl:\n    images = images.to(devi, dtype=pt_float)\n    labels = labels.to(devi, dtype=pt_long)\n\n    out = bl_net(images)\n\n    test_acc.append((out.argmax(dim=1) == labels).sum() / len(labels))\n\nprint(f'Test Accuracy {mean(as_tensor(test_acc)):^3.2f}')","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:43.419088Z","iopub.status.idle":"2022-01-14T23:15:43.419422Z","shell.execute_reply.started":"2022-01-14T23:15:43.419260Z","shell.execute_reply":"2022-01-14T23:15:43.419274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CNN\n***","metadata":{}},{"cell_type":"code","source":"class INPUTS(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.inputs = nn.Sequential(\n            nn.Conv2d(3, 32, 3),\n            nn.BatchNorm2d(32),\n            nn.MaxPool2d(2),\n            nn.Softshrink())\n        \n    def forward(self, x):\n        return self.inputs(x)\n\ninputs_block = INPUTS()\ninputs_block(rand(1,3,95,95)).shape","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:43.421924Z","iopub.status.idle":"2022-01-14T23:15:43.422486Z","shell.execute_reply.started":"2022-01-14T23:15:43.422259Z","shell.execute_reply":"2022-01-14T23:15:43.422290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BLOCK(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.block = nn.Sequential(\n            nn.Conv2d(32, 32, 3),\n            nn.Dropout2d(0.25),\n            nn.BatchNorm2d(32),\n            #nn.MaxPool2d(2),\n            nn.Softshrink(),\n            nn.ConstantPad2d(1, 0)\n        )\n        \n    def forward(self, x):\n        return self.block(x)\n\nblock = BLOCK()\nblock(rand(1,32,46,46)).shape\n","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:43.423341Z","iopub.status.idle":"2022-01-14T23:15:43.424648Z","shell.execute_reply.started":"2022-01-14T23:15:43.424248Z","shell.execute_reply":"2022-01-14T23:15:43.424294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RES_BLOCK(nn.Module):\n    def __init__(self, block):\n        super().__init__()\n        self.block = block\n        \n        self.pool = nn.AvgPool2d(2)\n        \n    def forward(self, x):\n        return self.pool(self.block(x) + x)\n\nres_block = RES_BLOCK(block)\nres_block(rand(1,32,46,46)).shape\n","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:43.426017Z","iopub.status.idle":"2022-01-14T23:15:43.426850Z","shell.execute_reply.started":"2022-01-14T23:15:43.426621Z","shell.execute_reply":"2022-01-14T23:15:43.426648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LINEAR(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.linear = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(800, int(800**0.5)),\n            nn.Dropout(0.25),\n            nn.Linear(int(800**0.5), 2),\n            nn.Dropout(0.25),\n            nn.LogSoftmax(dim=-1))\n        \n    def forward(self, x):\n        return self.linear(x)\n\nlinear = LINEAR()\nlinear(res_block(\n    res_block(\n        res_block(rand(1,32,46,46))))).shape\n","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:43.428587Z","iopub.status.idle":"2022-01-14T23:15:43.428972Z","shell.execute_reply.started":"2022-01-14T23:15:43.428778Z","shell.execute_reply":"2022-01-14T23:15:43.428804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class ARM...","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:43.430964Z","iopub.status.idle":"2022-01-14T23:15:43.431434Z","shell.execute_reply.started":"2022-01-14T23:15:43.431196Z","shell.execute_reply":"2022-01-14T23:15:43.431215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, inputs_block, res_block, linear):\n        super().__init__()\n        \n        self.inputs_block = inputs_block\n        self.res_block = res_block\n        self.linear = linear\n        \n        self.model = nn.Sequential(\n            self.inputs_block,\n            self.res_block,\n            self.res_block,\n            self.res_block,\n            #self.res_block,\n            #nn.Flatten()\n            self.linear,\n        )\n        \n        self.count_w_b()\n    \n    def forward(self, x):\n        return self.model(x)\n    \n    def count_w_b(self):\n        print(f'# Params: {sum(numel(p) for p in self.parameters()):,}')\n\ncnn_net = CNN(inputs_block, res_block, linear).to(devi)\ncnn_net(next(iter(tr_dl))[0]).shape\n\nopt = Adam(cnn_net.parameters(), lr=LR)\ncriterion = nn.NLLLoss(reduction='mean')\n\ncnn_net = cnn_net.train()\nfor epoch in range(25):\n    running_acc = []\n    running_loss = []\n    for images, labels in tr_dl:\n        images = images.to(devi, dtype=pt_float)\n        labels = labels.to(devi, dtype=pt_long)\n\n        out = cnn_net(images)\n        loss = criterion(out, labels)\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n        running_acc.append((out.argmax(dim=1) == labels).sum() / len(labels))\n        running_loss.append(loss)\n        \n    print(f'Epoch {epoch:^3} | Accuracy {mean(as_tensor(running_acc)):^3.2f} | Loss (-log(softmax())): {mean(as_tensor(running_loss)):^3.2f}')\n    \ncnn_net = cnn_net.eval()\ntest_acc = []\nfor images, labels in te_dl:\n    images = images.to(devi, dtype=pt_float)\n    labels = labels.to(devi, dtype=pt_long)\n\n    out = cnn_net(images)\n\n    test_acc.append((out.argmax(dim=1) == labels).sum() / len(labels))\n\nprint(f'Test Accuracy {mean(as_tensor(test_acc)):^3.2f}')","metadata":{"execution":{"iopub.status.busy":"2022-01-14T23:15:43.432564Z","iopub.status.idle":"2022-01-14T23:15:43.432883Z","shell.execute_reply.started":"2022-01-14T23:15:43.432719Z","shell.execute_reply":"2022-01-14T23:15:43.432736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}