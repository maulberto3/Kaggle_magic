{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pprint import pprint\nfrom collections import defaultdict, OrderedDict\nfrom random import choice, seed, randint\nfrom tqdm import tqdm\nfrom itertools import repeat, product, combinations, cycle\nfrom pathlib import Path\nfrom string import ascii_lowercase\n\nimport numpy as np\nimport pandas as pd\n\nfrom torch import optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.datasets import ImageFolder\nfrom torch import (load, amax as pt_amax, max as pt_max, ones, save, no_grad, stack, numel, tensor, \n                   manual_seed, sigmoid, tanh, add, mul, sub, div, amin as pt_amin, cat,\n                  maximum, minimum, device, cuda, rand, prod, median, log as pt_log, round as pt_round,\n                  isnan, flatten, mean)\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\n#from torchviz import make_dot\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n\nfrom deap import creator as ga_cr, base as ga_b, algorithms as ga_algo, tools as ga_t","metadata":{"execution":{"iopub.status.busy":"2022-01-05T02:39:54.598450Z","iopub.execute_input":"2022-01-05T02:39:54.598808Z","iopub.status.idle":"2022-01-05T02:39:56.659850Z","shell.execute_reply.started":"2022-01-05T02:39:54.598713Z","shell.execute_reply":"2022-01-05T02:39:56.658999Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#np.set_printoptions(suppress=True)\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'","metadata":{"execution":{"iopub.status.busy":"2022-01-05T02:39:56.661212Z","iopub.execute_input":"2022-01-05T02:39:56.661520Z","iopub.status.idle":"2022-01-05T02:39:56.664882Z","shell.execute_reply.started":"2022-01-05T02:39:56.661488Z","shell.execute_reply":"2022-01-05T02:39:56.664049Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = device(\"cuda\" if cuda.is_available() else \"cpu\")\n# device = \"cpu\"\nprint(\"==> Device:\", device)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T02:39:56.666607Z","iopub.execute_input":"2022-01-05T02:39:56.667244Z","iopub.status.idle":"2022-01-05T02:39:56.731183Z","shell.execute_reply.started":"2022-01-05T02:39:56.667206Z","shell.execute_reply":"2022-01-05T02:39:56.730280Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"==> Device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data\n#X_train, y_train = load('/kaggle/input/pytorch-mnist/training.pt')\n\n# This code cut and pasted inside eval fun\n\n#X_test, y_test = load('/kaggle/input/pytorch-mnist/test.pt')\n#X_train.shape, y_train.shape, X_test.shape, y_test.shape\n#num = randint(1, len(img_F))\n#img = img_F[num][0]\n#imshow(img)\n#img.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-05T02:39:56.732537Z","iopub.execute_input":"2022-01-05T02:39:56.732950Z","iopub.status.idle":"2022-01-05T02:39:56.741144Z","shell.execute_reply.started":"2022-01-05T02:39:56.732920Z","shell.execute_reply":"2022-01-05T02:39:56.740299Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class NET(nn.Module):\n    def __init__(self, \n                 batch_size,\n                 params={\n                     'image_r_crop': 64,\n                     #\n                    'feature_maps': 2, \n                    'f_kernel_size': 5, \n                    'f_pad_size': 2,\n                    'pools': 'MaxPool2d', \n                    'p_kernel_size': 3, \n                    'f_activs': 'ELU',\n                     #\n                    'f_kernel_size_h': 5, \n                    'f_pad_size_h': 2,\n                    'pools_h': 'MaxPool2d', \n                    'p_kernel_size_h': 3, \n                    'f_activs_h': 'ELU',\n                    'times_hidden': 2,\n                 },\n                 outputs_dim=5,\n                ):\n        super().__init__()\n        \n        self.batch_size = batch_size\n        self.image_r_crop = params['image_r_crop']\n        \n        # inputs model\n        self.f_maps = params['feature_maps']\n        self.f_k_size = params['f_kernel_size']\n        self.f_pad_size = params['f_pad_size']\n        self.pool = params['pools']\n        self.p_k_size = params['p_kernel_size']\n        self.f_activs = params['f_activs']\n        \n        # hidden model\n        self.f_k_size_h = params['f_kernel_size_h']\n        self.f_pad_size_h = params['f_pad_size_h']\n        self.pool_h = params['pools_h']\n        self.p_k_size_h = params['p_kernel_size_h']\n        self.f_activs_h = params['f_activs_h']\n        self.times_hidden = params['times_hidden']\n        \n        # outputs model\n        self.outputs_dim = outputs_dim  \n        \n        self.inputs_model = nn.Sequential(\n            nn.Conv2d(3, \n                      self.f_maps, \n                      self.f_k_size, \n                      padding=(self.f_pad_size, self.f_pad_size),\n                      padding_mode='reflect'),\n            nn.Dropout2d(p=0.25),\n            nn.__getattribute__(self.f_activs)(),\n            nn.__getattribute__(self.pool)(kernel_size=self.p_k_size, \n                                           stride=1))\n        \n        self.hidden_model = nn.Sequential(\n            nn.Conv2d(self.f_maps, \n                      self.f_maps, \n                      self.f_k_size_h, \n                      padding=(self.f_pad_size_h, self.f_pad_size_h),\n                      padding_mode='reflect'),\n            nn.Dropout2d(p=0.25),\n            nn.__getattribute__(self.f_activs_h)(),\n            nn.__getattribute__(self.pool_h)(kernel_size=self.p_k_size_h, \n                                             stride=1))\n        \n        self.hidden_models = nn.ModuleList([self.hidden_model for _ in range(self.times_hidden)])\n        \n        self._hiddens_to_output_helper()\n                \n        self.output_model = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(self.hiddens_out.shape[1], self.outputs_dim),\n            nn.Softmax(dim=-1)\n        )\n        \n    def _hiddens_to_output_helper(self):\n        self.hiddens_out = self.inputs_model(ones(self.batch_size,3,self.image_r_crop,self.image_r_crop))\n        reprs = []\n        for lay in self.hidden_models:\n            reprs.append(lay(self.hiddens_out))\n        self.hiddens_out = nn.Flatten()(cat(reprs, dim=-1))\n        \n    def forward(self, x):\n        \"\"\"Forward\"\"\"\n        res = self.inputs_model(x)\n        reprs = []\n        for lay in self.hidden_models:\n            reprs.append(lay(res))\n        res = cat(reprs, dim=-1)\n        res = self.output_model(res)\n        return res\n    \n    def count_weights_biases(self):\n        return int(sum(p.numel() for p in self.parameters() if p.requires_grad))\n    \n#net = NET(batch_size=16).train()\n#print(f'forward: {net(ones(16, 3, 64, 64).float()).shape}')","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:03:30.073842Z","iopub.execute_input":"2022-01-05T03:03:30.074157Z","iopub.status.idle":"2022-01-05T03:03:30.091475Z","shell.execute_reply.started":"2022-01-05T03:03:30.074129Z","shell.execute_reply":"2022-01-05T03:03:30.090624Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class GA_Pytorch():\n    def __init__(self, \n                 params, \n                 eval_func,\n                 eval_weights,\n                 #X_train,\n                 #X_test,\n                 #y_train,\n                 #y_test,\n                 #lr=0.0001,\n                 sel_tournsize=2, \n                 cx_uniform_prob=0.5, \n                 mut_shuffle_idx_prob=0.1, \n                 n_pop=35, \n                 n_gen=35, \n                 n_hof=5, \n                 cx_prob=0.5, \n                 mut_prob=0.1, \n                 n_jobs=1\n                ):\n        self.params = params\n        self.eval_func = eval_func\n        self.eval_weights = eval_weights\n        \n        #self.X_train = X_train\n        #self.X_test = X_test\n        #self.y_train = y_train\n        #self.y_test = y_test\n        #self.image_folder = image_folder\n        #self.batch_size = batch_size\n        #self.lr = lr\n        \n        self.sel_tournsize = sel_tournsize\n        self.cx_uniform_prob = cx_uniform_prob\n        self.mut_shuffle_idx_prob = mut_shuffle_idx_prob\n        self.n_pop = n_pop\n        self.n_gen = n_gen\n        self.n_hof = n_hof\n        self.cx_prob = cx_prob\n        self.mut_prob = mut_prob\n        \n        self.n_jobs = n_jobs\n\n        self._pad_params()\n        self._create_fitness_and_indiv()\n        self._register_indiv_and_pop_generators()\n        self._register_eval_func()\n        self._register_selection_crossover_mutation_methods()\n\n    def _pad_params(self):\n        \"\"\"Pad params for crossover shuffle idx method\"\"\"\n        assert isinstance(self.params, dict), 'Params must be a dict, i.e. estimator.get_params()'\n        params_count = {k: len(v) for k,v in self.params.items()}\n        max_length, max_key = -99, ''\n        for k, v in params_count.items():\n            if v <= max_length:\n                continue\n            else:\n                max_key = k\n                max_length = v\n        assert isinstance(max_length, int), 'The max length between all params must be an int'\n        # cycle through params for max length param, otherwise infinite cycle\n        values_padded = (cycle(v) if k!=max_key else v for k,v in self.params.items())\n        values_padded = zip(*values_padded)  # ('a', 1, 14), ('b', 2, 16), ('c', 3, 16) ...\n        values_padded = zip(*values_padded)  # ('a', 'b', 'c'), (1, 2, 3), (14, 15, 16)...\n        padded_params = {}\n        for k, v in zip(self.params, values_padded):\n            padded_params[k] = v\n        self.padded_params = padded_params\n        print('Params padded')\n\n    def _create_fitness_and_indiv(self):\n        \"\"\"Create GA individual and fitness entities (classes)\"\"\"\n        ga_cr.create('Fitness', ga_b.Fitness, weights=self.eval_weights)\n        ga_cr.create('Individual', list, fitness=ga_cr.Fitness)\n        print('GA entities created')\n\n    def _gen_params_to_ga(self):\n        \"\"\"Generate index for each param for individual\"\"\"\n        max_dict = len(self.padded_params)\n        max_length = len(list(self.padded_params.values())[0])\n        idxs = [randint(0, max_length-1) for _ in range(max_dict)]\n        return idxs\n    \n    def _register_indiv_and_pop_generators(self):\n        \"\"\"Register GA individual and population generators\"\"\"\n        self.tb = ga_b.Toolbox()\n\n        if self.n_jobs > 1:\n            from multiprocessing import Pool\n            pool = Pool()\n            self.tb.register(\"map\", pool.map)\n\n        self.tb.register(\"individual\", ga_t.initIterate, ga_cr.Individual, self._gen_params_to_ga)\n        #print('indiv', self.tb.individual())\n        self.tb.register(\"population\", ga_t.initRepeat, list, self.tb.individual)\n        #print('population', self.tb.population(n=2))\n        print('GA entities\\' methods registered')\n        \n    def _register_eval_func(self):\n        \"\"\"Set GA evaluate individual function\"\"\"\n        self.tb.register(\"evaluate\",\n                        self.eval_func,\n                        padded_params=self.padded_params,\n                        #image_folder=self.image_folder,\n                        #X_train=self.X_train,\n                        #X_test=self.X_test, \n                        #y_train=self.y_train, \n                        #y_test=self.y_test,\n                        #batch_size=self.batch_size,\n                        #lr=self.lr\n                        )\n        #print(list(self.tb.evaluate(indiv) for indiv in self.tb.population(3)))\n        print('GA eval function registered')\n    \n    def _register_selection_crossover_mutation_methods(self):\n        self.tb.register(\"select\", ga_t.selTournament, tournsize=self.sel_tournsize)\n        self.tb.register(\"mate\", ga_t.cxUniform, indpb=self.cx_uniform_prob)\n        self.tb.register(\"mutate\", ga_t.mutShuffleIndexes, indpb=self.mut_shuffle_idx_prob)\n        print('GA sel-cx-mut methods registered')\n        \n    def run_ga_search(self):\n        \"\"\"GA Search\"\"\"\n        pop = self.tb.population(n=self.n_pop)\n        hof = ga_t.HallOfFame(self.n_hof)\n\n        # Stats stdout\n        #stats = ga_t.Statistics(lambda ind: ind.fitness.values )\n        stats1 = ga_t.Statistics(lambda ind: ind.fitness.values[0] )\n        stats2 = ga_t.Statistics(lambda ind: ind.fitness.values[1] )\n        stats3 = ga_t.Statistics(lambda ind: ind.fitness.values[2] )\n        stats = ga_t.MultiStatistics(accuracy=stats1, risk=stats2, complexity=stats3)\n        stats.register(\"avg\", np.mean)\n        #stats.register(\"std\", np.std)\n        #stats.register(\"min\", np.min)\n        #stats.register(\"max\", np.max)\n\n        # History\n        #hist = tools.History()\n        #toolbox.decorate(\"select\", hist.decorator)\n        #tb.decorate(\"mate\", hist.decorator)\n        #tb.decorate(\"mutate\", hist.decorator)\n        #hist.update(pop)\n\n        # GA Run\n        pop, log = ga_algo.eaSimple(pop, self.tb, cxpb=self.cx_prob, \n                                    mutpb=self.mut_prob, ngen=self.n_gen, \n                                    stats=stats, halloffame=hof, verbose=True)\n        \n        # Convert back params\n        hof_ = {}\n        for i in range(self.n_hof):\n            hof_['hof_' + str(i)] = self._ga_to_params(hof[i])\n\n        return pop, log, hof_\n    \n    def _ga_to_params(self, idx_params):\n        \"\"\"Convert back idx to params\"\"\"\n        res = {}\n        for (k,v), idx in zip(self.padded_params.items(), idx_params):\n            res[k] = v[idx]\n        return res","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:04:48.464398Z","iopub.execute_input":"2022-01-05T03:04:48.464759Z","iopub.status.idle":"2022-01-05T03:04:48.488180Z","shell.execute_reply.started":"2022-01-05T03:04:48.464714Z","shell.execute_reply":"2022-01-05T03:04:48.487246Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"net_params = {\n    #image folder\n    'image_resize': np.linspace(64, 128, 5).astype(int),\n    'image_r_crop': np.linspace(16, 64, 5).astype(int),\n    \n    # inputs model\n    'feature_maps': np.linspace(5, 15, 5).astype(int),\n    'f_kernel_size': np.linspace(1, 5, 5).astype(int),\n    'f_pad_size': np.linspace(0, 4, 5).astype(int),\n    'pools': ['MaxPool2d', 'AvgPool2d'],\n    'p_kernel_size': np.linspace(1, 5, 5).astype(int),\n    'f_activs': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n    \n    # hidden model\n    'f_kernel_size_h': np.linspace(1, 5, 5).astype(int),\n    'f_pad_size_h': np.linspace(0, 4, 5).astype(int),\n    'pools_h': ['MaxPool2d', 'AvgPool2d'],\n    'p_kernel_size_h': np.linspace(1, 5, 5).astype(int),\n    'f_activs_h': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n    'times_hidden': np.linspace(1, 5, 2).astype(int),\n    \n    # learning\n    'batch_size': np.linspace(8, 64, 5).astype(int).tolist(),\n    'lr': np.linspace(0.0001, 0.01, 5),\n}\n\ndef net_eval_indiv(individual, padded_params):\n    \"\"\"Evaluate individual's genes (estimator's params)\"\"\"\n    # Params\n    indiv_params = {k : list(v)[idx] for (k,v), idx in zip(padded_params.items(), individual)}\n    image_folder_params = {k:v for k,v in indiv_params.items() if k in ['image_resize', 'image_r_crop']}\n    net_params = {k:v for k,v in indiv_params.items() if k in [\n        'feature_maps', 'f_kernel_size', 'f_pad_size', 'pools', 'p_kernel_size',\n        'f_activs', 'f_kernel_size_h', 'f_pad_size_h', 'pools_h', \n        'p_kernel_size_h', 'f_activs_h', 'times_hidden', 'image_r_crop'\n    ]}\n    learning_params = {k:v for k,v in indiv_params.items() if k in ['batch_size', 'lr']}    \n    \n    # Data\n    trans = transforms.Compose([\n                transforms.Resize(size=(image_folder_params['image_resize'],image_folder_params['image_resize'])), \n                # transforms.RandomRotation(degrees=[-5, 5], ),\n                transforms.RandomCrop(size=(image_folder_params['image_r_crop'],image_folder_params['image_r_crop'])),\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomVerticalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n    image_folder = ImageFolder('/kaggle/input/flower-photos-by-the-tensorflow-team/flower_photos', \n                        transform=trans)\n\n    # Net\n    try:\n        net = NET(batch_size=learning_params['batch_size'], params=net_params)\n        net = net.to(device)\n\n        # Optimizer\n        optimizer = Adam(net.parameters(), lr=learning_params['lr'])\n        criterion = nn.NLLLoss()\n\n        # Train\n        #train_ds = DS(X_train, y_train)  # TODO refactor out\n        train_dl = DataLoader(image_folder,\n                            batch_size=learning_params['batch_size'],\n                            shuffle=True,\n                            num_workers=2,\n                            drop_last=True)\n\n        for epoch in range(1):\n            #running_loss = []\n            train_correct = 0\n            train_total = 0\n            for i, (inputs, labels) in enumerate(train_dl):\n                if i <= 20:\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n                    outputs = net(inputs)\n                    outputs = pt_log(outputs)\n\n                    optimizer.zero_grad()\n                    loss = criterion(outputs, labels).mean()\n                    loss.backward()\n                    optimizer.step()\n\n                    # print statistics\n                    #running_loss.append(loss.item())\n                    _, predicted = pt_max(outputs.data, 1)\n                    train_total += labels.size(0)\n                    train_correct += (predicted == labels).sum().item()\n                    train_accuracy = train_correct / train_total * 100\n                    #print(f'TRAIN {train_accuracy:^5.2f} %', end=' ')\n                else:\n                    break\n    except BaseException as e:\n        print(e)\n        return (0.01, 10, 1000000,)\n        \n    # Eval\n    \"\"\"with no_grad():\n        net = net.eval()\n        test_ds = DS(X_test, y_test)  # TODO refactor out\n        test_dl = DataLoader(test_ds,\n                            batch_size=batch_size,\n                            shuffle=True,\n                            drop_last=True)\n        #running_loss = []\n        test_correct = 0\n        test_total = 0\n        for i, (inputs, labels) in enumerate(test_dl):\n            if i <= 100:\n                #inputs = inputs.cuda()\n                #labels = labels.cuda()\n                outputs = net(inputs)\n\n                # print statistics\n                #running_loss.append(loss.item())\n                _, predicted = pt_max(outputs.data, 1)\n                test_total += labels.size(0)\n                test_correct += (predicted == labels).sum().item()\n                test_accuracy = test_correct / test_total * 100\n            else:\n                break\n        #print(f'TEST {test_accuracy:^5.2f} %')\"\"\"\n        \n    # Risk\n    inputs = inputs.to(device)\n    risk = mean(prod(net(inputs)*10, dim=1))\n    if isnan(risk):\n        risk = 10\n    else:\n        risk = float(risk)\n        \n    # Complexity\n    compl = net.count_weights_biases()\n\n    return (train_accuracy, compl,)\n\nnet_weights = (1, -1, -1)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:05:10.247697Z","iopub.execute_input":"2022-01-05T03:05:10.248070Z","iopub.status.idle":"2022-01-05T03:05:10.270059Z","shell.execute_reply.started":"2022-01-05T03:05:10.248028Z","shell.execute_reply":"2022-01-05T03:05:10.269229Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"net_ga_params = GA_Pytorch(net_params,\n                           net_eval_indiv,\n                           net_weights)\npop, log, hof = net_ga_params.run_ga_search()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:05:11.063577Z","iopub.execute_input":"2022-01-05T03:05:11.063967Z","iopub.status.idle":"2022-01-05T03:52:35.716939Z","shell.execute_reply.started":"2022-01-05T03:05:11.063935Z","shell.execute_reply":"2022-01-05T03:52:35.715835Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Params padded\nGA entities created\nGA entities' methods registered\nGA eval function registered\nGA sel-cx-mut methods registered\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Fitness' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n  RuntimeWarning)\n/opt/conda/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n  RuntimeWarning)\n","output_type":"stream"},{"name":"stdout","text":"   \t      \t       accuracy       \t      complexity      \t         risk         \n   \t      \t----------------------\t----------------------\t----------------------\ngen\tnevals\tavg    \tgen\tnevals\tavg   \tgen\tnevals\tavg    \tgen\tnevals\n0  \t35    \t22.0198\t0  \t35    \t248062\t0  \t35    \t12.0116\t0  \t35    \n1  \t18    \t23.2718\t1  \t18    \t214795\t1  \t18    \t15.7491\t1  \t18    \n2  \t16    \t25.8277\t2  \t16    \t186215\t2  \t16    \t18.5593\t2  \t16    \n3  \t15    \t27.1013\t3  \t15    \t309391\t3  \t15    \t16.4109\t3  \t15    \n4  \t13    \t27.9793\t4  \t13    \t415380\t4  \t13    \t14.4838\t4  \t13    \n5  \t22    \t28.2922\t5  \t22    \t500725\t5  \t22    \t12.6693\t5  \t22    \n6  \t13    \t30.0753\t6  \t13    \t572869\t6  \t13    \t11.6528\t6  \t13    \n7  \t14    \t30.9379\t7  \t14    \t682520\t7  \t14    \t9.50409\t7  \t14    \n8  \t17    \t30.9785\t8  \t17    \t714878\t8  \t17    \t9.75932\t8  \t17    \n9  \t13    \t31.3934\t9  \t13    \t736567\t9  \t13    \t9.91786\t9  \t13    \n10 \t17    \t31.1791\t10 \t17    \t771324\t10 \t17    \t10.6591\t10 \t17    \n11 \t20    \t31.9108\t11 \t20    \t840674\t11 \t20    \t8.83526\t11 \t20    \n12 \t16    \t32.9108\t12 \t16    \t817644\t12 \t16    \t8.61969\t12 \t16    \n13 \t22    \t32.0789\t13 \t22    \t836419\t13 \t22    \t8.5661 \t13 \t22    \n14 \t17    \t31.47  \t14 \t17    \t824720\t14 \t17    \t9.40576\t14 \t17    \n15 \t12    \t32.2178\t15 \t12    \t843904\t15 \t12    \t8.92872\t15 \t12    \n16 \t20    \t32.7013\t16 \t20    \t827229\t16 \t20    \t8.90859\t16 \t20    \n17 \t20    \t32.8555\t17 \t20    \t827228\t17 \t20    \t9.07994\t17 \t20    \n18 \t23    \t32.0928\t18 \t23    \t810251\t18 \t23    \t9.09078\t18 \t23    \n19 \t19    \t32.1009\t19 \t19    \t820659\t19 \t19    \t8.8631 \t19 \t19    \n20 \t14    \t33.3238\t20 \t14    \t828941\t20 \t14    \t8.16045\t20 \t14    \n21 \t15    \t33.1157\t21 \t15    \t802196\t21 \t15    \t8.70464\t21 \t15    \n22 \t14    \t33.2421\t22 \t14    \t794085\t22 \t14    \t8.77006\t22 \t14    \n23 \t19    \t32.2774\t23 \t19    \t783705\t23 \t19    \t9.4922 \t23 \t19    \n24 \t21    \t31.5845\t24 \t21    \t776585\t24 \t21    \t9.51442\t24 \t21    \n25 \t20    \t31.4236\t25 \t20    \t802130\t25 \t20    \t9.09828\t25 \t20    \n26 \t23    \t31.8738\t26 \t23    \t786301\t26 \t23    \t8.98077\t26 \t23    \n27 \t14    \t32.4271\t27 \t14    \t782687\t27 \t14    \t7.98033\t27 \t14    \n28 \t19    \t32.1421\t28 \t19    \t756729\t28 \t19    \t8.56152\t28 \t19    \n29 \t17    \t33.0561\t29 \t17    \t773169\t29 \t17    \t9.57474\t29 \t17    \n30 \t21    \t32.9794\t30 \t21    \t799991\t30 \t21    \t9.53283\t30 \t21    \n31 \t16    \t32.7154\t31 \t16    \t791233\t31 \t16    \t9.12774\t31 \t16    \n32 \t24    \t32.7158\t32 \t24    \t841464\t32 \t24    \t8.86231\t32 \t24    \n33 \t16    \t33.1933\t33 \t16    \t835806\t33 \t16    \t8.65242\t33 \t16    \n34 \t17    \t33.1335\t34 \t17    \t807571\t34 \t17    \t9.31928\t34 \t17    \n35 \t17    \t33.4141\t35 \t17    \t799425\t35 \t17    \t8.56723\t35 \t17    \n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(list(hof.values()))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:53:30.821557Z","iopub.execute_input":"2022-01-05T03:53:30.822022Z","iopub.status.idle":"2022-01-05T03:53:30.861401Z","shell.execute_reply.started":"2022-01-05T03:53:30.821981Z","shell.execute_reply":"2022-01-05T03:53:30.860629Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"   image_resize  image_r_crop  feature_maps  f_kernel_size  f_pad_size  \\\n0            80            64            10              3           0   \n1            80            64            10              3           0   \n2            80            64            10              2           0   \n3            80            64            10              3           0   \n4            80            64            10              3           0   \n\n       pools  p_kernel_size  f_activs  f_kernel_size_h  f_pad_size_h  \\\n0  AvgPool2d              1  Softsign                4             0   \n1  AvgPool2d              1  Softsign                4             0   \n2  MaxPool2d              1  Softsign                4             0   \n3  MaxPool2d              1  Softsign                3             0   \n4  MaxPool2d              1       ELU                3             0   \n\n     pools_h  p_kernel_size_h f_activs_h  times_hidden  batch_size      lr  \n0  MaxPool2d                3        ELU             5          64  0.0001  \n1  MaxPool2d                3       CELU             5          50  0.0001  \n2  MaxPool2d                3       CELU             5          64  0.0001  \n3  MaxPool2d                3        ELU             5          64  0.0001  \n4  MaxPool2d                4        ELU             5          64  0.0001  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_resize</th>\n      <th>image_r_crop</th>\n      <th>feature_maps</th>\n      <th>f_kernel_size</th>\n      <th>f_pad_size</th>\n      <th>pools</th>\n      <th>p_kernel_size</th>\n      <th>f_activs</th>\n      <th>f_kernel_size_h</th>\n      <th>f_pad_size_h</th>\n      <th>pools_h</th>\n      <th>p_kernel_size_h</th>\n      <th>f_activs_h</th>\n      <th>times_hidden</th>\n      <th>batch_size</th>\n      <th>lr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>80</td>\n      <td>64</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>AvgPool2d</td>\n      <td>1</td>\n      <td>Softsign</td>\n      <td>4</td>\n      <td>0</td>\n      <td>MaxPool2d</td>\n      <td>3</td>\n      <td>ELU</td>\n      <td>5</td>\n      <td>64</td>\n      <td>0.0001</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80</td>\n      <td>64</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>AvgPool2d</td>\n      <td>1</td>\n      <td>Softsign</td>\n      <td>4</td>\n      <td>0</td>\n      <td>MaxPool2d</td>\n      <td>3</td>\n      <td>CELU</td>\n      <td>5</td>\n      <td>50</td>\n      <td>0.0001</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80</td>\n      <td>64</td>\n      <td>10</td>\n      <td>2</td>\n      <td>0</td>\n      <td>MaxPool2d</td>\n      <td>1</td>\n      <td>Softsign</td>\n      <td>4</td>\n      <td>0</td>\n      <td>MaxPool2d</td>\n      <td>3</td>\n      <td>CELU</td>\n      <td>5</td>\n      <td>64</td>\n      <td>0.0001</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80</td>\n      <td>64</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>MaxPool2d</td>\n      <td>1</td>\n      <td>Softsign</td>\n      <td>3</td>\n      <td>0</td>\n      <td>MaxPool2d</td>\n      <td>3</td>\n      <td>ELU</td>\n      <td>5</td>\n      <td>64</td>\n      <td>0.0001</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>80</td>\n      <td>64</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>MaxPool2d</td>\n      <td>1</td>\n      <td>ELU</td>\n      <td>3</td>\n      <td>0</td>\n      <td>MaxPool2d</td>\n      <td>4</td>\n      <td>ELU</td>\n      <td>5</td>\n      <td>64</td>\n      <td>0.0001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"net_params","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:53:58.932989Z","iopub.execute_input":"2022-01-05T03:53:58.933326Z","iopub.status.idle":"2022-01-05T03:53:58.943522Z","shell.execute_reply.started":"2022-01-05T03:53:58.933297Z","shell.execute_reply":"2022-01-05T03:53:58.942658Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"{'image_resize': array([ 64,  80,  96, 112, 128]),\n 'image_r_crop': array([16, 28, 40, 52, 64]),\n 'feature_maps': array([ 5,  7, 10, 12, 15]),\n 'f_kernel_size': array([1, 2, 3, 4, 5]),\n 'f_pad_size': array([0, 1, 2, 3, 4]),\n 'pools': ['MaxPool2d', 'AvgPool2d'],\n 'p_kernel_size': array([1, 2, 3, 4, 5]),\n 'f_activs': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n 'f_kernel_size_h': array([1, 2, 3, 4, 5]),\n 'f_pad_size_h': array([0, 1, 2, 3, 4]),\n 'pools_h': ['MaxPool2d', 'AvgPool2d'],\n 'p_kernel_size_h': array([1, 2, 3, 4, 5]),\n 'f_activs_h': ['ReLU', 'CELU', 'SELU', 'ELU', 'Softsign'],\n 'times_hidden': array([1, 5]),\n 'batch_size': [8, 22, 36, 50, 64],\n 'lr': array([0.0001  , 0.002575, 0.00505 , 0.007525, 0.01    ])}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}